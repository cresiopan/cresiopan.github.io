<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-03-16 Tue 18:30 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Control de Congestión</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="/res/org.css"/>
<script type="text/javascript" src="/res/org-info.js"></script>
<script type="text/javascript" src="../res/org-info.js"></script>
<link rel="stylesheet" type="text/css" href="../res/org.css"/>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<div id="content">

<div id="outline-container-org06f173e" class="outline-1">
<h1 id="org06f173e"><span class="section-number-1">1</span> Transporte Orientado a Conexion</h1>
<div class="outline-text-1" id="text-1">
</div>
<div id="outline-container-org7e80ac7" class="outline-2">
<h2 id="org7e80ac7"><span class="section-number-2">1.1</span> Control de flujo</h2>
<div class="outline-text-2" id="text-1-1">
<p>
recordemos que cada extremo de la conexion tcp, reserva un buffer para la
recepcion de datos. los datos se colocan en el buffer si son correctos y estan
en orden. la aplicacion puede tardar un tiempo en leer los datos y por lo tanto,
el emisor puede desbordar el buffer receptor.
</p>

<p>
tcp proveee un servicio de control de flujo para evitar que esto suceda. el
control de flujo es entonces un servicio para equilibrar las velocidades de
transmision del emisor y lectura de la aplicacion receptora.
</p>

<p>
(esto es diferente de control de congestion, en el sentido de que cc es debido a
congestion en la red. cf es debido a la sincronizacion entre emisor y receptor)
</p>

<p>
we suppose throughout this section that the TCP implementation is such that the
TCP receiver discards out-of-order segments.
</p>

<p>
se provee cf al hacer que el emisor mantenga una variable llamada <code>receive
window</code>. le da al emisor una idea de cuanto espacio libre hay disponible en el
buffer receptor.
</p>

<p>
Suppose that Host A is sending a large file to Host B over a TCP
connection. Host B allocates a receive buffer to this connection; denote its
size by RcvBuffer. From time to time, the application process in Host B reads
from the buffer.
</p>

<p>
Define the following variables:
</p>
<ul class="org-ul">
<li>LastByteRead: numero del ultimo byte leido en el stream de datos en el buffer
por el proceso en el host B</li>
<li>LastByteRcvd: numero del tulimo byte del stream que llego de la red y fue
colocado en el buffer en B.</li>
</ul>

<p>
como no se puede desbordar el buffer alocado:
</p>

<p>
\[LastByteRcvd−LastByteRead \leq RcvBuffer\]
</p>

<p>
La ventana de recepcion (\(rwnd\)) se configura para que sea la cantidad de
espacio libre en el buffer:
</p>

<p>
\[rwnd=RcvBuffer−[LastByteRcvd−LastByteRead]\]
</p>

<p>
imagen 3.38
</p>

<p>
el host b notifica al host a cuanto espacio libre tiene en su buffer al
colocar el valor actual de rwnd en el campo recieve window del header tcp.
</p>

<p>
por el otro lado, el host A mantiene dos variables:
</p>
<ul class="org-ul">
<li>LastByteSent</li>
<li>LastByteAcked</li>
</ul>

<p>
La diferencia \(LastByteSent - LastByteAcked\) es la cantidad de datos no
confirmados que A envio a la conexion.  si esta diferencia es menor a rwnd,
entonces el host A se asegura de que no esta desbordando el buffer en el host
B.
</p>

<p>
\[LastByteSent-LastByteAcked \leq rwnd\]
</p>

<p>
Que pasa si el receptor notifica que rwnd=0 y no tiene mensajes para enviar?
El emisor nunca podria saber cuando el receptor tiene espacio el buffer para
seguir almacenando datos.  por este motivo, la especificacion de TCP requiere
que el host A continue enviado segmentos de un byte de datos cuando el rwnd
de B es 0. estos segmentos son confirmados por el receptor. Eventualmente el
buffer del receptor se liberara y el rwnd aumentara.
</p>

<p>
udp no realiza control de flujo.
</p>
</div>
</div>

<div id="outline-container-org82fa436" class="outline-2">
<h2 id="org82fa436"><span class="section-number-2">1.2</span> Administracion de conexion de TCP</h2>
<div class="outline-text-2" id="text-1-2">
<p>
Como se establece y se termina una conexion TCP.
</p>

<p>
por que?
</p>
<ul class="org-ul">
<li>puede incrementar delay percivido</li>
<li>entender explotacion de vulnerabilidades</li>
</ul>

<p>
supongamos que un cliente quiere iniciar una connexion con un server:
</p>
<ol class="org-ol">
<li>TCP del lado cliente envia un segmento TCP especial al lado servidor. No
contiene datos de la capa de aplicacion, pero un bit del campo de flags
del encabezado del segmento, bit SYN, se setea a 1. Segmento SYN. Se elige
un numero de secuencia inicial de forma aleatoria (client<sub>isn</sub>). El
segmento se encapsula en un datagrama IP y se envia al servidor.</li>
<li>una vez que llega el datagrama al servidor, se extrae el segmento TCP, se
reserva espacio para los buffers y variables de la conexion, y se envia un
segmento de conexion-aprobada al cliente. Este segmento tampoco contiene
datos de capa de aplicacion, pero el encabezado TCP si contiene el bit SYN
en 1, el campo de ACK en client<sub>isn</sub>+1, y el numero-de-secuencia, inicial,
aleatorio, del servidor (server<sub>isn</sub>). Al este segmento se lo llama SYNACK</li>
<li>cuando el cliente recibe este segmento SYNACK, este reserva buffers y
variables para la conexion, y se envia al servidor un ultimo segmento para
indicar al servidor que se recibio el segmento de conexion-aprobada. Este
segmento tiene el bit de SYN en 0, numero de ACK server<sub>isn</sub>+1 y puede
tener datos de capa de aplicacion en el payload del segmento.</li>
</ol>

<p>
una vez realizados estos pasos, el cliente y servidor pueden enviarse
segmentos con datos entre si. (SYN = 0).
</p>

<p>
imagen 3.39
</p>

<p>
a este proceso (de establecimiento de conexion) se lo llama <code>three way
handshake</code>.
</p>

<p>
una vez que se quiera finalizar la conexion, los recursos reservados para
esta, deben liberarse.
</p>

<p>
imagen 3.40
</p>

<p>
supongamos que el cliente desea cerrar la conexion. este envia un comando
close. TCP del lado del cliente envia un segmento especial con el bit FIN
en 1.  Cuando el servidor recibe este segmento, responde con un ACK. Luego el
servidor envia otro segmento, esta vez con el bit FIN en 1, a lo que el
cliente responde con un ACK. En este punto es cuando se pueden liberar los
recursos.
</p>

<p>
imagen 3.41
</p>

<p>
se muestra en la imagen los posibles estados de TCP en el lado del cliente.
</p>

<p>
imagen 3.42
</p>

<p>
se muestra en la imagen los posibles estados de TCP en el lado del servidor.
</p>


<p>
Que pasa si el host receptor no tiene ningun proceso escuchando en un puerto,
al que otro host quiere conecarse?
</p>

<p>
El host receptor envia un segmento con el bit RST en 1 de vuelta a la fuente,
indicando que no hay un socket para el segmento recibido.
</p>
</div>

<div id="outline-container-org0bcac40" class="outline-3">
<h3 id="org0bcac40"><span class="section-number-3">1.2.1</span> SYN FLOOD attack</h3>
<div class="outline-text-3" id="text-1-2-1">
<p>
Al establecer la conexion TCP, un servidor reserva recursos para la misma y
luego envia un segmento SYNACK. Una forma de atacar al servidor es un Denial
of Service (DoS) mediante un SYN flood.
</p>

<p>
Consiste de enviar una gran cantidad de segmentos SYN, sin intencion de
completar el tercer paso del handshake. El servidor reserva recursos para
cada conexion falsa, lo que denega el servicio a clientes legitimos.
</p>

<p>
para contrarrestar esto se utilizan SYN cookies [RFC 4987] desplegadas en la
mayoria de los sistemas operativos
</p>

<ul class="org-ul">
<li>Cuando el servidor recibe un segmento SYN, el servidor crea un numero de
secuencia inicial a partir de un hash de: las ip de origen y destino;
numeros de puertos de origen y destino; y un numero secreto que solo
conoce el servidor. Este numero especial se llama cookie. El servidor
envia un SYNACK con el cookie como numero de secuencia. El servidor no
guarda informacion del estado de esta conexion (ni recursos ni cookie,
nada).</li>
<li>Un cliente legitimo devuleve el ACK. Cuando el servidor recive el
segmento, recalcula el hash y verifica que el numero del ACK sea el cookie
(recalculado) mas 1. Si es el caso, el servidor crea una conexion
completa.</li>
<li>Por el otro lado, si el cliente no responde con ACK, entonces el SYN
original no hace daño al servidor, ya que el servidor no reservo recursos.</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org784f22c" class="outline-1">
<h1 id="org784f22c"><span class="section-number-1">2</span> <span class="todo todo-class-TODO">TODO</span> Principios de Control de Congestion</h1>
<div class="outline-text-1" id="text-2">
<p>
Analizamos Control de congestion en un contexto generico:
</p>

<p>
congestion:
</p>
<ul class="org-ul">
<li>por que es malo</li>
<li>como se manifiesta (como es percivida en capas superiores)</li>
<li>como evitarla</li>
</ul>
</div>

<div id="outline-container-orge93898c" class="outline-2">
<h2 id="orge93898c"><span class="section-number-2">2.1</span> Causas y costos de la congestion</h2>
<div class="outline-text-2" id="text-2-1">
</div>
<div id="outline-container-org779285f" class="outline-3">
<h3 id="org779285f"><span class="section-number-3">2.1.1</span> escenario 1 - dos emisores, un router con buffers infinitos</h3>
<div class="outline-text-3" id="text-2-1-1">
<p>
imagen 3.43
</p>

<p>
el host a transmite datos con un promedio de &lambda;<sub>in</sub> bytes/seg. estos datos
son originales en el sentido en que cada unidad se envia al socket solo una
vez.
</p>

<p>
el protocolo de capa de transporte es simple, solo encapsula y envia. sin
recuperacion de errores, sin control de flujo o control de congestion.
</p>

<p>
ignorando el delay de otras capas, la velocidad de transmision el &lambda;<sub>in</sub>
</p>

<p>
el host b opera de forma similar. asumimos tambien que transmite a una velocidad
de &lambda;<sub>in</sub>.
</p>

<p>
a y b comparten un enlace de capacidad R al router. el router tiene buffers en
dicho enlace para que no halla overflow.
</p>

<p>
imagen 3.44
</p>

<p>
la imagen muestra el throughput en funcion de la velocidad de transmision. si la
velocidad de transmision va entre 0 a R/2, todo va bien, todo lo que se
transmite, se recibe. Cuando la velocidad de transmision pasa R/2, el throughput
se limita a R/2. el enlace no puede entregar paquetes que exceden la capacidad
del enlace. maximizar el throughput puede parecer bueno, porque se aprovecha la
capacidad del enlace, pero el otro grafico de la imagen 3.44, muestra las
consecuencias de operar al limite de la capacidad del enlace. cuando se excede
la transmision de R/2, la cantidad de paquetes encolados en el router incrementa
sin limite, por lo que el delay tambien incrementa.
</p>

<p>
se tienen delays de encolado a medida que la velocidad de arrivos de paquetes
(al router) se acerca a la capacidad del enlace.
</p>
</div>
</div>

<div id="outline-container-org9927ec0" class="outline-3">
<h3 id="org9927ec0"><span class="section-number-3">2.1.2</span> escenario 2 - dos emisores, un router con buffers finitos</h3>
<div class="outline-text-3" id="text-2-1-2">
<p>
en este escenario, puede ocurrir perdida de paquetes.
la conexion es confiable. si ocurre una perdida, el protocolo de
capa-de-transporte se encarga de retransmitir.
</p>

<p>
ahora hay una distincion entre transmision de datos-originales y transmision de
datos-originales-y-retransmitidos, &lambda;<sub>in</sub> y &lambda;<sub>in</sub><sup>'</sup>
respectivamente.
</p>

<p>
a &lambda;<sub>in</sub><sup>'</sup> tambien se lo llama <code>offered load</code> a la red.
</p>

<p>
&#x2026;
</p>

<p>
el transmisor debe retransmitir para compensar por perdida de paquetes debido a
buffer overflow.
</p>


<p>
retransmisiones innecesarias ante largos delays pueden causar que un router
utilice el bandwidth del enlace para enviar copias de paquetes inncesarias.
</p>
</div>
</div>

<div id="outline-container-org650bac8" class="outline-3">
<h3 id="org650bac8"><span class="section-number-3">2.1.3</span> escenario 3 - cuatro emisores, routers con buffers finitos, multiples saltos</h3>
<div class="outline-text-3" id="text-2-1-3">
<p>
imagen 3.47
</p>

<p>
&#x2026;
</p>

<p>
cuando un paquete se pierde en la ruta, la capacidad de transmision que fue
utilizada para enviar el paquete hasta el punto en el que se perdio, fue
desperdiciada.
</p>

<p>
&#x2026;
</p>
</div>
</div>
</div>

<div id="outline-container-org995636a" class="outline-2">
<h2 id="org995636a"><span class="section-number-2">2.2</span> Abordando el control de congestion</h2>
<div class="outline-text-2" id="text-2-2">
<p>
la capa de red puede asistir o no, a la capa de transporte para el control de
congestion:
</p>

<dl class="org-dl">
<dt>End-to-end congestion control</dt><dd>la capa-de-red no provee apoyo explicito a la
capa-de-transporte para el control de congestion. Los end-systems deben
inferir la presencia de congestion basados solamente en obsevaciones de la
red. La perdida de paquetes en TCP (por timeout o 3 ACK consecutivos) se toma
como congestion de la red.</dd>
<dt>Network-assisted congestion control</dt><dd><p>
los routers proveen feedback explicito
al emisor sobre el estado de la red. puede consistir de un solo bit indicando
la congestion en el enlace. IBM SNA, DEC DECnet, ATM.  El control de
congestion puede ser mas sofisticado, por ejemplo el router informa al emisor
sobre la capacidad maxima de transmision que tiene en un enlace saliente
(visto en ATM Available Bite Rate (ABR))
</p>

<p>
otra forma: cuando un paquete pasa por un router con congestion, el router marca
al encabezado indicando esto. cuando el receptor responde al emisor, lo hace con
la misma marca en el encabezado, de esta forma indicando al emisor de la
congestion. (toma un RTT)
</p></dd>
</dl>

<p>
imagen 3.49
</p>
</div>
</div>
</div>

<div id="outline-container-org81a916d" class="outline-1">
<h1 id="org81a916d"><span class="section-number-1">3</span> Control de Congestion de TCP</h1>
<div class="outline-text-1" id="text-3">
<p>
tcp debe usar control de congestion end-to-end ya que ip no provee asistencia.
</p>

<p>
en tcp cada transmisor limita la velocidad a la cual transmite trafico a la
conexion en funcion de la congestion percivida en la red.
</p>

<ul class="org-ul">
<li>como limita la velocidad de transmision?</li>
<li>como percive la congestion en la red?</li>
<li>que algoritmo deberia utilizar para cambiar la velocidad de transmision?</li>
</ul>

<p>
el emisor en tcp mantiene:
</p>
<ul class="org-ul">
<li>buffer de entrada y salida</li>
<li>LastByteRead</li>
<li>rwnd</li>
<li><code>congestion windows (cwnd)</code> : limita a la velocidad de transmision. La
cantidad de datos sin ACK en el emisor no puede superar al minimo entre cwnd y
rwnd
\[LastByteSent - LastByteAcked \leq \min\{cwnd,rwnd\}\]</li>
</ul>

<p>
se considera a un paquete perdido cuando ocurre un timeout o cuando el emisor
recibe tres ACK duplicados
</p>

<p>
por el otro lado, suponiendo que no hay perdidas de paquetes, el arrivo de
paquetes indica al emisor que todo anda bien y que se puede incrementar la
ventana de congestion. si los ACKs llegan despacio, la ventana de congestion
incrementa despacio. por este uso de este mecanismo, se dice que TCP es
<code>self-clocking</code>.
</p>

<ul class="org-ul">
<li>un segmento perdido implica congestion y por lo tanto, el emisor debe bajar la
velocidad de transmision</li>
<li>un segmento confirmado indica que la red entrega los segmentos al receptor y
por lo tanto el emisor puede incrementar la velocidad de transmision cuando
llegue el ACK de un paquete enviado.</li>
</ul>

<p>
El algoritmo de control de congestion definido en [RFC 5681] tiene 3
componentes:
</p>
<ol class="org-ol">
<li>slow start</li>
<li>congestion avoidance</li>
<li>fast recovery (opcional)</li>
</ol>
</div>

<div id="outline-container-org6ea0349" class="outline-2">
<h2 id="org6ea0349"><span class="section-number-2">3.1</span> Slow Start (SS)</h2>
<div class="outline-text-2" id="text-3-1">
<p>
cuando la conexion TCP empieza , en general cwnd = 1MSS
[RFC 3390]
</p>

<p>
por lo que la velocidad de transmision es MSS/RTT aprox. Se incrementa en 1 MSS
cada vez que se recibe un ACK.
</p>

<p>
imagen 3.50
</p>

<p>
crecimiento exponencial.
</p>

<p>
como termina ss?
</p>
<ul class="org-ul">
<li>si hay una perdida por timeout, cwnd=1, y se mantiene en modo SS
se establece una variable ssthresh (slow start threshold) = cwnd/2 , cuando se
detecta congestion</li>
<li>si cwnd=ssthresh, se ingresa en modo (CA congestion avoidance)</li>
<li>si se reciben 3 ACKs duplicados (4 ACKs iguales), se realiza fast retransmit y
se ingresa en modo fast recovery</li>
</ul>

<p>
imagen 3.51
</p>
</div>
</div>

<div id="outline-container-orgca6c169" class="outline-2">
<h2 id="orgca6c169"><span class="section-number-2">3.2</span> <span class="todo todo-class-TODO">TODO</span> Congestion Avoidance (CA)</h2>
<div class="outline-text-2" id="text-3-2">
<p>
[RFC 5681]
</p>

<p>
se setea a cwnd = cwnd/2 cuando se detecta congestion
</p>

<p>
por cada RTT, se incrementa cwnd en 1 MSS.  en realidad se incrementa por
cada ACK recibido, pero al enviarse cwnd/MSS (cantidad de MSSs/segmentos de
tamaño MSS) y cada ACK incrementa cwnd en MSS/cwnd; si se reciben todos los
ACKs, se termina incrementando cwnd en 1 MSS = cwnd/MSS (ACKs recibidos) *
MSS/cwnd (incremento por ACK)
</p>


<p>
como termina CA?
se entra en modo FR
</p>
</div>
</div>

<div id="outline-container-org5b07257" class="outline-2">
<h2 id="org5b07257"><span class="section-number-2">3.3</span> <span class="todo todo-class-TODO">TODO</span> Fast Recovery (FR)</h2>
<div class="outline-text-2" id="text-3-3">
<p>
[RFC 5681]
</p>

<p>
el valor de cwnd se incrementa en 1 MSS por cada ACK duplicado recibido para el segmento que causo que TCP entrara en modo FR.
</p>

<p>
utilizado en TCP Reno
</p>
</div>
</div>

<div id="outline-container-org3ca244e" class="outline-2">
<h2 id="org3ca244e"><span class="section-number-2">3.4</span> en retrospectiva</h2>
<div class="outline-text-2" id="text-3-4">
<p>
asumiendo que las perdidas ocurren por ACKs duplicados y no por timeout, el control de congestion de TCP consiste de incrementos aditivos y decrementos multiplicativos de la ventana de congestion (cwnd).
</p>

<p>
imagen 3.53
</p>
</div>
</div>

<div id="outline-container-orgeb969c1" class="outline-2">
<h2 id="orgeb969c1"><span class="section-number-2">3.5</span> <span class="todo todo-class-TODO">TODO</span> TCP Splitting</h2>
</div>
</div>

<div id="outline-container-org3f7418b" class="outline-1">
<h1 id="org3f7418b"><span class="section-number-1">4</span> Resumen</h1>
<div class="outline-text-1" id="text-4">
<p>
servicios que un protocolo de capa de transporte provee a aplicaciones de red.
</p>

<ul class="org-ul">
<li>mux/demux</li>
<li>entrega de datos confiable</li>
<li>garantia de delay</li>
<li>garantia de ancho de banda</li>
</ul>

<p>
servicios que se proveen estan restringidos por el protocolo de capa de red
(que esta abajo) si no se proveen garantias de delay y ancho de banda a
segmentos de capa de transporte, no se puede proveer estas garantias a
mensajes entre aplicaciones
</p>

<p>
se puede proveer TDC a traves de acuse de recibo, timers , retransmisiones y
numeros de secuencia.
</p>

<p>
TCP provee:
</p>
<ul class="org-ul">
<li>administracion de conexion</li>
<li>control de flujo</li>
<li>estimacion de tiempo de round-trip</li>
<li>TDC</li>
<li>control de congestion end-to-end que incrementa la velocidad de transmision de forma aditica y la decrementa de forma multiplicativa cuando se detecta perdida de paquetes.</li>
</ul>

<p>
La complejidad de TCP esta oculta para la aplicacion de red.
</p>

<p>
The Datagram Congestion Control Protocol (DCCP) [RFC 4340] provides a
low-overhead, message-oriented, UDP-like unreliable service, but with an
application-selected form of congestion control that iscompatible with TCP. If
reliable or semi-reliable data transfer is needed by an application, then
thiswould be performed within the application itself, perhaps using the
mechanisms we have studied inSection 3.4. DCCP is envisioned for use in
applications such as streaming media thatcan exploit the tradeoff between
timeliness and reliability of data delivery, but that want to be responsiveto
network congestion.
</p>

<p>
Google’s QUIC (Quick UDP Internet Connections) protocol [Iyengar
2016], implemented in Google’sChromium browser, provides reliability via
retransmission as well as error correction, fast-connectionsetup, and a
rate-based congestion control algorithm that aims to be TCP friendly—all
implemented asan application-level protocol on top of UDP. o
</p>

<p>
DCTCP (Data Center TCP) [Alizadeh 2010] is a version of TCP
designed specifically for data centernetworks, and uses ECN to better support
the mix of short- and long-lived flows that characterize datacenter
workloads.
</p>

<p>
The Stream Control Transmission Protocol (SCTP) [RFC 4960, RFC 3286]
is a reliable, message-oriented protocol that allows several different
application-level “streams” to be multiplexed through asingle SCTP connection
(an approach known as “multi-streaming”).
From a reliability standpoint,
thedifferent streams within the connection are handled separately, so that
packet loss in one stream doesnot affect the delivery of data in other
streams.
</p>

<p>
QUIC provides similar multi-stream semantics.
</p>

<p>
SCTP also allows data to
be transferred over two outgoing paths when a host is connected to two or
morenetworks, optional delivery of out-of-order data, and a number of other
features.
</p>

<p>
SCTP’s flow- andcongestion-control algorithms are essentially the same
as in TCP.
</p>

<p>
The TCP-Friendly Rate Control (TFRC) protocol [RFC 5348] is a
congestion-control protocol rather thana full-fledged transport-layer
protocol. It specifies a congestion-control mechanism that could be used
inanother transport protocol such as DCCP (indeed one of the two
application-selectable protocolsavailable in DCCP is TFRC). The goal of TFRC
is to smooth out the “saw tooth” behavior (see Fig­ure3.53) in TCP congestion
control, while maintaining a long-term sending rate that is “reasonably” close
tothat of TCP. With a smoother sending rate than TCP, TFRC is well-suited for
multimedia applicationssuch as IP telephony or streaming media where such a
smooth rate is important. TFRC is an “equation-based” protocol that uses the
measured packet loss rate as input to an equation [Padhye 2000] thatestimates
what TCP’s throughput would be if a TCP session experiences that loss rate.
This rate is thentaken as TFRC’s target sending rate.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
Last update: 2021-03-16 18:30
</div>
</body>
</html>
