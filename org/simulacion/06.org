#+title:Cadenas de Markov

* Cadenas de Markov

** Introducción

   En la práctica los procesos aleatorios que necesitamos modelar *no son
   independientes*.

   Una forma de incluir dependencia entre variables aleatorias es considerar un
   modelo que limite esta *dependencia* a los *vecinos más cercanos*.

   Proceso de Markov: A random process X(t) is a *Markov process* if the future
   of the process given the present is independent of the past, that is, if for
   arbitrary times $t_1 < t_2 < \dots < t_k < t_{k+1}$,

   $$P\left(X(t_{k+1}) = x_{k+1} | X(t_k) = x_k,\dots , X(t_1) = x_1 \right) =
   P\left(X(t_{k+1}) = x_{k+1}|X(t_k) = x_k\right) $$

   imagen

** Algunos ejemplos

   "sum process"

   \begin{align}S_n &= X_1 + X_2 + \dots + X_n \\ &= S_{n-1} + X-n\end{align}

   where the $X_i$'s are an iid sequence of random variables and where $S_0
   = 0$. $S_n$ is a Markov process since

   \begin{align} P\left(S_{n+1} = s_{n+1} | S_n = s_n , \dots , S_1 = s_1 \right) &=
      P\left( X_{n+1} = s_{n+1} - s_n \right)\\ &= P\left( S_{n+1} = s_{n+1} | S_n
      = s_n \right)\end{align}

   "Poisson process"

   The Poisson process is a continuous-time Markov process since

   \begin{align} P\left( N(t_{k+1}) = j | N(t_k) = i, N(t_{k-1}) = x_{k-1},\dots, N(t_1) = x_1
   \right) &= P\left(j-i \text{ events in } t_{k+1}-t_k \text{ seconds}\right)\\ &=
   P\left(N(t_{k+1})=j|N(t_k)=i\right) \end{align}

** Cadenas de Markov

   Una *cadena de Markov* es un proceso de Markov que toma valores $X(t_k)$
   naturales.

   Propiedad de Markov: la *probabilidad conjunta* de un conjunto de variables
   aleatorias en distintos instantes de tiempo se obtiene como el *producto de
   la probabilidad inicial y las probabilidades de las transiciones
   subsiguientes*:

   \begin{align}
   P\left(X(t_{k+1}) = x_{k+1}, X(t_k) = x_k,\dots,X(t_1) = x_1\right) &=
   P\left(X(t_{k+1}) = x_{k+1} | X(t_k) = x_k\right) P\left(X(t_k) = x_k |
   X(t_{k-1}) = x_{k-1}\right) \dots P\left(X(t_1) = x_1\right)\\ &= \left\{
   \prod_{j=1}^{k} P\left(X(t_{j+1}=x_{j+1} | X(t_j) = x_j)\right)\right\}
   P\left(X(t_1) = x_1\right)\end{align}

** Cadenas de Markov en tiempo discreto

   Sea $X_n$ una cadena de Markov a valores enteros de tiempos discretos que
   comienza en $n=0$ con fpm

   $$ p_j(0) =^* P\left(X_0 = j\right) j=0,1,2,\dots$$

   Propiedad de Markov:

   $$P\left(X_n=i_n,\dots,X_0=i_0\right) = P\left(X_n = i_n | X_{n-1} =
   i_{n-1}\right) \dots P\left(X_1 = i_1 | X_0 = i_0\right) P\left(X_0 =
   i_0\right)$$

   Asumimos probabilidades de transiciones homogéneas (estacionariedad):

   $$P\left(X_{n+1} = j|X_n=i\right)=p_{ij} \forall n$$

   Matriz de probabilidades de transición:

   #+ATTR_latex: :mode math :environment pmatrix :align ccc
   $P = \begin{pmatrix}
   p_{00} & p_{01} & p_{02} & \dots \\
   p_{10} & p_{11} & p_{12} & \dots \\
   .      & .      & .      & .     \\
   p_{i0} & p_{i1} & p_{i2} & \dots \\
   .      & .      & .      & .     \\
   \end{pmatrix}$

   $$\displaystyle\sum_{j} P\left(X_{n+1} = j| X_n = i\right) =
   \displaystyle\sum_{j} p_{ij} = 1$$

   $$P\left(X_n = i_n,\dots,X_0=i_0\right) = p_{i_{n-1},i_n}
   ... p_{i_0,i_1}p_{i_0}$$

   La distribución conjunta de una cadena de Markov queda totalmente definida a
   partir de la matriz de transiciones y la condición inicial.

** Representación con grafos

   Nodos: estados
   Links: probabilidades de transición

   Ejemplos:
   Dos estados

   Tres estados

   Bernoulli counting process
   (infinitos estados - contables)

** Algunos ejemplos

   Bulbs in reserve
   Matriz de transiciones
   Grafo


   Binomial Counting Process
   Matriz de transiciones
   Grafo

** Probabilidades de transición en n pasos

   Sea $P(n) = \{p_{ij}(n)\}$ la matrix de transicion en n pasos, donde

   $$p_{ij}(n) = P\left( X_{n+k} = k| X_k=i\right)$$ $$ 0 \leq n,i,j$$

   En general, para 2 pasos: $$p_{ij}(2) = \displaystyle\sum_k
   p_{ij}(1)p_{kj}(1) \\ \forall i,j \longrightarrow P(2) = P(1)P(1)=P^2$$

   En general, para n pasos:
   $$P(n) = P^n$$

   Propagación de probabilidades de estados:
   \begin{align}
      p_{j}(n) &= \displaystyle\sum_i P\left(X_n = j| X_0=i\right)
      P\left( X_0 = i \right)\\ &= \displaystyle\sum_i p_{ij}(n)p_i(0)
   \end{align}

   y la notacion matricial es $$p(n) = p(0)P(n)=p(0)P^n $$ $$ n=1,2,...$$

   por lo tanto fpm de estado en el paso n se obtiene multiplicando la fpm del
   estado inicial por P^n.

** Análisis de ejemplo

   Bulbs in reserve

   Matriz de transiciones

   La probabilidad de que se acaben las lamparas de repuesto tiende a uno

** Comportamiento asintótico: ejemplo

   Dada la siguiente cadena de Markov, encontrar la matriz de transiciones
   asintótica

   diag

   $P=\begin{bmatrix}1-\alpha & \alpha\\ \beta & 1-\beta\end{bmatrix}$ $P^n
   \displaystyle\longrightarrow_{n \rightarrow \infty}$ ?

   Buscamos autovalores y autovectores de la matriz de transición $P$

   \begin{align}0 &= det(P-\lambda I) = \begin{vmatrix}1-\alpha-\lambda &\alpha\\\beta&1-\beta-\lambda\end{vmatrix} = (1-\lambda)(1-\alpha-\beta-\lambda)\\
     &= (1-\alpha-\lambda)(1-\beta-\lambda) - \alpha\beta\end{align}
   los autovalores de $P$ son 1 y $1-\alpha-\beta$


   $\mathbf{E}=[\mathbf{e}_1\mathbf{e}_2] = \begin{bmatrix}
   1&\alpha\\1&-\beta\end{bmatrix} \longrightarrow P = \mathbf{E}\Lambda
   \mathbf{E}^{-1} = \frac{1}{\alpha+\beta} \begin{bmatrix} 1 & \alpha\\1&-\beta
   \end{bmatrix} \begin{bmatrix} 1 & 0\\0 & 1-\alpha-\beta
   \end{bmatrix} \begin{bmatrix}\beta & \alpha \\ 1 &-1 \end{bmatrix}$

   $P^n = \mathbf{E}\Lambda^n\mathbf{E}^{-1} = \begin{bmatrix}
   \frac{\beta}{\alpha+\beta} & \frac{\alpha}{\alpha+\beta}
   \\ \frac{\beta}{\alpha+\beta} & \frac{\alpha}{\alpha+\beta}
   \end{bmatrix}+\frac{(1-\alpha-\beta)^n}{\alpha+\beta} \begin{bmatrix}\alpha &
   \alpha \\ -\beta & \beta \end{bmatrix}$

   Si $\alpha + \beta < 1$, entonces
   $\frac{(1-\alpha-\beta)^n}{\alpha+\beta} \begin{bmatrix}\alpha & \alpha
   \\ -\beta & \beta \end{bmatrix} \longrightarrow 0$

   $P^n = \begin{bmatrix} \frac{\beta}{\alpha+\beta} &
   \frac{\alpha}{\alpha+\beta} \\ \frac{\beta}{\alpha+\beta} &
   \frac{\alpha}{\alpha+\beta} \end{bmatrix}$


   $\mathbf{p}(n) = \begin{pmatrix}p_0(0) & 1-p_0(0)\end{pmatrix}P^n
   \longrightarrow \left(\frac{\beta}{\alpha+\beta},
   \frac{\alpha}{\alpha+\beta}\right)$

   Las probabilidades de estado no dependen de la condición inicial
   (asintóticamente)

** Comportamiento asintótico: teoría

   El comportamiento asintótico está determinado por el límite de la siguiente
   matriz:

   #+ATTR_latex: :mode math :environment pmatrix :align ccc
   $$P^n = \mathbf{E} \Lambda^n \mathbf{E}^{-1} =
   \mathbf{E} \begin{pmatrix}\lambda_1^n & 0 & \dots &0\\0 & \lambda_2^n & \dots
   & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \lambda_K^n
   \end{pmatrix} \mathbf{E}^{-1}$$

   $\lambda_k$: autovalores de $\mathbf{P}$

   $\mathbf{e}_k$: columnas de $\mathbf{E}$, autovectores de $\mathbf{P}$

   Ejercicio 1: demostrar que $\mathbf{e} = [1, 1, . . . , 1]^T$ y $\lambda=1$
   siempre son un autovector y un autovalor de $\mathbf{P}$, respectivamente.

   Proposición: Si los restantes $K-1$ autovalores de $\mathbf{P}$ cumplen
   $|\lambda_k| < 1$, entonces

   $P^n \longrightarrow \begin{pmatrix} 1\\1\\ \vdots \\ 1
   \end{pmatrix} \begin{bmatrix}\pi_1 & \pi_2 & \dots & \pi_K \end{bmatrix}$

   Independientemente de la condición inicial, la cadena de Markov converge a
   las *probabilidades asintóticas*: $\begin{bmatrix}\pi_1 & \pi_2 & \dots &
   \pi_K \end{bmatrix}$


   Donde $\begin{bmatrix}\pi_1 & \pi_2 & \dots & \pi_K \end{bmatrix}$ el vector
   de probabilidades de estados asintótico.

   Condición de *equilibrio* o *steady state* (si existe): $\mathbf{\pi} =
   \mathbf{\pi P} \quad \displaystyle\sum_{k=1}^K\pi_k=1$

** Usando la condición de equilibrio

   diag

   Usamos $\mathbf{\pi} = \mathbf{\pi P}$

   $$\pi_0 = (1-\alpha)\pi_0+\beta\pi_1$$
   $$\pi_1=\alpha\pi_0+(1-\beta)\pi_1$$

   que implica que $\alpha\pi_0 = \beta\pi_1 = \beta(1-\pi_0)$ ya que
   $\pi_0+\pi_1=1$

   $$\pi_0 = \frac{\beta}{\alpha+\beta} = \frac{2}{3}$$ $$\pi_1 =
   \frac{\alpha}{\alpha+\beta} = \frac{1}{3}$$

   Nota importante: Esto sólo vale si $|1-\alpha-\beta| < 1$ (condición de
   convergencia)

** Qué pasa si no se cumple la condición de convergencia?

   diag

   Por ejemplo $\alpha =\beta=1$ y suponemos que empezamos el proceso en estado
   0, esto es, $p_0(0)=1$

   Las probabilidades de estado en el momento $n$ son:

   $$\mathbf{p}(n)= \begin{pmatrix}p_0(0) & 1-p_0(0)\end{pmatrix} P^n
   = \begin{pmatrix}1&0\end{pmatrix} \begin{bmatrix}0&1\\1&0\end{bmatrix}^n$$

   En este caso el proceso alterna entre el estado 0 en instantes de tiempo
   pares y el estado 1 en instantes impares. $P^n$ no converge, y en cambio
   alterna tomando los valores $P$ y $P^2=I$. El vector de probabilidades de
   estado alterna entre los valores $\begin{pmatrix}1&0\end{pmatrix}$ y
   $\begin{pmatrix}0&1\end{pmatrix}$ por lo que no exhibe convergencia.

   Necesitamos más teoría para poder determinar convergencia !!

** Estados recurrentes y transitorios

   Estado recurrente: si el proceso retorna a ese estado con probabilidad igual
   a 1.

   $$\iff \displaystyle\sum_{n=1}^\infty p_{ii}(n) = \infty$$ Un estado
   recurrente se repite infinitas veces.

   Estado transitorio: si el proceso retorna a ese estado con probabilidad menor
   que 1.

   $$\iff \displaystyle\sum_{n=1}^\infty p_{ii}(n) < \infty$$ Un estado
   transitorio se repite un número finito de veces.

   Ejemplo:

   diag

   si el proceso comenzase en el estado 1

   $$p_{11}(n) = \frac{\beta + \alpha(1-\alpha-\beta)^n}{\alpha+\beta} =
   \frac{\frac{1}{2}+\frac{1}{4}(\frac{7}{10})^n}{\frac{3}{4}}$$

   $$\displaystyle\sum_{n=1}^\infty p_{11}(n) = \displaystyle\sum_{n=1}^\infty
   \left( \frac{2}{3}+\frac{\left(\frac{7}{10}\right)^n}{3} \right) = \infty$$


   el estado 0 es transitorio ya que $p_{00}(n) = \left( \frac{1}{2} \right)^n$,
   entonces

   $$\displaystyle\sum_{n=1}^\infty p_{00}(n) = \displaystyle\sum_{n=1}^\infty
   \frac{1}{2} \left( \frac{1}{2} \right)^2 + \left( \frac{1}{2} \right)^3 +
   \dots = 1 < \infty$$


** Clases de estados

   El estado $j$ es accesible desde el estado $i$ si $p_{ij}(n)>0$ para algún
   $n: i \rightarrow j$

   Los estados $j$ e $i$ están conectados si son accesibles el uno con el otro:
   $i \leftrightarrow j$

   *Clase*: conjunto de estados conectados entre sí.

   *Cadena de Markov irreducible*: cuando todos los estados forman una única
   clase.

   Ejemplos:

   diag

   Tres clases: $\{0\}$, $\{1,2\}$ y $\{3\}$


   diag
   Una clase: $\{0,1,2,3\}$
   Cadena irreducible

** Cadenas de Markov ergódicas

   Período: El estado $i$ tiene período $d$ si puede repetirse solamente en
   tiempos múltiplos de $d$, es decir, cuando $p_{ii}(n) = 0$ si $n$ no es
   múltiplo de $d$.

   Una cadena de Markov es *aperiódica* cuando todos sus estados tienen período
   $d=1$.

   diag

   proporcion de tiempo el en estado $i = \frac{k}{T_i(1)+T_i(2)+\dots+T_i(k)}
   \\ \rightarrow \frac{1}{E[T_i]} = \pi_i$

   Estado recurrente positivo: $E[T_i] < \infty (\pi_i > 0)$

   Estado recurrente nulo: $E[T_i] = \infty (\pi_i = 0)$

   Cadena de Markov ergódica: cuando es *irreducible*, *aperiódica* y
   *recurrente positiva*.

   Todos los estados de la cadena son visitados con frecuencia suficiente para
   que su probabilidad de visita sea distinta de cero.

   Una cadena ergódica converge a una distribución asintótica con probabilidades
   distintas de cero

** Algoritmo Google Page Rank (1)


** Algoritmo Google Page Rank (2)

   O resolviendo para el estado estacionario:

   $$ \mathbf{\pi} = \mathbf{\pi P} \text{ con } \displaystyle\sum_{k=1}^K
   \pi_k=1$$

   Nota importante: Este algoritmo simplificado de Google Page Rank tiene el
   problema que no garantiza que la cadena de Markov sea irreducible y
   aperiódica. Ver qué modificación es necesaria para garantizar una cadena
   ergódica (ver paper original).

* Material de Lectura
  - Libros (Mínimo):
    - [15] Probability, Statistics, and Random Processes for Eletrical
      Engineerging, 3rd_Ed. - Leon-Garcia., Cap 11.
    - [5] Intuitive Probability and Random Processes Using MatLab - Steven
      M. Kay, Cap 22.

  - Libros (opcional):
    - [16] Performance Modeling and Design of Computer Systems: Queueing Theory
      in Action, Mor Harchol-Balter,2013, Cap 8-10
    - [19] Introduction to probability models, Ross Sheldon, 2007, Cap 4.

  - Papers (opcional):
    - “The Anatomy of a Large-Scale Hypertextual Web Search Engine”, Sergey Brin
      and Lawrence Page, Computer Networks and IDSN Systems, 30 (1998),
      107 - 117.
 
 
 
 
 


             