#+title: Capa de Enlace: Intro, DOCSIS y ARP
6-6.1, 6.3-6.4.1

we naturally wonder how packets are sent across the individual links that make
up the end-to-end communication path.

How are the network-layer datagrams encapsulated in the link-layer frames for
transmission over a single link?

Are different link-layer protocols used in the different links along the
communication path?

How are transmission conflicts in broadcast links resolved?

Is there addressing at the link layer and, if so, how does the link-layer
addressing operate with the network-layer addressing we learned about in Chapter
4?

And what exactly is the difference between a switch and a router?

there are two fundamentally ­different types of link-layer channels. The first
type are broadcast channels, which connect multiple hosts in wireless LANs,
satellite networks, and hybrid fiber-coaxial cable (HFC) access networks. Since
many hosts are connected to the same broadcast communication channel, a
so-called medium access protocol is needed to coordinate frame transmission. In
some cases, a central controller may be used to coordinate transmissions; in
other cases, the hosts themselves coordinate transmissions.

The second type of link-layer channel is the point-to-point communication link,
such as that often found between two routers connected by a long-distance link,
or between a user’s office computer and the nearby Ethernet switch to which it
is connected. Coordinating access to a point-to-point link is simpler; the
reference material on this book’s Web site has a detailed discussion of the
Point-to-Point Protocol (PPP), which is used in settings ranging from dial-up
service over a telephone line to high-speed point-to-point frame transport over
fiber-optic links.

* Intro to the link layer

  node: any devicethat runs a link-layer protocol

  Nodes include hosts, routers, switches, and WiFiaccess points. We will also
  refer to the communication channels that connect adjacent nodes along the
  communication path as links

  imagen 6.1

** The Services Provided by the Link Layer

   Although the basic service of any link layer is to move a datagram from one node
   to an adjacent nodeover a single communication link, the details of the provided
   service can vary from one link-layerprotocol to the next.

*** Framing
    Almost all link-layer protocols encapsulate each network-layer datagram within a
    link-layer frame before transmission over the link. A frame consists of a data
    field, in which the network-layer datagram is inserted, and a number of header
    fields. The structure of the frame is specified by the link-layer
    protocol. We’ll see several different frame formats when we examine specific
    link-layer protocols in the second half of this chapter.

*** Link access
    A medium access control (MAC) protocol specifies the rules by which a frame is
    transmitted onto the link. For point-to-point links that have a single sender at
    one end of the link a nda single receiver at the other end of the link, the MAC
    protocol is simple (or nonexistent)—the sender can send a frame whenever the
    link is idle. The more interesting case is when multiple nodes share a single
    broadcast link—the so-called multiple access problem. Here, the MAC protocol
    serves to coordinate the frame transmissions of the many nodes.

*** Reliable delivery
    When a link-layer protocol provides reliable delivery service, it guarantees to
    move each network-layer datagram across the link without error. Recall that
    certain transport-layer protocols (such as TCP) also provide a reliable delivery
    service. Similar to a transport-layer reliable delivery service, a link-layer
    reliable delivery service can be achieved with acknowledgments and
    retransmissions (see Section 3.4). A link-layer reliable delivery service is
    often used for links that are prone to high error rates, such as a wireless
    link, with the goal of correcting an error locally—on the link where the error
    occurs—rather than forcing an end-to-end retransmission of the data by a
    transport- or application-layer protocol. However, link-layer reliable delivery
    can be considered an unnecessary overhead for low bit-error links, including
    fiber, coax, and many twisted-pair copper links. For this reason, many wired
    link-layer protocols do not provide a reliable delivery service.

*** Error detection and correction
    The link-layer hardware in a receiving node can incorrectly decide that a bit in
    a frame is zero when it was transmitted as a one, and vice versa. Such bit
    errors are introduced by signal attenuation and electromagnetic noise. Because
    there is no need to forward a datagram that has an error, many link-layer
    protocols provide a mechanism to detect such bit errors.

    This is done by having the transmitting node include error-detection bits in the
    frame, and having the receiving node perform an error check. Recall from
    Chapters 3 and 4 that the Internet’s transport layer and network layer also
    provide a limited form of error detection—the Internet checksum. Error detection
    in the link layer is usually more sophisticated and is implemented in
    hardware. Error correction is similar to error detection, except that a receiver
    not only detects when bit errors have occurred in the frame but also determines
    exactly where in the frame the errors have occurred (and then corrects these
    errors).

** Where Is the Link Layer Implemented?
   for the most part, the link layer is implemented in a network adapter, also
   sometimes known as a =network interface card (NIC)=. At the heart of the network
   adapter is the link-layer controller, usually a single, special-purpose chip
   that implements many of the link-layer services (framing, link access, error
   detection, and so on). Thus, much of a link-layer controller’s functionality is
   implemented in hardware.

   imagen 6.2

   On the sending side, the controller takes a datagram that has been created and
   stored in host memory by the higher layers of the protocol stack, encapsulates
   the datagram in a link-layer frame (filling in the frame’s various fields), and
   then transmits the frame into the communication link, following the link-access
   protocol.

   On the receiving side, a controller receives the entire frame, and extracts the
   network-layer datagram.

   If the link layer performs error detection, then it is the sending controller
   that sets the error-detection bits in the frame header and it is the receiving
   controller that performs error detection

   while most of the link layer is implemented in hardware, part of the link layer
   is implemented in software that runs on the host’s CPU. The software components
   of the link layer implement higher-level link-layer functionality such as
   assembling link-layer addressing information and activating the controller
   hardware.

   On the receiving side, link-layer software responds to controller
   interrupts (e.g., due to the receipt of one or more frames), handling error
   conditions and passing a datagram up to the network layer. Thus, the link layer
   is a combination of hardware and software—the place in the protocol stack where
   software meets hardware.

* Multiple Access Links and Protocols

  A =point-to-point link= consists of a single sender at one end of the link and a
  single receiver at the other end of the link. Many link-layer protocols have
  been designed for point-to-point links; the point-to-point protocol (PPP) and
  high-level data link control (HDLC) are two such protocols.

  a =broadcast link=, can have multiple sending and receiving nodes all connected
  to the same, single, shared broadcast channel. The term broadcast is used here
  because when any one node transmits a frame, the channel broadcasts the frame
  and each of the other nodes receives a copy. Ethernet and wireless LANs are
  examples of broadcast link-layer technologies.

  - the =multiple access problem= :: how to coordinate the access of multiple
    sending and receiving nodes to a shared broadcast channel

  Computer networks have protocols — so-called multiple access protocols — by
  which nodes regulate their transmission into the shared broadcast channel.

  When multiple nodes transmit frames on a channel at the same time, all of the
  nodes receive multiple frames at the same time; that is, the transmitted frames
  =collide= at all of the receivers. Typically, when there is a collision, none of
  the receiving nodes can make any sense of any of the frames that were
  transmitted. Thus, all the frames involved in the collision are lost, and
  the broadcast channel is wasted during the collision interval.

  It is the multiple access protocol's job to coordinate the transmission of the
  active nodes.

  we can classify just about any multiple access protocol as belonging to one of
  three categories:
  - channel partitioning protocols,
  - random access protocols, and
  - taking-turns protocols.

  desirable characteristics of a multiple-access-protocol for a broadcast channel
  of rate $R$ bits per second:
  1. When only one node has data to send, that node has a throughput of R bps.
  2. When M nodes have data to send, each of these nodes has a throughput of R/M
     bps. This need not necessarily imply that each of the M nodes always has an
     instantaneous rate of R/M, but rather that each node should have an average
     transmission rate of R/M over some suitably defined interval of time.
  3. The protocol is decentralized; that is, there is no master node that
     represents a single point of failure for the network.
  4. The protocol is simple, so that it is inexpensive to implement.


** Channel Partitioning Protocols

   N: number of nodes on the channel.

   R: transmission rate of the channel in bps.

*** Time Division Multiplexing (TDM)
    TDM divides time into =time frames= and further divides each time frame into
    N =time slots=.

    Each time slot is then assigned to one of the N nodes.

    Whenever a node has a packet to send, it transmits the packet’s bits during its
    assigned time slot in the revolving TDM frame.

    - Pros
      - Avoids collisions
      - Fair division of the bandwidth among the nodes
      - Each node gets a dedicated transmission rate of R/N bps during each frame
        time.
    - Cons
      - a node is limited to an average rate of R/N bps even when it is the only
        node with packets to send
      - a node must always wait for its turn in the transmission sequence even when
        it is the only node with packets to send

*** Frequency Division Multiplexing (FDM)
    FDM divides the R bps channel into different frequencies (each with a bandwidth
    of R/N) and assigns each frequency to one of the N nodes.

    FDM thus creates N smaller channels of R/N bps out of the single, larger R bps
    channel.

    - Pros
      - Avoids collisions
      - Fair division of the bandwidth among the nodes
      - Each node gets a dedicated transmission rate of R/N bps during each frame
        time.
    - Cons
      - a node is limited to an average rate of R/N bps even when it is the only
        node with packets to send

*** Code Division Multiple Access (CDMA)
    CDMA assigns a different code to each node.

    Each node then uses its unique code to encode the data bits it sends. If the
    codes are chosen carefully, CDMA networks have the property that different nodes
    can transmit simultaneously and yet have their respective receivers correctly
    receive a sender’s encoded data bits (assuming the receiver knows the sender’s
    code) in spite of interfering transmissions by other nodes.

** Random Access Protocols

   a transmitting node always transmits at the full rate of the channel

   When there is a collision, each node involved in the collision repeatedly
   retransmits its frame (that is, packet) until its frame gets through without a
   collision.

   The node retransmits the frame after waiting for a random delay independently
   from the other nodes and hopefully it will be able to send the frame into the
   channel without a collision.

*** Slotted ALOHA

    Assume the following:
    - All frames consist of exactly L bits.
    - Time is divided into slots of size L/R seconds (that is, a slot equals the
      time to transmit one frame).
    - Nodes start to transmit frames only at the beginnings of slots.
    - The nodes are synchronized so that each node knows when the slots begin.
    - If two or more frames collide in a slot, then all the nodes detect the
      collision event before the slot ends.

    Operation:
    - When the node has a fresh frame to send, it waits until the beginning of the
      next slot and transmits the entire frame in the slot.
    - If there isn’t a collision, the node has successfully transmitted its frame
      and thus need not consider retransmitting the frame. (The node can prepare a
      new frame for transmission, if it has one.)
    - If there is a collision, the node detects the collision before the end of the
      slot. The node retransmits its frame in each subsequent slot with probability
      $p$ until the frame is transmitted without a collision.

    allows a node to transmit continuously at the full rate, R, when that node is
    the only active node. (A node is said to be active if it has frames to send.)

    highly decentralized, because each node detects collisions and independently
    decides when to retransmit.

    however,it requires the slots to be synchronized in the nodes

    Slotted ALOHA works well when there is only one active node, but how ­efficient
    is it when there are multiple active nodes?

    imagen 6.10

    1. when there are multiple active nodes, a certain fraction of the slots will
       have collisions and will therefore be “wasted.”
    2. another fraction of the slots will be empty because all active nodes refrain
       from transmitting as a result of the probabilistic transmission policy.

    the only “unwasted” slots will be those in which exactly one node transmits. A
    slot in which exactly one node transmits is said to be a =successful slot=. The
    efficiency of a slotted multiple access protocol is defined to be the long-run
    fraction of successful slots in the case when there are a large number of active
    nodes, each always having a large number of frames to send.

    the maximum efficiency of the protocol is given by p=1/e=0,37.

    when a large number of nodes have many frames to transmit,then (at best) only 37
    percent of the slots do useful work. Thus the effective transmission rate of
    the channel is not R bps but only 0.37 R bps!

*** ALOHA

    The first ALOHA protocol was unslotted and fully decentralized.

    when a frame first arrives (that is, a network-layer datagram is passed down
    from the network layer at the sending node), the node immediately transmits the
    frame in its entirety into the broadcast channel.

    Si se detecta una colision, inmediatamente luego de transmitir el frame
    colisionado, se retransmite el frame con una probabilidad $p$. Si no se detecta
    colision, se transmite el proximo frame con probabilidad $p$.

    siempre se espera a que se termine de transmitir el frame.

    imagen 6.11

    the maximum efficiency of the protocol is given by p=1/(2e).

    La mitad de eficiencia que el protocolo slotted ALOHA. Esto es porque es
    totalmente descentralizado.

*** Carrier Sense Multiple Access (CSMA)

    - Listen before speaking :: If someone else is speaking, wait until they are
      finished. In the networking world, this is called =carrier sensing= —a node
      listens to the channel before transmitting. If a frame from another node is
      currently being transmitted into the channel, a node then waits until it
      detects no transmissions for a short amount of time and then begins
      transmission.

    - If someone else begins talking at the same time, stop talking :: In the
      networking world, this is called =collision detection= —a transmitting node
      listens to the channel while it is transmitting. If it detects that another
      node is transmitting an interfering frame, it stops transmitting and waits a
      random amount of time before repeating the sense-and-transmit-when-idle
      cycle.

    imagen 6.12

    From Figure 6.12, it is evident that the end-to-end =channel propagation delay=
    of a broadcast channel—the time it takes for asignal to propagate from one of
    the nodes to another—will play a crucial role in determining its
    performance. The longer this propagation delay, the larger the chance that a
    carrier-sensing node is not yet able to sense a transmission that has already
    begun at another node in the network.

*** Carrier Sense Multiple Access with Collision Detection (CSMA/CD)

    When a node performs collision detection, itceases transmission as soon as it
    detects a collision.

    imagen 6.13

    1. The adapter obtains a datagram from the network layer, prepares a link-layer
       frame, and puts the frame adapter buffer.
    2. If the adapter senses that the channel is idle (that is, there is no signal
       energy entering the adapter from the channel), it starts to transmit the
       frame. If, on the other hand, the adapter senses that the channel is busy, it
       waits until it senses no signal energy and then starts to transmit the frame.
    3. While transmitting, the adapter monitors for the presence of signal energy
       coming from other adapters using the broadcast channel.
    4. If the adapter transmits the entire frame without detecting signal energy
       from other adapters, the adapter is finished with the frame. If, on the other
       hand, the adapter detects signal energy from other adapters while
       transmitting, it aborts the transmission (that is, it stops transmitting its
       frame).
    5. After aborting, the adapter waits a random amount of time and then returns to
       step 2.

    Como se elije el tiempo de espera aleatorio?

    - =binary exponential backoff= algorithm :: when transmitting a frame that has
      already experienced $n$ collisions, a node chooses the value of $K$ at random
      from $\{0,1,2,2^{n-1}\}$

    example

    We define the =efficiency of CSMA/CD= to be the long-run fraction of time during
    which frames are being transmitted on the channel without collisions when there
    is a large number of active nodes, with each node having a large number of
    frames to send.

    let $d_{prop}$ denote the maximum time it takes signal energy to propagate
    between any two adapters.

    Let $d_{trans}$ be the time to transmit a maximum-size frame

    $$Efficiency = 11 + 5 * \frac{d_{prop}}{d_{trans}}$$

** Taking Turn Protocols

*** Polling Protocol

    The polling protocol requires one of the nodes to be designated as a master
    node. The master node polls each of the nodes in a round-robin fashion.

    In particular, the master node first sends a message to node 1, saying that it
    can transmit up to some maximum number of frames. After node 1 transmits some
    frames, the master node tells node 2 it can transmit up to the maximum number of
    frames. (The master node can determine when a node has finished sending its
    frames by observing the lack of a signal on the channel.)

    The procedure continues in this manner, with the master node polling each of the
    nodes in a cyclic manner.

    - Cons:
      - polling delay: amount of time required to notify a node that it can
        transmit.
      - if the master node fails, the channel becomes inioperative.

*** Token-passing protocol

    A small, special-purpose frame known as a =token= is exchanged among the
    nodes in some fixed order. When a node receives a token, it holds onto the
    token only if it has some frames to transmit; otherwise, it immediately
    forwards the token to the next node. If a node does have frames to transmit
    when it receives the token, it sends up to a maximum number of frames and
    then forwards the token to the next node. Token passing is decentralized and
    highly efficient. But for example, the failure of one node can crash the
    entire channel. Or if a node accidentally neglects to release the token,
    then some recovery procedure must be invoked to get the token back in
    circulation.

** Data-Over-Cable Service Interface Specifications (DOCSIS)

   Recall that a cable access network typically connects several thousand
   residential cable modems to a cable modem termination system (CMTS) at the
   cable network headend.

   DOCSIS uses FDM to divide the downstream (CMTS to modem) and upstream (modem
   to CMTS) network segments into multiple frequency channels.

   Each downstream channel is 6 MHz wide, with a maximum throughput of approximately
   40 Mbps per channel;

   Each upstream channel has a maximum channel width of 6.4 MHz, and a
   maximum upstream throughput of approximately 30 Mbps.

   Each channel (upstream and downstream) is a broadcast channel.

   Frames transmitted on the downstream channel by the CMTS are received by all
   cable modems receiving that channel; since there is just a single CMTS
   transmitting into the downstream channel, there is no multiple access
   problem.

   In the upstream direction, since multiple cable modems share the same
   upstream channel (frequency) to the CMTS, collisions can potentially occur.

   imagen 6.14

   each upstream channel is divided into intervals of time (TDM-like), each
   containing a sequence of mini-slots during which cable modems can transmit to
   the CMTS. The CMTS explicitly grants permission to individual cable modems to
   transmit during specific mini-slots by sending a
   control message known as a =MAP message= on a downstream channel to specify
   which cable modem (with data to send) can transmit during which mini-slot for
   the interval of time specified in the control message.

   mini-slots are allocated to cable modems, so there are no colliding
   transmissions during a mini-slot.

   to know which cable modems have data to send (and therefore, be assigned a
   mini-slot), the cable modems send mini-slot-request frames to the CMTS during
   a special set of interval mini-slots that are dedicated for this purpose.

   These mini-slot-request frames are transmitted in a random access manner and
   so may collide with each other. A cable modem can neither sense whether the
   upstream channel is busy nor detect collisions. Instead, the cable modem
   infers that its mini-slot-request frame experienced a collision if it does
   not receive a response to the requested allocation in the next downstream
   control message. When a collision is inferred, a cable modem uses binary
   exponential backoff to defer the retransmission of its mini-slot-request
   frame to a future time slot. When there is little traffic on the upstream
   channel, a cable modem may actually transmit data frames during slots
   nominally assigned for mini-slot-request frames (and thus avoid having to
   wait for a mini-slot assignment).

* Switched Local Area Networks

  imagen 6.15

  Figure 6.15 shows a switched local network connecting three departments, two
  servers and a router with four switches. Because these switches operate at the
  link layer, they switch link-layer frames (rather than network-layer
  datagrams), don’t recognize network-layer addresses, and don’t use routing
  algorithms to determine paths through the network of layer-2 switches. Instead
  of using IP addresses, we will soon see that they use link-layer addresses to
  forward link-layer frames through the network of switches.

** Link-Layer Addressing and ARP

*** Mac Addresses

    hosts and routers have adapters (network interfaces) which have a link-layer
    address.

    host or router with multiple network interfaces will thus have multiple
    link-layer addresses associated with it, just as it would also have multiple
    IP addresses associated with it. however, link-layer switches do not have
    link-layer addresses associated with their interfaces that connect to hosts
    and routers. This is because the job of the link-layer switch is to carry
    datagrams between hosts and routers; a switch does this job transparently,
    that is, without the host or router having to explicitly address the frame
    to the intervening switch.


    these address are called =LAN addresses=, =physical addresses= or =MAC
    addresses=, and are of 6 bytes long. They can be changed via software.

    no two adapters have the same address, because the ieee manages the mac
    address space. an adapter manufacturer can buy an address space of 2^{24}
    addresses, having an available space to manufacture 2^{24} adapters.

    An adapter’s MAC address has a flat structure (as opposed to a hierarchical
    structure) and doesn’t change no matter where the adapter goes.

    When an adapter wants to send a frame to some destination adapter, the
    sending adapter inserts the destination adapter’s MAC address into the frame
    and then sends the frame into the LAN.  As we will soon see, a switch
    occasionally broadcasts an incoming frame onto all of its interfaces.
    because frames are broadcasted to all adapters, an adapters has to check if
    a frame is addressed to it.  However, sometimes a sending adapter does want
    all the other adapters on the LAN to receive and process the frame it is
    about to send. In this case, the sending adapter inserts a special =MAC
    broadcast address= into the destination address field of the frame.

*** Address Resolution Protocol (ARP)

    imagen 6.17

    each host and router has a single IP address and single MAC address

    assume in this section that the switch broadcasts all frames; that is,
    whenever a switch receives a frame on one interface, it forwards the frame
    on all of its other interfaces.

    uppose that the host with IP address 222.222.222.220 wants to send an IP
    datagram to host 222.222.222.222. In this example, both the source and
    destination are in the same subnet.

    To send a datagram, the source must give its adapter not only the IP
    datagram but also the MAC address for destination 222.222.222.222. The
    sending adapter will then construct a link-layer frame containing the
    destination’s MAC address and send the frame into the LAN.

    But how does the sending host, know the MAC address of destination host?

    The solution is ARP. n ARP module in the sending host takes any IP address
    on the same LAN as input, and returns the corresponding MAC address.

    ARP resolves an IP address to a MAC address for hosts and router interfaces
    in the same subnet.

    Each host and router has an =ARP table= in its memory, which contains
    mappings of IP addresses to MAC addresses.

    imagen 6.18
    |      IP Address | MAC Address       |      TTL |
    | 222.222.222.221 | 88-B2-2F-54-1A-0F | 13:45:00 |
    | 222.222.222.223 | 5C-66-AB-90-75-B1 | 13:52:00 |

    The ARP table also contains a time-to-live (TTL) value, which indicates when
    each mapping will be deleted from the table. Note that a table does not
    necessarily contain an entry for every host and router on the subnet; some
    may have never been entered into the table, and others may have expired.

    if the ARP table doesn’t currently have an entry for the destination, the
    sender uses the ARP protocol to resolve the address. First, the sender
    constructs a special packet called an =ARP packet=. An ARP packet has
    several fields, including the sending and receiving IP and MAC
    addresses. Both ARP query and response packets have the same format. The
    purpose of the ARP query packet is to query all the other hosts and routers
    on the subnet to determine the MAC address corresponding to the IP address
    that is being resolved.

    the query ARP message is sent within a broadcast frame, whereas the response
    ARP message is sent within a standard frame.

    ARP is plug-and-play; that is, an ARP table gets built ­automatically—it
    doesn’t have to be configured by a system administrator. And if a host
    becomes disconnected from the subnet, its entry is eventually deleted from
    the other ARP tables in the subnet.

    ARP is a protocol that arguably lies in between the link layer and the
    network layer.

*** Sending a datagram off the subnet

    imagen 6.19

    Each host has exactly one IP address and one adapter.

    Each router has an IP address for each of its interfaces. For each router
    interface there is also an ARP module (in the router) and an adapter.

    Because the router in Figure 6.19 has two interfaces, it has two IP addresses,
    two ARP modules, and two adapters. Of course, each adapter in the network has
    its own MAC address

    El adaptador del nodo que envia, debe completar en el frame de capa de enlace,
    la direccion MAC de el router que conecta a las subredes. Esto se conoce por
    ARP. Una vez que el datagrama llega al router, este lo acepta porque esta
    destinado para el mismo. El router inspecciona el paquete y observa que el
    paquete (de capa de red) IP esta destinado a una IP de la otra subred.  El
    router inspecciona en la tabla ARP para obtener la direccion MAC del nodo
    receptor, y como direccion MAC de origen del nuevo datagrama, coloca la
    direccion MAC del adaptador conectado a la subred destino.
