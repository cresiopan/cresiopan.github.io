#+title:Variables aleatorias: Momentos
* Esperanza
La información relevante sobre el comportamiento de una variable
aleatoria está contenida en su función de distribución. Sin embargo,
en la práctica, es útil disponer de algunos números representativos de
la variable aleatoria que resuman esa información.
**** Motivación
Se gira una rueda de la fortuna varias veces. En cada giro se puede
obtener alguno de los siguiente números x_1, x
2
, \dots , x
k
-que representan la cantidad de dinero que se obtiene en el giro- con probabilidades p(x
1
), p(x
2
), \dots , p(x
k
), respectivamente. ¿Cuánto dinero
se /espera"/obtener como recompensa /"por cada giro"/ ? Los términos /"espera/ y /"por cada
giro"/son un tanto ambiguos, pero se pueden interpretar de la siguiente manera.
Si la rueda se gira n veces y n(x
i
) es la cantidad de veces que se obtiene x
i
, la cantidad total
de dinero recibida es
P
k
{i=1}
n (x
i
)x
i
y la cantidad media por giro es \mu =
1
n
P
k
{i=1}
n (x
i
)x
i
. Interpretando las probabilidades como frecuencias relativas obtenemos que para n suficientemente
grande l a cantidad de dinero que se /espera"/recibir /"por cada giro/ es
\mu =}
1
n
k
X
{i=1}
x
i
n (x
i
) =
k
X
{i=1}
x
i
n (x
i
)
n
\approx
k
X
{i=1}
x
i
p (x
i
).
2
** Definición
**** Definición 1.1 (Esperanza de una variable discreta)
Sea X una variable aleatoria discreta.
La esperanza de X, denotada por E[X], es el promedio ponderado
E[X] :=
X
x \in A
x{\mathbb{P}(X = x) , (1)
donde A = \{x \in \Re : F (x) − F (x{−}) > 0{\} es el conjunto de todos los átomos de la función
distribución de X.
**** Ejemplo 1.2 (Esperanza de la función indicadora)
Sea$(\Omega, \mathcal{A}, \mathbb{P})$un espacio de probabilidad.
Para cualquier evento A \in A vale que
E[1\{\omega \in A\] = 0 · (1 −} \mathbb{P}(A)) + 1 · \mathbb{P}(A) = \mathbb{P}(A). (2)
La esperanza como centro de gravedad. La noción de esperanza es análoga a la noción}
de centro de gravedad para un sistema de partículas discreto.
Se consideran n partículas ubicadas en los puntos x
1
, \dots , x
n
cuyos pesos respectivos son
p (x
1
), \dots , p(x
n
). No se pierde generalidad si se supone que
P
n
{i=1}
p (x
i
) = 1. El centro de
gravedad, c, del sistema es el punto respecto de la cual la suma de los momentos causados
por los pesos p(x
i
) es nula. Observando que
k
X
{i=1}
(x
i
− c) p (x}
i
) = 0 \iff c =
k
X
{i=1}
x
i
p (x
i
)
resulta que el centro de gravedad del sistema coincide con la esperanza de una variable aleato
ria X a valores en \{x}
1
, \dots , x
n
\} tal que \mathbb{P}(X = x}
i
) = p(x
i
).
1 3 6 10
c
Figura 1: Interpretación de la esperanza como centro de gravedad. Se considera un sis
tema de cuatro /partículas/ de pesos p
i
proporcionales a las áreas de los círculos de radio
1 / 3, 2 / 3, 3 / 3, 4 / 3 centrados en los puntos x
i
= 1, 3, 6, 10, respectivamente. No se pierde gen
eralidad si se supone que el peso total del sistema es la unidad. El centro de gravedad del
sistema se encuentra en el punto c =
P
4
{i=1}
x
i
p
i
= 227 / 30 = 7.56 \dots}
3
La esperanza como promedio. Sea X una variable aleatoria a valores x}
1
, \dots , x
n
con
función de probabilidades
\mathbb{P}(X = x) =}
1
n
1\{x \in \{x}
1
, \dots , x
n
\\}.
Conforme a la Definición 1.1 la esperanza de X es
E[X] =}
n
X
{i=1}
x
i
\mathbb{P}(X = x}
i
) =
1
n
n
X
{i=1}
x
i
. (3)
Dicho en palabras: la esperanza de una variable aleatoria uniformemente distribuida sobre los
valores x
1
, x
2
, \dots , x
n
coincide con el promedio de dichos valores.
**** Ejemplo 1.3 (Dado equilibrado).
Sea X el resultado del lanzamiento de un dado equilibrado.
De acuerdo con (3) l a esperanza de X es
E[X] =}
1
6
6
X
{x=1}
x =}
21
6
=
7
2
.
**** Ejemplo 1.4 (Uniforme sobre el /intervalo/ \1, 2, \dots , n{\})
La variable aleatoria del Ejemplo}
1.3 es un caso particular de una variable aleatoria discreta X uniformemente distribuida sobre
el /i ntervalo/ de números enteros \1, 2, \dots , n{\} . De acuerdo con (3) la esperanza de X es
E[X] =}
1
n
n
X
{x=1}
x =}
1
n

n (n + 1)
2

=
1 + n
2
.
**** Ejemplo 1.5 (Moneda equilibrada).
Sea N la cantidad de veces que debe lanzarse una mon
eda equilibrada hasta que salga cara. N es una variable aleatoria discreta a valores 1, 2, \dots tal
que \mathbb{P}(N = n) = (1 / 2)
n
, n = 1, 2, \dots . De acuerdo con la definición 1.1, la esperanza de N es
E[N] =}
\infty
X
{n=1}
n{\mathbb{P}(N = n) =}
\infty
X
{n=1}
n

1
2

n
.
Derivando ambos lados de la igualdad
P
\infty
{n=0}
x
n
= (1 −x)
−{1}
, que vale para |x| < 1, se deduce
que
P
\infty
{n=0}
nx
n{−{1
= (1 − x)
−{2}
y de allí resulta que
P
\infty
{n=1}
nx
n
= x(1 − x)
−{2}
. Evaluando en
x = 1}/{2 se obtiene que}
E[N] =}
\infty
X
{n=1}
n

1
2

n
=

1
2

1
2

−{2}
= 2.
La noción de esperanza se extiende a variables aleatorias absolutamente continuas cam}
biando en (1) la suma por la integral y la función de probabilidades \mathbb{P}(X = x), x \in A}, por la
densidad de probabilidades de la variable X.
4
**** Definición 1.6 (Esperanza de una variable absolutamente continua)
Sea X una variable}
aleatoria absolutamente continua con densidad de probabilidades f_X(x). La esperanza de X,
denotada por E[X], se define por
E[X] :=}
Z
\infty
−\infty
xf_X(x)dx. (4)
**** Ejemplo 1.7 (Fiabilidad).
Sea T el tiempo de espera hasta que ocurre la primer falla en un}
sistema electrónico con función intensidad de fallas de la forma \lambda(t) = 2{t{1{\}t > 0{\}. La función
de distribución de T es F}
T
(t) =

1 − exp

−t
2

1\{t > 0} \. En consecuencia, T es una variable
aleatoria absolutamente continua con densidad de probabilidad f
T
(t) = 2t exp

−t
2

1\{t > 0}\}.
De acuerdo con l a definición 1.6, la esperanza de T es
E[T ] =}
Z
\infty
−\infty
tf
T
(t)dt =
Z
\infty
0
t{2}t exp(−} t
2
)dt =
Z
\infty
0
exp(−t}
2
)dt =
\sqrt{}
\pi
2
.
La tercera igualdad se deduce de la fórmula de integración por partes aplicada a u = t y
v
′
= 2t exp(−t}
2
) y la cuarta se deduce de la identidad
R
\infty
0
exp(−x}
2
/{2)dx =}
\sqrt{}
2{\pi/}2 mediante
el c ambio de variables t = x/}
\sqrt{}
2.
Extendiendo la noción a variables mixtas. La no c
ión de esperanza para variables}
mixtas se obtiene combinando las nociones anteriores.
**** Definición 1.8 (Esperanza de una variable mixta)
Sea X una variable aleatoria mixta con}
función de distribución F}
X
(x). La esperanza de X, denotada por E[X], se define de la siguiente
manera:
E[X] :=}
X
x{\inA}
x{\mathbb{P}(X = x) +}
Z
\infty
−\infty
xF
′
X
(x)dx, (5)
donde A = \{x \in \Re : F}
X
(x) − F
X
(x{−}) > 0{\} es el conjunto de todos los átomos de F}
X
(x) y
F
′
X
(x) es una función que coincide con la derivada de F}
X
(x) en todos los puntos donde esa
función es derivable y vale 0 en otro lado.
**** Ejemplo 1.9 (Mixtura).
Sea X una variable aleatoria mixta cuya función de distribución es}
F_X(x) =

2x+5
8

1\{−{1 \leq x < 1}\} + 1\{x \geq 1}\. De acuerdo con la fórmula (5), la esperanza de
X es}
E[X] = −}1 · \mathbb{P}(X = −}1) + 1 · \mathbb{P}(X = 1) +}
Z
1
−{1}
F
′
X
(x)dx = −}
3
8
+
1
8
+
Z
1
−{1}
2
8
dx =}
1
4
.
**** Nota Bene
En todas las definiciones anteriores, se presupone que las series y/o integrales}
involucradas son absolutamente convergentes.
**** Ejemplo 1.10
(Distribución de Cauchy). Sea X una variable aleatoria con distribución de
Cauchy. Esto es, X es absolutamente continua y admite una densidad de probabilidades de}
la forma
f (x) =}
1
\pi(1 + x
2
)
.
5
Debido a que
Z
\infty
−\infty
|x|{f (x) dx =
Z
\infty
−\infty
|x|
\pi(1 + x
2
)
dx = \infty},
X no tiene esperanza.
**** Teorema 1.11.
Sea X una variable aleatoria no negativa (i.e., F_X(x) = \mathbb{P}(X \leq x) = 0 para
todo x < 0). Vale que
E[X] =}
Z
\infty
0
[1 − F_X(x)] dx. (6)
**** Demostración
El argumento principal está contenido en la Figura 2. E l caso general se}
deduce usando téc nicas de /paso al límite/  .
p
2
p
3
p
k
1
x
1
p
1
p
k{−{1
x
2
x
3
x
k{−{1
x
k
0
Figura 2: Argumento geométrico que muestra la validez de la identidad (6) en e l caso en que
X es no negativa, discreta y a valores 0 \leq x
1
< x
2
< \cdots < x
k
. Si p
i
= \mathbb{P}(X = x
i
), el área
de la región sombreada es la suma x
1
p
1
+ \cdots + x
k
p
k
= E[X] de las áreas de los rectángulos
horizontales y coincide con la integral de la altura \mathbb{P}(X > x).
**** Corolario 1.12.
Sea X una variable aleatoria con función de distribución F_X(x). Vale que
E[X] =}
Z
\infty
0
[1 − F_X(x)] dx −
Z
0
−\infty
F_X(x)dx. (7)
**** Demostración
Ejercicio.
6
**** Nota Bene
Las identidades (6) y (7) son interesantes porque muestran que para calcular}
la esperanza de una variable aleatoria basta conocer su función de distribución. De hecho, la
identidad (7) ofrece una definición alternativa y unificada de la noción de esperanza.
**** Ejemplo 1.13.
Una máquina fue diseñada para prestar servicios en una instalación produc
tiva. La máquina se enciende al iniciar la jornada laboral y se apaga al finalizar la misma. Si
durante ese perío do la máquina falla, se la repara y en esa tarea se consume el resto de la
jornada.
Suponiendo que la función intensidad de fallas de la máquina es una constante \lambda > 0 (y
que el tiempo se mide en jornadas laborales), hallar el máximo valor de \lambda que permita asegurar
con una probabilidad mayor o igual que 2/3 que la máquina prestará servicios durante una
jornada laboral completa. Para ese valor de \lambda, hallar (y graficar) la función de distribución
del tiempo, T , de funcionamiento de la máquina durante una jornada laboral y calcular el
tiempo medio de funcionamiento, E[T ].
Solución. Si T_1
es el tiempo que transcurre desde que se enciende la máquina hasta que
ocurre la primer falla, el evento /la máquina funciona durante una jornada laboral completa/
se describe mediante \{T_1
> 1{\}. Queremos hallar el máximo \lambda > 0 tal que \mathbb{P}(T_1
> 1) \geq 2}/{3.
Debido a que la función intensidad de fallas es una constante \lambda se tiene que \mathbb{P}(T}
1
> t) = e
−{\lambda t}
.
En consecuencia, \mathbb{P}(T}
1
> 1) \geq 2}/{3 \iff e
− \lambda
\geq 2 / 3 \iff \lambda \leq −{log(2 / 3). Por lo tanto,}
\lambda = −}log (2}/{3). En tal caso, \mathbb{P}(T > 1) = 2}/{3.
0
1 / 3
1
1
Figura 3: Gráfico de la función de distribución de T .
El tiempo de funcionamiento de la máquina por jornada laboral es T = mín\{T_1
, 1{\}. Para}
t > 0 vale que}
F
T
(t) = \mathbb{P}(T \leq t) = 1 −\mathbb{P}(T > t) = 1 − \mathbb{P}(mín\{T_1
, 1{\} > t)
= 1 − \mathbb{P}(T}
1
> t)1{\}1 > t{\} = 1 − e
log(2 / 3)t_1\{t < 1}\}
=

1 − e}
log(2 / 3)t

1\{0 \leq t < 1}\} + 1\{t \geq 1\}.
7
Como T > 0 y conocemos la función \mathbb{P}(T > t) lo más sencillo para calcular la esperanza
es usar l a fórmula E[T ] =
R
\infty
0
\mathbb{P}(T > t)dt}:}
E[T ] =}
Z
\infty
0
\mathbb{P}(T > t)dt =}
Z
1
0
e
log(2 / 3)t
dt =}
e
log(2 / 3)t
log(2 / 3)





1
0
=
2 / 3 − 1
log(2 / 3)
=
−{1 / 3}
log(2 / 3)
\approx 0.822\dots}
** Cálculo
Sea X una variable aleatoria cuya función de distribución conocemos. Queremos calcular
la esperanza de alguna función de X, digamos, g(X). ¿Cómo se puede efectuar ese cálculo?
Una manera es la siguiente: (1) Hallamos la función de distribución de la variable aleatoria
Y = g (X) a partir del conocimiento que tenemos sobre la distribución de X:}
F_Y(y) := \mathbb{P}(Y \leq y) = \mathbb{P}(g(X) \leq y) = P

X \in g
−{1}
(−\infty, y]

.
(2) Usando la distribución de Y calculamos la esperanza E[g(X)] = E[Y ] por definición.
**** Ejemplo 1.14.
Sea X una variable aleatoria discreta tal que \mathbb{P}(X = 0) = 0.2, \mathbb{P}(X = 1) = 0.5}
y \mathbb{P}(X = 2) = 0.3. Queremos calcular E[X_2
]. Poniendo Y = X_2
obtenemos una variable
aleatoria a valores en \0
2
, 1}
2
, 2}
2
\} tal que \mathbb{P}(Y = 0) = 0.2 \mathbb{P}(Y = 1) = 0.5 y \mathbb{P}(Y = 4) = 0.3.
Por definición, E[X_2
] = E[Y ] = 0(0.2) + 1(0.5) + 4(0.3) = 1.7.
**** Ejemplo 1.15.
Sea X una variable aleatori a con distribución uniforme sobre el intervalo}
(0, 1). Queremos calcular E[X
3
]. Ponemos Y = X
3
y calculamos su función de distribución:
para cada 0 < y < 1 vale que F}
Y
(y) = \mathbb{P}(Y \leq y) = \mathbb{P}(X
3
\leq y) = \mathbb{P}(X \leq y
1 / 3
) = y
1 / 3
.
Derivando F}
Y
(y) obtenemos la densidad de probabilidad de Y : f_Y(y) =
1
3
y
−{2 / 3}
1\{0 < y < 1\}.
Por definición,
E[X}
3
] = E[Y ] =
Z
\infty
−\infty
yf_Y(y)dy =
Z
1
0
y
1
3
y
−{2 / 3}
dy =}
1
3
Z
1
0
y
1 / 3
dy =}
1
3
3
4
y
4 / 3




1
0
=
1
4
.
**** Nota Bene
Existe una manera mucho más simple para calcular la esperanza de Y = g(X)
que no recurre al procedimiento de determinar primero la distribución de Y para luego calcular
su esperanza por definición. El Teorema siguiente muestra cómo hacerlo.
**** Teorema 1.16.
Sea X una variable aleatoria y sea g : R \rightarrow \Re una función tal que g(X)
también es una variable aleatoria.
(a) Si X es discreta con átomos en el conjunto A, entonces
E[g(X)] =}
X
x{\inA}
g (x)\mathbb{P}(X = x) . (8)
(b) Si X es continua con densidad de probabilidad f_X(x) y g(X) es continua, entonces
E[g(X)] =}
Z
\infty
−\infty
g (x) f_X(x)dx. (9)
8
(c) Si X es mixta,
E[g(X)] =}
X
x{\inA}
g (x)\mathbb{P}(X = x) +}
Z
\infty
−\infty
g (x) F
′
X
(x)dx, (10)
donde A es el conjunto de todos los átomos de F}
X
(x) y F}
′
X
(x) es un función que coincide
con la derivada de F}
X
(x) en todos los puntos donde esa función es derivable y vale cero en
otro lado.
**** Demostración
Para simplificar la demostración supondremos que g \geq 0.
(a) Por el Teorema 1.11 tenemos que
E[g(X)] =}
Z
\infty
0
\mathbb{P}(g(X) > y)dy =}
Z
\infty
0
X
x{\inA}
1\{g (x) > y}\\mathbb{P}(X = x)
!
dy
=
X
x{\inA}

Z
\infty
0
1\{g (x) > y}\dy

\mathbb{P}(X = x) =}
X
x{\inA}
g (x)\mathbb{P}(X = x) .
(b) Por el Teorema 1.11 tenemos que
E[g(X)] =}
Z
\infty
0
\mathbb{P}(g(X) > y)dy =}
Z
\infty
0
Z
\{x{: g (x) >y\}
f (x) dx
!
dy
=
Z
\infty
−\infty
Z
g (x)
0
dy
!
f (x) dx =}
Z
\infty
−\infty
g (x) f (x) dx.
(c) Se obtiene combinando adecuadamente los resultados (a) y (b).
**** Ejemplo 1.17.
Aplicando la parte (a) del Teorema 1.16 al Ejemplo 1.14
se obtiene}
E[X}
2
] = 0
2
(0.2) + 1
2
(0.5) + 2
2
(0.3) = 1.7.
**** Ejemplo 1.18.
Aplicando la parte (b) del Teorema 1.16 al Ejemplo 1.15
se obtiene}
E[X}
3
] =
Z
1
0
x
3
dx =}
1
4
.
**** Teorema 1.19 (Cálculo de Esperanzas)
Sea X un vector aleatorio y sea g : \Re}
n
\rightarrow \Re una
función tal que g(X) es una variable aleatoria. Si la variable aleatoria g(X) tiene esperanza
finita, entonces
E[g(X)] =}



P
x
g(x)p
X
(x) en el caso discreto,
R
R
n
g(x)f_X(x) dx en el caso continuo,
donde, según sea el caso, p
X
(x) y f_X(x) son la función de probabilidad y la densidad conjunta
del vector X, respectivamente.
9
\hypertarget{pfa}
**** Demostración
Enteramente análoga a la que hicimos en dimensión 1.
Sobre el cálculo de esperanzas. El Teorema 1.19 es una herramienta práctica para}
calcular esperanzas. Su resultado establece que si queremos calcular la esperanza de una
transformación unidimensional del vector X, g(X), no neces itamo s calcular la distribución
de g(X). La esperanza E[g(X)] puede calcularse directamente a partir del conocimiento de la
distribución conjunta de X.
**** Corolario 1.20 (Esp eranza de las marginales).
Sea X = (X}
1
, \dots , X
n
) un vector aleatorio.
Si la variable X
i
tiene esperanza finita, entonces
E[X}
i
] =



P
x
x
i
p
X
(x) en el caso discreto,
R
R
n
x
i
f_X(x) dx en el caso continuo.
** Propiedades
(a) Si X = 1, entonces E[X] = 1.
(b) Monotonía. Si X_1
y X_2
son dos variables aleatorias tales que X_1
\leq X_2
, entonces
E[X}
1
] \leq E[X_2
].
(c) Si X es una variable aleatoria tal que E[X
n
] es finita y a
0
, a
1
, \dots , a
n
son constantes,
entonces
E
"
n
X
{k=0}
a
k
X
k
\#
=
n
X
{k=0}
a
k
E[X}
k
]. (11)
(d) Linealidad. Si las variables aleatorias X_1
, \dots , X
n
tienen esperanza finita y a
1
, a
2
, \dots , a
n
son constantes, entonces
E
"
n
X
{i=1}
a
i
X
i
\#
=
n
X
{i=1}
a
i
E[X}
i
]. (12)
(e) Regla del producto independiente. Si l as variables aleatorias X_1
, \dots , X
n
tienen esper
anza finita y son independientes, entonces el producto tiene esperanza finita y coincide con
el producto de las esperanzas:
E
"
n
Y
{i=1}
X
i
\#
=
n
Y
{i=1}
E[X}
i
]. (13)
**** Demostración
(a) es consecuencia inmediata de la Definición 1.1 porque \mathbb{P}(X = 1) = 1.
(b) es consecuencia del Teorema 1.11 y de que para todo x \in \Re vale que F}
X_1
(x) \geq F
X_2
(x).
(c) es c onsecuencia inmediata del Teorema 1.16. (d) es consecuencia inmediata del Teorema
1.19. (e) es consecuencia del Teorema 1.19 y de la factorización de la distribución conjunta
como producto de las distribuciones marginales.
10
\hypertarget{pfb}
** Dividir y conquistar
**** Teorema 1.21.
Sea$(\Omega, \mathcal{A}, \mathbb{P})$un espacio de probabilidad y sea X : \Omega \rightarrow \Re  una variable}
aleatoria. Sea A \subset \Re un conjunto tal que \{X \in A\} = \{\omega \in \Omega : X(\omega) \in A\} \in A}. Si
\mathbb{P}(X \in A) > 0, entonces}
E[X | X \in A] =}
1
\mathbb{P}(X \in A)
E[X{1{\}X \in A{\]. (14)
**** Demostración
Para simplificar la exposición vamos a suponer que la variable aleatoria X}
es discreta. Por la Definición 1.1 tenemos que
E[X | X \in A] =}
X
{x \in X(\Omega)}
xp
X | {X \in A}
(x) =
X
{x \in X(\Omega)}
x
\mathbb{P}(X = x)
\mathbb{P}(X \in A)
1\{x \in A\}
=
1
\mathbb{P}(X \in A)
X
{x \in X(\Omega)}
x{1{\}x \in A{\\mathbb{P}(X = x) =}
1
\mathbb{P}(X \in A)
E[X{1{\}X \in A{\].
La última igualdad es consecuencia del Teorema 1.16.
**** Ejemplo 1.22.
Sea X el resultado del tiro de un dado equilibrado y sea A = \2, 4, 6{\}. De}
acuerdo con (14) la esperanza de X | X \in A es
E[X | X \in A] =}
1
\mathbb{P}(X \in A)
E[X{1{\}X \in A{\] =}
1
1 / 2

2
6
+
4
6
+
6
6

= 4.
Resultado que por otra parte es intuitivamente evidente.
**** Teorema 1.23 (Fórmula de probabilidad total)
Sea X una variable aleatoria. Si A}
1
, \dots , A_n
es una partición medible de R tal que \mathbb{P}(X \in A}
i
) > 0, i = 1, \dots , n}. Entonces,
E[X] =}
n
X
{i=1}
E[X | X \in A_i
]\mathbb{P}(X \in A}
i
). (15)
**** Demostración
Descomp onemos la variable X como una suma de variables (dependientes}
de la partición) X =
P
n
{i=1}
X{1{\}X \in A_i
\. Como la esperanza es un operador lineal tenemos}
que
E[X] =}
n
X
{i=1}
E[X{1{\}X \in A_i
\] =}
n
X
{i=1}
E[X | X \in A_i
]\mathbb{P}(X \in A}
i
).
La última igualdad se obtiene de (14).
**** Nota Bene
Sea g : R \rightarrow \Re una función tal que g(X) es una variable aleatoria. Bajo las}
hipótesis del Teorema 1.23 también vale que
E[g(X)] =}
n
X
{i=1}
E[g(X)|X \in A_i
]\mathbb{P}(X \in A}
i
). (16)
La fórmula (16) se puede extender sin ninguna dificultad al caso multidimensional.
11
\hypertarget{pfc}
**** Ejemplo 1.24
(Dividir y conquistar). Todas las mañanas Lucas llega a la estación del subte}
entre las 7:10 y las 7:30 (con distribución uniforme en el intervalo). El subte llega a la estación
cada quince minutos comenzando a las 6:00. Calcular la media del tiempo que tiene que esperar
Lucas hasta subirse al subte.
Sea X el horario en que Lucas llega a la estación del subte. El tiempo que tiene que esperar
hasta subirse al subte se descri be por
T = (7.15 − X)1{\}X \in [7 : 10}, 7 : 15]\} + (7 : 30 − X)1{\}X \in (7 : 15}, 7 : 30]\} .
Ahora bien, dado que X \in [7 : 10, 7 : 15], la distribución de T es uniforme sobre el intervalo
[0, 5] minutos y dado que X \in (7 : 15, 7 : 30] la distribución de T es uniforme sobre el intervalo
[0, 15] minutos. De acuerdo con (16)
E[T ] =}
5
2

5
20

+
15
2

15
20

= 6.25.
* Varianza
** Definición
La esperanza de una variable aleatoria X, E[X], también se conoce como la media o el
primer momento de X. La cantidad E[X
n
], n \geq 1, se llama el n{-ésimo momento de X. Si la
esperanza E[X] es finita, la cantidad E[(X − E [X])
n
] se ll ama el n -ésimo momento central.}
Después de la esper anza la siguiente cantidad en orden de importancia para resumir el
comportamiento de una variable aleatoria X es su segundo momento central también llamado
la varianza de X}.
**** Definición 2.1 (Varianza)
Sea X una variable aleatoria con esperanza finita. La varianza
de X se define por
V(X) := E

(X − E [X])
2

. (17)
En otras palabras, la varianza de X es la esperanza de la variable aleatoria (X − E [X])
2
.
Puesto que (X − E [X])
2
sólo puede tomar valores no negativos, la varianza es no negativa.
La varianza de X es una de las formas más utilizadas para medir la dispersión de los
valores de X respecto de su media. Otra medida de dispersión es el desvío estándar de X,
que se define como la raíz cuadrada de la varianza y se denota \sigma(X):
\sigma (X) :=}
p
V(X). (18)
A diferencia de la varianza, el desvío estándar de una variable aleatoria es más fácil de
interpretar porque tiene las mismas unidades de X.
**** Nota Bene
Grandes valores de V(X) significan grandes variaciones de los valores de X}
alrededor de la media. Al contrario, pequeños valores de V(X) implican una pronunciada
concentración de la masa de la distribución de probabilidades en un entorno de la media. En
el caso extremo, cuando la varianza es 0, la masa total de la distribución de probabilidades se
concentra en la media. Estas afirmaciones pueden hacerse más precisas y serán desarrolladas
en la sección 4.
12
\hypertarget{pfd}
** Cálculo
Una manera /brutal/ de calcular V(X) es calcular la función de distribución de la variable
aleatoria (X − E [X])
2
y usar la definición de esperanza. En lo que sigue mostraremos una
manera más simple de realizar ese tipo cálculo.
Proposición 2.2 (Expresión de la varianza en términos de los momentos). Sea X una variable}
aleatoria con primer y segundo momentos finitos, entonces
V(X) = E[X}
2
] − E[X]
2
. (19)
En palabras, la varianza es la diferencia entre el segundo momento y el cuadrado del primer
momento.
**** Demostración
Desarrollar el cuadrado (X −{E [X])
2
y usar las propiedades de la esperanza.
Poniendo (X − E [X])
2
= X_2
− 2{X{E[X] + E[X]
2
se obtiene
V(X) = E[X}
2
] − 2{X{E[X] + E[X]
2
= E[X_2
] − 2{E[X]
2
+ E[X]
2
= E[X_2
] − E[X]
2
.
**** Ejemplo 2.3 (Varianza de la función indicadora)
Sea$(\Omega, \mathcal{A}, \mathbb{P})$un espacio de probabilidad.
Para cualquier evento A \in A vale que
V(1\{\omega \in A\}) = E[1\{\omega \in A\
2
] − E[1\{\omega \in A\]
2
= \mathbb{P}(A) − \mathbb{P}(A)
2
= \mathbb{P}(A)(1 − \mathbb{P}(A)). (20)
**** Ejemplo 2.4 (Dado equilibrado).
Sea X el resultado del lanzamiento de un dado equilibrado.
Por el Ejemplo 1.3 sabemos que E[X] = 7 / 2. Por otra parte
E[X}
2
] =
6
X
{x=1}
x
2
\mathbb{P}(X = x) =}
1
6
6
X
{x=1}
x
2
=
1 + 4 + 9 + 16 + 25 + 36
6
=
91
6
.
Por lo tanto, de acuerdo con la Proposición 2.2, la varianza de X es
V(X) =}
91
6
−

7
2

2
=
32
12
=
8
3
.
**** Ejemplo 2.5 (Fiabilidad).
Sea T el tiempo de espera hasta que ocurre la primer falla en}
un sistema electrónico con función intensidad de fallas de la forma \lambda(t) = 2{t{1{\}t > 0{\}. Por el
**** Ejemplo 1.7
sabemos que E[T ] =
\sqrt{}
\pi/{2. Por otra parte,}
E[T_2
] =
Z
\infty
−\infty
t
2
f (t) dt =}
Z
\infty
0
t
2
2t exp(−t}
2
)dt =
Z
\infty
0
xe
−x
dx = 1}.
La tercera igualdad se obtiene mediante el cambio de variables t
2
= x y la cuarta se deduce
usando l a fórmula de integración por partes aplicada a u = x y v
′
= e
−x
.
Por lo tanto, de acuerdo con la Proposición 2.2, la varianza de T es
V(T) = 1 −

\sqrt{}
\pi
2

2
= 1 −}
\pi
4
.
13
\hypertarget{pfe}
** Propiedades
Proposición 2.6. Para todo a, b \in \Re
V(aX + b) = a}
2
V(X). (21)
**** Demostración
Por definición,}
V(aX + b) = E[(aX + b − E[aX + b])
2
] = E[a
2
(X − E [X])
2
] = a
2
V(X).
Para obtener la segunda igualdad usamos que E[aX + b] = a{E[X] + b.
Error cuadrático medio. Una manera de /representar/ la variable aleatoria X mediante}
un valor fijo c \in \Re es hallar el valor c que minimice el llamado error cuadrático medio,
E[(X − c)
2
].
**** Teorema 2.7 (Pitágoras)
Sea X una variable aleatoria con esperanza y varianza finitas.
Para toda constante c \in \Re vale que
E[(X − c)
2
] = V(X)
2
+ (E[X] − c)
2
.
En particular, el valor de c que minimiza el error cuadrático medio es la esperanza de X,
E[X].
**** Demostración
Escribiendo X{−}c en la forma X{−{E [X]+{E[X]−c y desarrollando cuadrados}
se obtiene (X −}c)
2
= (X −{E [X])
2
+(E[X]−c)
2
+2(X −{E [X])(E[X]−c). El resultado se obtiene
tomando esperanza en ambos lados de la igualdad y observando que E[X − E [X]] = 0.
* Covarianza
** Definición
**** Definición 3.1 (Covarianza)
Sean X e Y dos variables aleatorias de varianzas finitas definidas
sobre el mismo espacio de probabilidad $(\Omega,
\mathcal{A},\mathbb{P})$. La covarianza de X e Y se define por


Cov (X, Y) := E[(X − E[X]) (Y − E[ Y ])]. (22)
** Cálculo
Proposición 3.2. Sean X e Y dos variables aleatorias definidas sobre
el mismo espacio de} probabilidad $(\Omega, \mathcal{A},
\mathbb{P})$. Si los segundos momentos de las variables al eatorias X
e Y son finitos, se tiene que

Cov (X, Y) = E[XY ] − E[X]E[Y ]}. (23)
**** Demostración
La esperanza del producto E[XY ] es finita porque las esperanzas E[X}
2
] y
E[Y}
2
] son finitas y vale que |{xy}| \leq}
1
2
(x
2
+ y
2
). Usando la propiedad distributiva del producto
y la linealidad de la esperanza tenemos que
E[(X − E[X]) (Y − E[Y ])] = E[XY − E[Y ]X − E[X]Y + E[X]E[Y ]]
= E[XY ] − E[Y ]E[X] − E[X]E[Y ] + E[X]E[Y ]
= E[XY ] − E[X]E[Y ].
**** Ejemplo 3.3.
Sea$(\Omega, \mathcal{A}, \mathbb{P})$un espacio de probabilidad y sean A \in $A$ y $B$ \in A dos eventos de}
probabilidad positiva. Consideremos las variables aleatorias X = 1\{\omega \in A\} e Y = 1\{\omega \in B\} .
Entonces,
Cov (X, Y) = E[XY ] − E[X]E[Y ]}
= \mathbb{P}(XY = 1) − \mathbb{P}(X = 1)\mathbb{P}(Y = 1)
= \mathbb{P}(X = 1, Y = 1) − \mathbb{P}(X = 1)\mathbb{P}(Y = 1).
La segunda y la tercera igualdad se obtienen de (2) observando que XY es una variable a
valores 0 o 1 que vale 1 si y solo si X e Y son ambas 1.
Notamos que
Cov (X, Y) > 0 \iff \mathbb{P}(X = 1, Y = 1) > \mathbb{P}(X = 1)\mathbb{P}(Y = 1) }
\iff
\mathbb{P}(X = 1, Y = 1)
\mathbb{P}(X = 1)
> \mathbb{P}(Y = 1)
\iff \mathbb{P}(Y = 1} |{X = 1) > \mathbb{P}(Y = 1).
En palabras, la covarianza de X e Y es positiva si y solamente si la condición X = 1 aumenta
la probabilidad de que Y = 1.
**** Ejemplo 3.4.
En una urna hay 6 bolas rojas y 4 bolas negras. Se extraen 2 bolas al azar sin}
reposición. Consideramos los eventos
A_i
= \sale una bola roja en la i-ésima extracción{\, i = 1, 2,
y definimos las variables aleatorias X_1
y X_2
como las funciones indicadoras de los eventos
A_1
y A_2
respectivamente. De acuerdo con el Ejemplo anterior es intuitivamente claro que
Cov (X_1
, X_2
) < 0. (¿Por qué?)
Cov (X_1
, X_2
) = \mathbb{P}(X_1
= 1, X}
2
= 1) − \mathbb{P}(X_1
= 1)\mathbb{P}(X_2
= 1) = \mathbb{P}(A_1
\cap A_2
) − \mathbb{P}(A_1
)\mathbb{P}(A_2
)
=
6
10
\times
5
9
−
6
10

5
9
\times
6
10
+
6
9
\times
4
10

= −}
2
75
= −}0.02666....
**** Nota Bene
Se puede mostrar que Cov(X , Y) > 0 es una indicación de que Y tiende a}
crecer cuando X lo hace, mientras que Cov(X,Y) < 0 es una indicación de que Y decrece
cuando X crece.
15
** Propiedades
**** Lema 3.5 (Propiedades)
Para variables aleatorias X, Y, Z y constantes a, valen las
siguientes propiedades

1. $Cov(X, X) = V(X),$
2. $Cov(X,Y) = Cov(Y, X),$
3. $Cov(aX, Y) = aCov(X,Y),$
4. $Cov(X, Y + Z) = Cov(X,Y) + Cov(X, Z).$
**** Demostración
Ejercicio

Sobre la esperanza del producto. Si se conoce la covarianza y la
esperanza de las marginales, l a identidad (23) puede ser útil para
calcular la esperanza del producto: E[XY ] = E[X]E[Y ] + Cov(X,Y).
**** Nota Bene
Si X e Y son independientes, Cov(X, Y) = 0 porque E[XY ] = E[X]E[Y
]. Pero la recíproca no es cierta.

**** Ejemplo 3.6 (Dos bolas en dos urnas)
El experimento aleatorio consiste en ubicar dos
bolas distinguibles en dos urnas. Sean N la cantidad de urnas ocupadas y X
i
la cantidad
de bolas en la urna i. El espacio muestral se puede representar de la siguiente manera \Omega =
\(1, 1); (1, 2); (2, 1); (2, 2)\. La función de probabilidad conjunta de N y X
1
se muestra en el Cuadro 1
N  \setminus  X_1
0 1 2 p
N
1 1/4 0 1/4 1/2
2
0 1/2 0 1/2
p
X_1
1/4 1/2 1/4
Cuadro 1: Función de probabilidad conjunta de (N, X}
1
).
Para calcular la esperanza del producto NX}
1
usamos el Teorema 1.19
E[NX_1
] = 1 · 1 · p}
N,X_1
(1, 1) + 1 · 2 · p}
N,X_1
(1, 2) + 2 · 1 · p}
N,X_1
(2, 1) + 2 · 2 · p}
N,X_1
(2, 2)
= 1 · 0 + 2 · 1 / 4 + 2 · 1 / 2 + 4 · 0 = 3 / 2.
Es fácil ver que E[N] = 3 / 2 y E[X_1
] = 1. Por lo tanto, Cov(N, X}
1
) = 0. Sin embargo, las
variables N y X_1
no son i ndependientes.
** Varianza de sumas
Usando las propiedades de la covarianza enunciadas en Lema 3.5 se puede demostrar que
Cov


n
X
{i=1}
X
i
,
m
X
{j=1}
Y
j


=
n
X
{i=1}
m
X
{j=1}
Cov (X
i
, Y
j
) (24)
16
En particular , se obtiene que
V
n
X
{i=1}
X
i
!
= Cov}


n
X
{i=1}
X
i
,
n
X
{j=1}
X
j


=
n
X
{i=1}
V(X}
i
) + 2
n
X
{i=1}
X
j<i
Cov (X
i
, Y
j
). (25)

Finalmente, si las variables son independientes
V
n
X
{i=1}
X
i
!
=
n
X
{i=1}
V(X}
i
). (26)
* Algunas desigualdades
** Cauchy-Schwartz
**** Teorema 4.1 (Cauchy-Schwartz)
E[|{XY |] \leq (E[X} 2 ]E[Y 2 ]) 1 / 2 (27)
**** Demostración
Observar que para todo t \in \Re :}
0 \leq E[(t | X{| + |Y |)
2
] = t
2
E[X}
2
] + 2{t{E[|{XY |] + E[Y
2
].

Como la función cuadrática en t que aparece en el lado derecho de la igualdad tiene a lo sumo
una raíz real se deduce que
4{E[|{XY |]
2
− 4{E[X}
2
]E[Y
2
] \leq 0.
Por lo tanto,
E[|{XY |]
2
\leq E[X_2
]E[Y
2
].
**** Corolario 4.2
Sea X una variable aleatoria tal que E[X
2
] < \infty. Si a < E[X], entonces}
\mathbb{P}(X > a) \geq
(E[X] − a)
2
E[X}
2
]
.
**** Demostración
De la desigualdad X}1\{X > a\} \leq |X}1\{X > a\}| y de la propiedad de
monotonía de la esperanza se deduce que
E[X{1{\}X > a{\] \leq E[|{X{1} \{X > a\}|]. (28)
Aplicando la desigualdad de Cauchy-Schwartz a |{X{1} \{X > a\}| se obtiene que
E[|{X{1} \{X > a\}|] \leq (E[X}
2
]E[1\{X > a\
2
])
1 / 2
= (E[X_2
]\mathbb{P}(X > a))
1 / 2
(29)
Observando que X = X{1{\}X > a{\} + X{1{\}X \leq a{\} y que X{1{\}X \leq a{\} \leq a se deduce que
E[X] = E[X{1{\}X > a{\] + E[X{1{\}X \leq a{\] \leq E[X{1{\}X > a{\] + a}
17
y en consecuencia,
E[X] − a \leq E[X{1{\}X > a{\]. (30)
Combinando las desigualdades (30), (28) y (29) se obtiene que
E[X] − a \leq (E[X}
2
]\mathbb{P}(X > a))
1 / 2
y como E[X] − a > 0, elevando al cuadrado, se concluye que
(E[X] − a)
2
\leq E[X_2
]\mathbb{P}(X > a).
El resultado se obtiene despejando.
** Chebyshev
**** Teorema 4.3 (Desigualdad de Chebyshev)
Sea \varphi : R \rightarrow \Re tal que \varphi \geq 0 y A \in B(R) . Sea
i
A
:= ínf\{\varphi}(x) : x \in A{\. Entonces,
i
A
\mathbb{P}(X \in A) \leq E[\varphi(X)] (31)
**** Demostración
La definición de i}
A
y el hecho de que \varphi \geq 0 implican que
i
A_1\{X \in A\} \leq \varphi (X) 1\{X \in A\} \leq \varphi (X)
El resultado se obtiene tomando esperanza.
En lo que sigue enunciaremos algunos corol arios que se obtienen como casos particulares
del Teorema 4.3.
**** Corolario 4.4 (Desigualdad de Markov)
Sea X una variable aleatoria a valores no negativos.
Para cada a > 0 vale que
\mathbb{P}(X \geq a) \leq
E[X]
a
. (32)
**** Demostración
Aplicar la desigualdad de Chebyshev usando la función \varphi(x) = x restringi
da a la semi-r ecta no negativa [0, \infty}) y el conjunto A = [a, \infty}) para obtener
a{\mathbb{P}(X \geq a) \leq E[\varphi (X)] = E[X].
y despejar.
**** Corolario 4.5.
Sea a > 0} . Vale que}
\mathbb{P}(X > a) \leq
1
a
2
E[X}
2
]. (33)
**** Demostración
Aplicar la desigualdad de Chebyshev usando la función \varphi(x) = x}
2
y el
conjunto A = (a, \infty}) para obtener
a
2
\mathbb{P}(X > a) \leq E[X}
2
]
y despejar.
**** Corolario 4.6 (Pequeña desigualdad de Chebyshev)
Sea X una variable aleatoria de vari
anza finita. Para cada a > 0 vale que
\mathbb{P}(|X − E[X]| \geq a) \leq
V(X)
a
2
. (34)
18
**** Demostración
Debido a que (X − E [X])
2
es una variable aleatoria no negativa podemos
aplicar l a desigualdad de Markov (poniendo a
2
en lugar de a) y obtenemos
P

(X − E [X])
2
\geq a
2

\leq
E[(X − E[X])
2
]
a
2
=
V(X)
a
2
.
La desigualdad (X − E [X])
2
\geq a
2
es equivalente a la desigualdad |X − E[X]| \geq a}. Por lo
tanto,
\mathbb{P}(|X − E[X]| \geq a) \leq
V(X)
a
2
.
Lo que concluye la demostración.
**** Nota Bene
Grosso modo la pequeña desigualdad de Chebyshev establece que si la varianza
es pequeña, los grandes desvíos respecto de la media son improbables.
**** Corolario 4.7.
Sea X una variable aleatoria con varianza finita, entonces para cada \alpha > 0}
\mathbb{P}(|X − E[X]| \geq \alpha\sigma}(X)) \leq
1
\alpha
2
. (35)
El resultado se obtiene poniendo a = \alpha\sigma(X) en la pequeña desigualdad de Chebyshev.
**** Ejemplo 4.8.
La cantidad X de artículos producidos por un fábrica durante una semana es}
una variable aleatoria de media 500.
(a) ¿Qué puede decirse sobre la probabilidad de que la producción semanal supere los
1000 artículos? Por la desigualdad de Markov,
\mathbb{P}(X \geq 1000) \leq
E[X]
1000
=
500
1000
=
1
2
.
(b) Si la varianza de la producción semanal es conocida e igual a 100, ¿qué puede decirse
sobre la probabilidad de que la producción semanal se encuentre entre 400 y 600 artículos?
Por la desigualdad de Chebyshev,
\mathbb{P}(|X − 500{| \geq 100) \leq
\sigma
2
(100)
2
=
1
100
.
Por lo tanto, \mathbb{P}(|X − 500{| < 100) \geq 1 −}
1
100
=
99
100
, la probabilidad de que la producción
semanal se encuentre entre 400 y 600 artículos es al menos 0.99.
El que mucho abarca poco aprieta. Las desigualdades de Markov y Chebyshev son im
portantes porque nos permiten deducir cotas sobre las probabilidades cuando solo se conocen
la media o la media y la varianza de la distribución de probabilidades. Sin embargo, debe
tenerse en cuenta que las desigualdades de Markov y de Chebyshev producen cotas universales
que no dependen de las distribuciones de las variables aleatorias (dependen pura y exclusiva
mente de los valores de la esperanza y de la varianza). Por este motivo su comportamiento
será bastante heterogéneo: en algunos casos producirán cotas extremadamente finas, pero en
otros c asos solamente cotas groseras.
19
* La ley débil de los grandes números
**** Teorema 5.1 (Le y débil de los grandes números)
Sea $X_1, X2, \dots$ una sucesión de variables
aleatorias independientes idénticamente distribuidas, tales que V(X_1) < \infty . Sea S_n
, n \geq 1, la
sucesión de las sumas parciales definida por S_n
:=
P
n
{i=1}
X
i
. Entonces, para cualquier \epsilon > 0
\lim_{n  \rightarrow \infty}
P





S_n
n
− E[X_1
]




> \epsilon

= 0.
**** Demostración
Se obtiene aplicando la desigualdad de Chebyshev a la variable aleatoria
S_n
/n.
Usando que la esperanza es un operador lineal se obtiene que
E [S_n
/n] =}
1
n
E
"
n
X
{i=1}
X
i
\#
=
1
n
n
X
{i=1}
E[X}
i
] = E[X_1
].
Como las variables X_1
, X_2
, \dots son independientes tenemos que}
V (S_n
/n) =}
1
n
2
V
n
X
{i=1}
X
i
!
=
1
n
2
n
X
{i=1}
V(X}
i
) =
V(X}
1
)
n
.
Entonces, por la desigualdad de Chebyshev, obtenemos la siguiente estimación
P





S_n
n
− E[X_1
]




> \epsilon

\leq
V(X}
1
)
n\epsilon
2
. (36)
Como V(X_1
) < \infty el lado derecho de la última desigualdad tiende a 0 cuando n \rightarrow \infty} .
**** Nota Bene
La ley débil de los grandes números establecida en el Teorema 5.1 sir ve como}
base para la noción intuitiva de probabilidad como medida de las frecuencias relativas. La
proposición /"en una larga serie de ensayos idénticos la frecuencia relativa del evento A se
aproxima a su probabilidad \mathbb{P}(A)"/se puede hacer teóricamente más precisa de la siguiente
manera: el resultado de cada ensayo se representa por una variable aleatoria (independiente de
las demás) que vale 1 cuando se obtiene el evento A y vale cero en caso contrario. La expresión
/una larga serie de ensayos/ adopta la forma de una sucesión X_1
, X_2
, \dots de variables aleatorias}
independientes cada una con la misma distribución que la indicadora del evento A. Notar que
X
i
= 1 significa que /en el i-ésimo ensayo ocurrió el evento A/ y la suma parcial S_n
=
P
n
{i=1}
X
i
representa la /frecuencia del evento A/ en los primeros n ensayos. Puesto que E[X_1
] = \mathbb{P}(A)
y V(X_1
) = \mathbb{P}(A)(1 − \mathbb{P}(A)) la estimación (36) adopta la forma
P





S_n
n
− \mathbb{P}(A)}




> \epsilon

\leq
\mathbb{P}(A)(1 − \mathbb{P}(A))
n\epsilon
2
. (37)
Por lo tanto, la probabilidad de que la frecuencia relativa del evento A se desvíe de su prob
abilidad \mathbb{P}(A) en más de una cantidad prefijada \epsilon, puede hacerse todo lo c hica que se qui era,
siempre que la cantidad de ensayos n sea suficientemente grande.
**** Ejemplo 5.2 (Encuesta electoral).
Se quiere estimar la proporción del electorado que pre
tende votar a un cierto candidato. Cuál deb e ser el tamaño muestral para garantizar un
determinado e rror entre la proporción poblacional, p, y la proporción muestral S
n
/n{?}
20
Antes de resolver este problema, debemos reﬂexionar sobre la definición de error. Habit}
ualmente, cuando se habla de error, se trata de un número real que expresa la (in)capacidad
de una cierta cantidad de representar a otra. En los problemas de estimación estadística,
debido a que una de las cantidades es una variable aleatoria y l a otra no lo es, no es posible
interpretar de un modo tan sencillo el significado de la palabra error.
Toda medida muestral tiene asociada una incerteza (o un riesgo) expresada por un modelo
probabilístico. En este problema consideramos que el voto de cada elector se comporta como
una variable aleatoria X tal que \mathbb{P}(X = 1) = p y \mathbb{P}(X = 0) = 1{−p, donde X = 1 significa que
el elector vota por el candidato considerado. Por lo tanto, cuando se habla de que quer emos
encontrar un tamaño muestral suficiente para un determinado error máximo, por ejemplo
0.02, tenemos que hacerlo con una medida de certeza asociada. Matemáticamente, queremos
encontrar n tal que P



S_n
n
− p


\leq 0.02}

\geq 0.9999 o, equivalentemente, queremos encontrar n}
tal que
P





S_n
n
− p




> 0.02}

\leq 0.0001.
Usando la estimación (37) se deduce que
P





S_n
n
− p




> 0.02}

\leq
p(1 − p)
n(0.02)
2
.
El numerador de la fracc ión que aparece en el l
ado derecho de la estimación depende de p y
el valor de p es desconocido. Sin embargo, sabemos que p(1 −p) es una parábola convexa con
raíces en p = 0 y p = 1 y por lo tanto su máximo ocurre cuando p = 1 / 2, esto es p(1{−p) \leq 1 / 4.
En l a peor hipótesis tenemos:
P





S_n
n
− p




> 0.02}

\leq
1
4n(0.02)
2
.
Como máximo estamos dispuestos a correr un riesgo de 0.0001 y en el peor caso tenemos aco
tada la máxima incerteza por (4n(0.02)
2
)
−{1}
. El problema se reduce a resolver la desigualdad
(4n(0.02)
2
)
−{1}
\leq 0.0001. Por lo tanto,}
n \geq ((0}.0001)
˙
4(0.02)
2
)
−{1}
= 6250000.
Una cifra absurdamente grande!! Más adelante, mostraremos que existen métodos más sofisti
cados que permiten disminuir el tamaño de la muestra.
21
* Distribuciones particulares
Para facilitar referencias posteriores presentaremos tablas de
esperanzas y varianzas de algunas distribuciones importantes de uso
frecuente y describiremos el método para obtener las.
** Discretas
No. Nombre Probabilidad Soporte Esperanza Varianza
*** 1. Uniforme
1
b{−}a{+1}
a \leq x \leq b(a + b) /{2 (b − a)(b − a − 2)}/{12}
*** 2. Bernoulli p
x
(1 − p)
1{−x}
x \in \{0}, 1{\} p p(1 − p)
*** 3. Binomial

n
x

p
x
(1 − p)
n{−}x
0 \leq x \leq n np np}(1 − p)
*** 4. Geométrica (1 − p)
x{−{1
p x \in N 1 /p (1 − p) /p
2
*** 5. Poisson
\lambda
x
x{!}
e
− \lambda
x \in N
0
\lambda \lambda
Cuadro 2: Esperanza y varianza de algunas distribuciones discretas de uso frecuente.
** Continuas
No. Nombre Densidad Soporte Esperanza Varianza
*** 1. Uniforme
1
b{−}a
x \in [ a, b] (a + b) /{2 (b − a)
2
/{12}
*** 2. Exponencial \lambda e}
−{\lambda x}
x > 0 1}/\lambda 1}/\lambda
2
*** 3. Gamma
\lambda
\nu
\Gamma(\nu)
x
\nu{−{1
e
−{\lambda x}
x > 0 \nu/\lambda \nu/\lambda
2
*** 4. Beta
\Gamma(\nu
1
+ \nu
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
x
\nu
1
−{1}
(1 − x)
\nu
2
−{1}
x \in (0}, 1)
\nu
1
\nu
1
+ \nu
2
\nu
1
\nu
2
(\nu
1
+ \nu
2
)
2
(\nu
1
+ \nu
2
+1)
5. Normal
1
\sqrt{}
2{\pi\sigma}
e
−(x}−{\mu)
2
/{2}\sigma
2
x \in \Re \mu \sigma
2
Cuadro 3: Esperanza y varianza de algunas distribuciones continuas de uso frecuente.
** Cuentas con variables discretas
*** 1. Distribución uniforme discreta.
Sean a y b dos números enteros tales que a < b}. Se dice que la variable aleatoria X tiene
distribución uniforme sobre el /intervalo/  de números enteros [a, b] := \{a, a + 1, \dots , b{\}, y se
denota X \sim \mathcal{U} [a, b], si X es discreta y tal que
\mathbb{P}(X = x) =}
1
b − a + 1}
1\{x \in \{a, a + 1, \dots , b\}\}.
Notando que la distribución de X coincide con la de la variable X
∗
+ a − 1, donde X
∗
está uniformemente distribuida sobre \1, \dots , b − a + 1{\, resulta que
E[X] = E[X}
∗
] + a − 1 =
1 + (b − a + 1)
2
+ a − 1 =
a + b
2
.
Para calcular la varianza de X, consideramos primero el caso más simple donde a = 1 y b = n.
Por inducción en n se puede ver que
E[X}
2
] =
1
n
n
X
{k=1}
k
2
=
(n + 1)(2n + 1)
6
.
La varianza puede obtenerse en términos de los momentos de orden 1 y 2:
V(X) = E[X}
2
] − E[X]
2
=
(n + 1)(2n + 1)
6
−
(n + 1)
2
4
=
(n + 1)[2(2n + 1) − 3(n + 1)]
12
=
n
2
− 1}
12
.
Para el caso general, notamos que la variable aleatoria uniformemente
distribuida sobre [a, b] tiene la misma varianza que la variable
aleatoria uniformemente distribuida sobre [1, b{−}a}+1], puesto que
esas dos variables difieren en la constante a −} 1. Por lo tanto, la
varianza buscada se obtiene de la fórmula anterior sustituyendo n = b
− a + 1
V(X) =}
(b − a + 1)
2
− 1}
12
=
(b − a)(b − a + 2)
12
.
*** 2. Distribución Bernoulli.
Sea p \in (0, 1). Se dice que la variable aleatoria X tiene distribución Bernoulli de parámetro}
p, y se denota X \sim Bernoulli(}p), si X es discreta y tal que}
\mathbb{P}(X = x) = p}
x
(1 − p)
1{−x}
, donde x = 0, 1}.
Por definición,
E[X] = 0 · \mathbb{P}(X = 0) + 1 · \mathbb{P}(X = 1) = 0 · (1 − p) + 1 · p = p.}
Por otra parte,
E[X}
2
] = 0
2
· \mathbb{P}(X = 0) + 1
2
· \mathbb{P}(X = 1) = p.
Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= p − p}
2
= p(1 − p).
*** 3. Distribución Binomial.
Sean p \in (0, 1) y n \in N . Se dice que la variable aleatoria X tiene distribución Binomia
l}
de parámetros n y p, y se denota X \sim Binomial (}n, p), si X es discreta y tal que
\mathbb{P}(X = x) =}

n
x

p
x
(1 − p)
n{−}x
, donde x = 0, 1, \dots , n.
Por definición,
E[X] =}
n
X
{x=0}
x{\mathbb{P}(X = x) =}
n
X
{x=0}
x

n
x

p
x
(1 − p)
n{−}x
=
n
X
{x=1}
x_n{!}
(n − x)!x!
p
x
(1 − p)
n{−}x
=
n
X
{x=1}
n{!}
(n − x)!(x − 1)!
p
x
(1 − p)
n{−}x
= np}
n
X
{x=1}
(n − 1)!
(n − x)!(x − 1)!
p
x{−{1
(1 − p)
n{−}x
= np}
n{−{1
X
y{=0}

n − 1
y

p
y
(1 − p)
n{−{1}−}y
= np(p + (1 − p))
n{−{1
= np.
Análogamente se puede ver que
E[X}
2
] = np((n − 1)p + 1).
Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= np((n − 1)p + 1) − (np)
2
= np((n − 1)p + 1 − np}) = np(1 − p).
*** 4. Distribución Geométrica.
Sea p \in (0, 1). Se dice que la variable aleatoria X tiene distribución Geométrica de}
parámetro p, y se denota X \sim Geométrica(p), si X es discreta y tal que
\mathbb{P}(X = x) = (1 − p)
x{−{1
p{1{\}x \in N\}.
Por definición,
E[X] =}
\infty
X
{x=1}
x{\mathbb{P}(X = x) =}
\infty
X
{x=1}
x(1 − p)
x{−{1
p = p
\infty
X
{x=1}
x(1 − p)
x{−{1
.
La serie se calcula observando que x(1 − p)
x{−{1
= −}
d
dp
(1 − p)
x
y recordando que las series de
potencias se pueden derivar término a término:
\infty
X
{x=1}
x(1 − p)
x{−{1
= −}
d
dp
\infty
X
{x=1}
(1 − p)
x
= −}
d
dp

p
−{1}
− 1}

= p
−{2}
.
Por lo tanto, E[X] = p · p}
−{2}
= 1{/p}.
24
Para calcular V(X) usaremos la misma técnica: derivamos dos veces ambos lado s de la
igualdad
P
\infty
{x=1}
(1 − p)
x{−{1
= p
−{1}
y obtenemos
2p
−{3}
=
d
2
dp
2
p
−{1}
=
d
2
dp
2
\infty
X
{x=1}
(1 − p)
x{−{1
=
\infty
X
{x=1}
(x − 1)(x − 2)(1 − p)
x{−{3
=
\infty
X
{x=1}
(x + 1)x(1 − p)
x{−{1
=
\infty
X
{x=1}
x
2
(1 − p)
x{−{1
+
\infty
X
{x=1}
x(1 − p)
x{−{1
.
Multiplicando por p los miembros de las igualdades obtenemos, 2p
−{2}
= E[X_2
] + E[X] =
E[X}
2
] + p
−{1}
. En consecuencia, E[X_2
] = 2p
−{2}
− p
−{1}
. Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= 2p
−{2}
− p
−{1}
− p
−{2}
= p
−{2}
− p
−{1}
= p
−{2}
(1 − p).
5. Distribución de Poisson.
Sea \lambda > 0. Se dice que la variable aleatoria X tiene distribución de Poisson de intensidad}
\lambda, y se denota X \sim Poisson(}\lambda), si X es discreta y tal que}
\mathbb{P}(X = x) =}
\lambda
x
x{!}
e
− \lambda
1\{x \in N
0
\}.
Por definición,
E[X] =}
\infty
X
{x=0}
x{\mathbb{P}(X = x) =}
\infty
X
{x=0}
x
\lambda
x
x{!}
e
− \lambda
= \lambda e}
− \lambda
\infty
X
{x=1}
x
\lambda
x{−{1
x{!}
= \lambda e}
− \lambda
\infty
X
{x=1}
\lambda
x{−{1
(x − 1)!
= \lambda e}
− \lambda
e
\lambda
= \lambda.
Derivando término a término, se puede ver que
E[X}
2
] =
\infty
X
{x=0}
x
2
\mathbb{P}(X = x) =}
\infty
X
{x=0}
x
2
\lambda
x
x{!}
e
− \lambda
= \lambda e}
− \lambda
\infty
X
{x=1}
x
2
\lambda
x{−{1
x{!}
= \lambda e}
− \lambda
\infty
X
{x=1}
x\lambda
x{−{1
(x − 1)!
= \lambda e}
− \lambda
d
d\lambda
\infty
X
{x=1}
\lambda
x
(x − 1)!
= \lambda e}
− \lambda
d
d\lambda

\lambda e
\lambda

= \lambda e}
− \lambda

e
\lambda
+ \lambda e}
\lambda

= \lambda + \lambda}
2
.
Por lo tanto,
V(X) = E[X}
2
] − E[X] = \lambda + \lambda}
2
− \lambda}
2
= \lambda.
** Cuentas con variables continuas
*** 1. Distribución uniforme.
Sean a < b}. Se dice que la variable aleatoria X tiene distribución uniforme sobre el}
intervalo [a, b], y se denota X \sim \mathcal{U} [a, b], si X es absolutamente continua con densidad de}
probabilidades
f (x) =}
1
b − a
1\{x \in [a, b]\}.
25
\hypertarget{pf1a}
Por definición,
E[X] =}
Z
\infty
−\infty
xf (x) dx =}
Z
\infty
−\infty
x
1
b − a
1\{x \in [a, b]\dx =
1
b − a
Z
b
a
x dx =}
1
b − a

b
2
− a
2
2

=
a + b
2
.
Por otra parte,
E[X}
2
] =
Z
\infty
−\infty
x
2
f (x) dx =}
1
b − a
Z
b
a
x
2
dx =}
1
b − a

b
3
− a
3
3

=
a
2
+ ab + b
2
3
.
Finalmente,
V(X) = E[X}
2
] − E[X]
2
=
a
2
+ ab + b
2
3
−

a + b
2

2
=
a
2
− 2{ab + b}
2
12
=
(b − a)
2
12
.
*** 2. Distribución exponencial.
Sea \lambda > 0. Se dice que la variable aleatoria X tiene distribución exponencial de intensi
dad \lambda, y se denota X \sim Exp(}\lambda), si X es absolutamente continua con función densidad de
probabilidades
f (x) = \lambda e
−{\lambda x}
1\{x \geq 0\}.
El cálculo de E[X] y V(X) se reduce al caso X \sim Exp(1). Basta observar que Y \sim Exp(\lambda)
si y solo si Y = \lambda}
−{1}
X, donde X \sim Exp(1) y usar las identidades E[}\lambda
−{1}
X] = \lambda
−{1}
E[X] y}
V(\lambda }
−{1}
X) = \lambda
−{2}
V(X). En lo que sigue suponemos que X \sim Exp(1).
Integrando por partes se obtiene,
E[X] =}
Z
\infty
−\infty
xf (x) dx =}
Z
\infty
−\infty
xe
−x
1\{x \geq 0\} =
Z
\infty
0
\lambda xe
−x
dx = −} xe
−x




\infty
0
+
Z
\infty
0
e
−x
dx
= 1.
Por otra parte,
E[X}
2
] =
Z
\infty
−\infty
x
2
f (x) dx =}
Z
\infty
0
x
2
e
−x
dx = −} x
2
e
−x


\infty
0
+
Z
\infty
0
2{xe}
−x
dx = 2}.
Por lo tanto, V(X) = E[X_2
] − E[X]
2
= 2 − 1 = 1.
*** 3. Distribución gamma.
La función gamma se define por
\Gamma(t) :=
Z
\infty
0
x
t{−{1
e
−x
dx t > 0}.
Integrando por partes puede verse que \Gamma(t) = (t − 1)\Gamma(t − 1) para todo t > 0. De aquí se
deduce que la función gamma interpola a los números factoriales en el sentido de que
\Gamma(n + 1) = n! para n = 0, 1, \dots}
Sean \lambda > 0 y \nu > 0. Se dice que la variable aleatoria X tiene distribución gamma de parámetros}
\nu, \lambda, , y se denota X \sim \Gamma(}\nu, \lambda), si X es absolutamente continua con función densidad de}
probabilidades
f (x) =}
\lambda
\nu
\Gamma(\nu)
x
\nu{−{1
e
−{\lambda x}
1\{x > 0}\}.
El cálculo de E[X] y V(X) se reduce al caso X \sim \Gamma(\nu, 1). Para ello, basta observar que Y \sim
\Gamma(\nu, \lambda) si y solo si Y = \lambda}
−{1}
X, donde X \sim \Gamma(}\nu, 1) y usar las identidades E[\lambda
−{1}
X] = \lambda
−{1}
E[X]
y V(\lambda
−{1}
X) = \lambda
−{2}
V(X). En lo que sigue suponemos que X \sim \Gamma(\nu, 1)
E[X] =}
Z
\infty
0
xf (x) dx =}
Z
\infty
0
1
\Gamma(\nu)
x
\nu
e
−x
dx =}
1
\Gamma(\nu)
\Gamma(\nu + 1) = \nu.
Del mismo mo do se puede ver que E[X_2
] = (\nu + 1)\nu = \nu}
2
+ \nu}. Por lo tanto, V(X) =
E[X}
2
] − E[X]
2
= \nu}.
*** 4. Distribución beta
Sean \nu}
1
> 0 y \nu
2
> 0. Se dice que la variable aleatoria X tiene distribución beta de
parámetros \nu}
1
, \nu}
2
, y se denota X \sim \beta(\nu
1
, \nu
2
), si X es absolutamente continua con función
densidad de probabilidades
f (x) =}
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
x
\nu
1
−{1}
(1 − x)
\nu
2
−{1}
1\{x \in (0, 1\}.
Por definición,
E[X] =}
Z
\infty
−\infty
xf (x) dx =}
Z
\infty
−\infty
x
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
x
\nu
1
−{1}
(1 − x)
\nu
2
−{1}
1\{x \in (0, 1}\dx
=
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
Z
1
0
x
\nu
1
(1 − x)
\nu
2
−{1}
dx =}
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
\Gamma(\nu
1
+ 1)\Gamma(\nu
2
)
\Gamma(\nu
1
+ \nu}
2
+ 1)
=
\nu
1
\nu
1
+ \nu}
2
Por otra parte,
E[X}
2
] =
Z
\infty
−\infty
x
2
f (x) dx =}
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
Z
1
0
x
\nu
1
+1
(1 − x)
\nu
2
−{1}
dx
=
\Gamma(\nu
1
+ \nu}
2
)
\Gamma(\nu
1
)\Gamma(\nu
2
)
\Gamma(\nu
1
+ 2)\Gamma(\nu
2
)
\Gamma(\nu
1
+ \nu}
2
+ 2)
=
\nu
1
(\nu
1
+ 1)
(\nu
1
+ \nu}
2
)(\nu
1
+ \nu}
2
+ 1)
Finalmente,
V(X) = E[X}
2
] − E[X]
2
=
\nu
1
(\nu
1
+ 1)
(\nu
1
+ \nu}
2
)(\nu
1
+ \nu}
2
+ 1)
−

\nu
1
\nu
1
+ \nu}
2

2
=
\nu
1
\nu
2
(\nu
1
+ \nu}
2
)
2
(\nu
1
+ \nu}
2
+ 1)
.
*** 5. Distribución normal.
Sean \mu \in \Re y \sigma > 0. Se dice que la variable aleatoria X tiene distribución normal de}
parámetros \mu, \sigma}
2
, y se denota X \sim N}(\mu, \sigma
2
), si X es absolutamente continua con función
densidad de probabilidades
f (x) =}
1
\sqrt{}
2{\pi\sigma}
e
−(x}−{\mu)
2
/{2}\sigma
2
.
El cálculo de E[X] y V(X) se reduce al caso X \sim N}(0, 1). Para ello, basta observar que
Y \sim N (\mu, \sigma
2
) si y solo si Y = \sigmaX + \mu, donde X \sim N}(0, 1) y usar las identidades E[\sigmaX + \mu] =
\sigma{E[X]+ \mu y V(\sigmaX + \mu) = \sigma
2
V(X). En lo que sigue suponemos que X \sim N}(0, 1) y denotamos}
su densidad mediante
\varphi (x) =}
1
\sqrt{}
2 \pi
e
−x
2
/{2}
Es evidente que E[X] = 0. En consecuencia,
V(X) = E[X}
2
] =
Z
\infty
−\infty
x
2
\varphi (x) dx
Observando que \varphi}
′
(x) = −{x\varphi}(x) e integrando por partes se obtiene,
V(X) =}
Z
\infty
−\infty
x (x\varphi (x))dx = −} x\varphi (x)




\infty
−\infty
+
Z
\infty
−\infty
\varphi (x) dx = 0 + 1}.
* Bibliografía consultada
Para redactar estas notas se consultaron los siguientes libros:
1. Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to
   Probability. M.I.T. Lecture Notes. (2000)
2. Bil lingsley, P.: Probability and Measure. John Wiley & Sons, New
   York. (1986)
3. Durrett, R. Elementary Probability for Applications. Cambridge
   University Press, New York. (2009)
4. Feller, W.: An introduction to Probability Theory and Its
   Applications. Vol. 1. John Wiley & Sons, New York. (1957)
5. Kolmogorov, A. N.: The Theory of Probability. Mathematics. Its
   Content, Methods, and Meaning. Vol 2. The M.I.T. Press,
   Massachusetts. (1963) pp. 229-264.
6. Ross, S.: Introduction to Probability and Statistics for Engineers
   and Scientists. Academic Press, San D iego. (2004)
7. Ross, S.: Introduction to Probability Models. Academic Press, San D
   iego. (2007)
8. Soong, T. T.: Fundamentals of Probability and Statistics for
   Engineers. John Wiley & Sons Ltd. (2004)



 
 
 
 
 

