#+title:Estimadores puntuales
* Introducción
** Nociones y presupuestos básicos
**** Definición 1.1 (Muestra aleatoria). 
Sea $(\Omega, \mathcal{A}, \mathbb{P})$ un espacio de probabilidad y $X :
\Omega \rightarrow \Re$ una variable aleatoria. Una muestra aleatoria
de volumen n de la variable aleatoria X es una sucesión $X_1, \dots ,
X_n$ de variables aleatorias independientes cada una con la misma
distribución de X.

**** Modelos paramétricos. 
En todo lo que sigue vamos a suponer que
1. La función de distribución de la variable aleatoria X es
   desconocida parcialmente: se sabe que $F (x) = \mathbb{P}(X \leq
   x)$ pertenece a una familia, $F$, de distribuciones conocidas que
   dependen de un parámetro $\theta$ desconocido: $F = \{F_{\theta}:
   \theta \in \Theta\}$.
2. El conjunto paramétrico, $\Theta$, es no vacío y está contenido en R
d
.
3. Las distribuciones de la familia $F$ son distinguibles:
   $F_{\theta_1} \neq F_{\theta_2}$ cuando $\theta_1 \neq \theta_2$ .
4. Las distribuciones de la familia $F$ tienen /"densidad''. Si se
   trata de una familia de distribuciones continuas esto significa que
   para cada $\theta \in \Theta$, existe una función densidad de
   probabilidades (f.d.p.) $f(x|\theta)$ tal que $\frac{d}{dx}
   F_{\theta}(x) = f(x | \theta)$. Si se trata de una familia de
   distribuciones discretas esto significa que para cada $\theta \in
   \Theta$, existe una función de probabilidad (f.p.) $f (x | \theta)$
   tal que $F_{\theta}(x) − F_{\theta}(x^−) = f(x | \theta)$.
5. Es posible conseguir muestras aleatorias de la variable X del
   volumen que se desee.

**** Nota Bene 
De los presupuestos básicos adoptados resulta que los modelos
paramétricos} adoptan la forma

$$F = \{f(x|\theta) : \theta \in \Theta\},$$

donde $\theta$ es un parámetro desconocido que puede tomar valores en
un espacio paramétrico $\Theta \subset \Re d$.
** Algunas familias paramétricas
Repasamos algunas de las familias de distribuciones que se utilizan
comúnmente en el análisis de datos en problemas prácticos.

1. Familia Normal, N(\mu, \sigma 2). Decimos que X tiene distribución normal de parámetros
\mu \in R y \sigma
2
> 0 cuando la f.d.p. de X está dada por
f ( x | \mu, \sigma
2
) =
1
\sigma
\sqrt{}
2 \pi 
exp

−
(x − \mu)
2
2 \sigma 
2

, −\infty < x < \infty}.
Vale que E[X] = \mu y V(X) = \sigma}
2
.
* Familia Gamma, \Gamma(\nu, \lambda)
Decimos que X tiene distribución gamma de parámetros
\nu > 0 y \lambda > 0 cuando la f.d.p. de X está dada por
f ( x | \nu, \lambda) =}
\lambda
\nu
\Gamma( \nu )
x
\nu{−{1
e
−{\lambda x}
1\{x \geq 0}\, 
donde \Gamma( \nu ) :=
R
\infty
0
x
\nu{−{1
e
−x
dx. Vale que E[X] = \nu/\lambda y V(X) = \nu/\lambda
2
.
Casos particulares de las familias Gamma son las familias exponenciales Exp( \lambda ) = \Gamma(1, \lambda)
y las familias chi cuadrado \Chi
2
\nu
= \Gamma(\nu/}2, 1 / 2).
3. Familia Beta, \beta ( \nu}
1
, \nu
2
). Decimos que X tiene distribución beta de parámetros \nu}
1
> 0}
y \nu}
2
> 0 cuando la f.d.p. de X está dada por}
f ( x | \nu
1
, \nu
2
) =
\Gamma( \nu 
1
+ \nu}
2
)
\Gamma( \nu 
1
)\Gamma( \nu 
2
)
x
\nu
1
−{1}
(1 − x)
\nu
2
−{1}
1\{0 < x < 1\}.
Vale que
E[X] =}
\nu
1
\nu
1
+ \nu}
2
y V(X) =
\nu
1
\nu
2
( \nu 
1
+ \nu}
2
)
2
( \nu 
1
+ \nu}
2
+ 1)
.
Notar que cuando los parámetros \nu}
1
y \nu}
2
son números naturales se tiene que
\Gamma( \nu 
1
+ \nu}
2
)
\Gamma( \nu 
1
)\Gamma( \nu 
2
)
=
( \nu 
1
+ \nu}
2
− 1)!}
( \nu 
1
− 1)!( \nu }
2
− 1)!}
= ( \nu 
1
+ \nu}
2
− 1)

\nu
1
+ \nu}
2
− 2}
\nu
1
− 1}

.
La distribución \beta( \nu 
1
, \nu
2
) se puede obtener como la distribución del cociente X_1
/ ( X_1
+ X_2
)
donde X_1
\sim \Gamma( \nu }
1
, 1) y X_2
\sim \Gamma( \nu }
2
, 1).
Notar que \beta(1, 1) = U(0, 1).
3
4. Familia Binomial, Binomial(n, p). Decimos que X tiene distribución Binomial de}
parámetros n \in N y 0 < p < 1 cuando su f.p. está dada por
f ( x | n, p) =}

n
x

(1 − p)
n{−}x
p
x
, x = 0, 1, \dots , n.
Vale que E[X] = np y V(X) = np(1 − p).
5. Familia Pascal, Pascal(n, p). Decimos que X tiene distribución Pascal de parámetros}
n \in N y 0 < p < 1 cuando su f.p. está dada por}
f ( x | n, p) =}

x − 1
n − 1

p
n
(1 − p)
x{−}n
, x = n, n + 1, \dots .
Vale que E[X] = n/p y V(X) = n(1 − p)/p}
2
.
6. Familia Poisson, Poisson( \lambda ). Decimos que X tiene distribución Poisson de parámetro}
\lambda > 0 cuando su f.p. está dada por}
f ( x | \lambda) = e
− \lambda 
\lambda
x
x{!}
, x = 0, 1, \dots .
Vale que E[X] = \lambda y V(X) = \lambda}.
2. Estimadores
El punto de partida de la investigación estadística está constituido por una muestra
aleatoria, X = (X_1
, \dots , X
n
), de la distribución desconocida F perteneciente a una familia
paramétrica de distribuciones F = \{F
\theta : \theta \in \Theta{\}
1
. Como las distribuciones de la familia F}
son distinguibles lo que se quier e saber e s cuál es el parámetro \theta \in \Theta que corresponde a la
distribución F . En otras palabras, se quiere hallar \theta \in \Theta tal que F = F}
\theta
.
Formalmente, /"cualquier"/función,
ˆ
\theta :=}
ˆ
\theta(X), de la muestra aleatoria X que no depende}
de parámetros desconocidos se denomina una estadística.
**** Ejemplo 2.1. 
Sea X = (X}
1
, \dots , X
n
) una muestra aleatoria de la variable aleatoria X con
función de distribución F}
\theta
. Ejemplos de estadísticas son
(i) X
(1)
= mín(X_1
, \dots , X
n
),
(ii) X
(n)
= máx(X_1
, \dots , X
n
),
(iii)
¯
X =}
1
n
P
n
{i=1}
X
i
,
(iv) ˆ \sigma 
2
=
1
n
P
n
{i=1}
(X
i
−
¯
X ) 
2
.
1
Notación. Si F es una familia de distribuciones F
\theta
con /"densidades"/f (x | \theta), \theta \in \Theta, escribimos
P
\theta
(X \in A) =
Z
A
f ( x | \theta ) dx y E
\theta
[r (X)] =
Z
r ( x ) f  ( x | \theta ) dx
El subíndice \theta indica que la probab ilidad o la esperanza es con respecto a f(x | \theta). Similarmente, escribimos V}
\theta
para la varianza.
4
En (i) y (ii), mín(·) y máx(·) denotan, respectivamente, el mínimo y el máximo muestrales
observados. Por otro lado,
¯
X y ˆ \sigma }
2
denotan, respectivamente, la media y la varianza muestrales.
Cualquier estadística que asuma valores en el conjunto paramétrico \Theta de la familia de
distribuciones F se denomina un estimador puntual para $\theta$}. El adjetivo puntual está puesto
para distinguirla de las estimaciones por intervalo que veremos más adelante.}
En muchas si tuaciones lo que interesa es estimar una función g(\theta). Por ejemplo, cuando
se considera una muestra aleatoria X de una variable X \sim N}(\mu, \sigma
2
) donde \mu y \sigma}
2
son
desconocidos entonces \theta = (\mu, \sigma
2
) y el conjunto de parámetros es \Theta = \(\mu, \sigma
2
) : \mu \in \Re y \sigma}
2
>
0{\}. Si el objetivo es estimar solamente \mu, entonces g(\theta) = \mu}.
**** Definición 2.2. 
Cualquier estadística que solamente asuma valores en el conjunto de los}
posibles valores de g(\theta) es un estimador para g ( \theta). 
Uno de los grandes problemas de la estadística es construir estimadores razonables para
el parámetro desconocido \theta o para una función g(\theta). Existen diversos méto dos para elegir
entre todos los estimadores posibles de $\theta$}. Cada elección particular del estimador depende de
ciertas propiedades que se consideran /"deseables"/para la estimación.
** Error cuadrático medio, sesgo y varianza
Uno de los procedimientos más usados para evaluar el desempeño de un estimador es
considerar su error cuadrático medio. Esta noción permite precisar el sentido que se le otorga
a los enunciados del tipo /"{el estimador puntual}
ˆ
\theta =}
ˆ
\theta(X) está próximo de $\theta${''. }
**** Definición 2.3 (Error cuadrático medio)
El error cuadrático medio (ECM) de un estimador
ˆ
\theta para el parámetro \theta se define por}
ECM(
ˆ
\theta) = E
\theta
h
(
ˆ
\theta − \theta ) 
2
i
. (1)
El ECM se puede descomponer de la siguiente manera
2
E
\theta
h
(
ˆ
\theta − \theta ) 
2
i
= V}
\theta
(
ˆ
\theta) + B}
2
\theta
(
ˆ
\theta ) , (2)
donde B
\theta
(
ˆ
\theta) := E
\theta
[
ˆ
\theta] − \theta es el llamado sesgo del e stimador. El primer término de la descom
posición (2) describe la /"variabilidad"/del estimador, y el segundo el /"error sistemático'': E}
\theta
[
ˆ
\theta]
describe alrededor de qué valor ﬂuctúa
ˆ
\theta y V
\theta
(
ˆ
\theta) mide cuánto ﬂuctúa. 
2
La descomposición (2) se obtiene escribiendo
ˆ
\theta − \theta en la forma (
ˆ
\theta − E
\theta
[
ˆ
\theta]) + (E
\theta
[
ˆ
\theta] − \theta). Desarrollando}
cuadrados obtenemos (
ˆ
\theta − \theta ) 
2
= (
ˆ
\theta − E
\theta
[
ˆ
\theta])
2
+ 2(
ˆ
\theta − E
\theta
[
ˆ
\theta])(E
\theta
[
ˆ
\theta] − \theta) +}
/"
E
\theta
[
ˆ
\theta] − \theta
''
2
. El resultado se obtiene
observando que la esperanza E}
\theta
de los términos cruzados (
ˆ
\theta − E
\theta
[
ˆ
\theta])(E
\theta
[
ˆ
\theta] − \theta) es igual a 0:}
E
\theta
h
(
ˆ
\theta − \theta ) 
2
i
= E}
\theta
»
(
ˆ
\theta − E
\theta
[
ˆ
\theta])
2
+ 2(
ˆ
\theta − E
\theta
[
ˆ
\theta])(E
\theta
[
ˆ
\theta] − \theta) +}
/"
E
\theta
[
ˆ
\theta] − \theta
''
2
-
= E}
\theta
h
(
ˆ
\theta − E
\theta
[
ˆ
\theta])
2
i
+ 0 +
/"
E
\theta
[
ˆ
\theta] − \theta
''
2
= V}
\theta
(
ˆ
\theta) + B}
2
\theta
(
ˆ
\theta ) .
5
**** Definición 2.4 (Estimadores insesgados)
Diremos que un estimador
ˆ
\theta es insesgado para el}
parámetro \theta si
E
\theta
[
ˆ
\theta] = \theta.
para todo \theta \in \Theta, o sea B
\theta
(
ˆ
\theta) ≡ 0. Si lím}
{n \rightarrow \infty}
B
\theta
[
ˆ
\theta] = 0 para todo \theta \in \Theta, diremos que el
estimador
ˆ
\theta es asintóticamente insesgado para $\theta$}. 
**** Nota Bene 
En el caso en que}
ˆ
\theta es un estimador insesgado para $\theta$, tenemos que}
ECM(
ˆ
\theta) = V
\theta
(
ˆ
\theta ) ,
o sea, el error cuadrático medio de
ˆ
\theta se reduce a su varianza.
**** Nota Bene 
Una consecuencia destacable de la descomposición (2) para grandes muestras}
(n >> 1) es la siguiente: si a medida que se aumenta el volumen de la muestra, el sesgo y la
varianza del estimador
ˆ
\theta tienden a cero, entonces, el estimador}
ˆ
\theta converge en media cuadrática}
al verdadero valor del parámetro \theta}.
**** Ejemplo 2.5 (Estimación de media)
Sea F = \{F 
\theta
: \theta \in \Theta{\} una familia de distribuciones.
Para cada \theta \in \Theta designemos mediante \mu(\theta) y \sigma}
2
(\theta) la media y la varianza correspondientes a
la distribución F}
\theta
, respectivamente. Sea X = (X_1
, \dots , X
n
) una muestra aleatoria de alguna
distribución perteneciente a F}. Denotemos mediante
¯
X el promedio de la muestra:}
¯
X =}
1
n
n
X
{i=1}
X
i
.
En lo que sigue vamos a suponer que para cada \theta \in \Theta, \mu(\theta) \in \Re y \sigma}
2
(\theta) < \infty} . Si la muestra
aleatoria proviene de la distribución F}
\theta
, tenemos que
E
\theta

¯
X

= E}
\theta
"
1
n
n
X
{i=1}
X
i
\#
=
1
n
n
X
{i=1}
E
\theta
[X
i
] = \mu(\theta).
Por lo tanto
¯
X es un estimador insesgado para \mu ( \theta) y su error cuadrático medio al estimar}
\mu ( \theta) es}
ECM(
¯
X) = V
\theta

¯
X

= V}
\theta_1
n
n
X
{i=1}
X
i
!
=
1
n
2
n
X
{i=1}
V
\theta
[X
i
] =
1
n
\sigma
2
(\theta).
**** Ejemplo 2.6 (Estimación de varianza)
Sea F = \{F 
\theta
: \theta \in \Theta{\} una familia de distribuciones.
Para cada \theta \in \Theta designemos mediante \mu(\theta) y \sigma}
2
(\theta) la media y la varianza correspondientes
a la distribución F}
\theta
, respectivamente, a las que supondremos finitas. Sea X_1
, \dots , X
n
una
muestra aleatoria de alguna distribución perteneciente a F}. Sean
¯
X y ˆ \sigma }
2
la media y la
varianza muestrales definidas en el Ejemplo 2. 1:
¯
X :=}
1
n
n
X
{i=1}
X
i
y ˆ \sigma 
2
:=
1
n
n
X
{i=1}
(X
i
−
¯
X ) 
2
.
6
Para analizar el sesgo de la varianza muestral conviene descomponerla de la siguiente manera:
ˆ \sigma 
2
=
1
n
n
X
{i=1}
(X
i
− \mu ( \theta))}
2
−  ( 
¯
X −}\mu ( \theta))
2
, (3)
cualquiera sea \theta \in \Theta.
3
Si la muestra aleatoria, X_1
, \dots , X
n
, proviene de la distribución F}
\theta
, al
tomar esperanzas en ambos lados de (3) se obtiene
E
\theta
[ˆ \sigma 
2
] =
1
n
n
X
{i=1}
E
\theta

(X
i
− \mu ( \theta))}
2

− E}
\theta

(
¯
X −}\mu ( \theta))
2

=
1
n
n
X
{i=1}
V
\theta
(X
i
) − V
\theta
(
¯
X ) . (4)
Según el Ejemplo 2.5
¯
X es un estimador insesgado para la media \mu ( \theta) y su varianza vale}
V
\theta
(
¯
X) =}
1
n
\sigma
2
(\theta), en consecuencia,
E
\theta
[ˆ \sigma 
2
] =
1
n
n
X
{i=1}
V
\theta
(X
i
) − V
\theta
(
¯
X) = \sigma
2
(\theta) −}
1
n
\sigma
2
(\theta) =
n − 1
n
\sigma
2
(\theta). (5)
Esto demuestra que ˆ \sigma 
2
no es un e sti mador insesgado para la varianza \sigma
2
(\theta). La identidad
E
\theta
[ˆ \sigma 
2
] =
n{−{1
n
\sigma
2
(\theta) significa que si tomamos repetidas muestras de tamaño n y se promedian
las varianzas muestrales resultantes, el promedio no se aproximará a la verdadera varianza,
sino que de mo do sistemático el valor será más pequeño debido al factor (n{−} 1)/n}. Este factor
adquiere importancia en las muestras pequeñas. Si n \rightarrow \infty}, el factor (n − 1)/n \rightarrow 1 lo que
demuestra que ˆ \sigma 
2
es un estimador asintóticamente insesgado para la varianza \sigma 
2
(\theta).
Para eliminar el sesgo en ˆ \sigma 
2
, basta multiplicar ˆ \sigma 
2
por
n
n{−{1
. De (5) sigue que
S
2
:=
n
n − 1
ˆ \sigma 
2
=
1
n − 1
n
X
{i=1}
(X
i
−
¯
X ) 
2
(6)
es un estimador insesgado para la varianza.
** Comparación de estimadores
El error cuadrático medio puede usarse para comparar estimadores. Diremos que
ˆ
\theta_1
es
mejor que}
ˆ
\theta
2
si
ECM(
ˆ
\theta_1
) \leq ECM(
ˆ
\theta
2
), (7)
para todo \theta, con desigualdad estricta para al menos un valor de $\theta$}. En tal caso, el estimador
ˆ
\theta
2
se dice inadmisible}. Si existe un estimador
ˆ
\theta
∗
tal que para todo estimador
ˆ
\theta de $\theta$ con}
ˆ
\theta \neq
ˆ
\theta
∗
ECM(
ˆ
\theta
∗
) \leq ECM(
ˆ
\theta ) , (8)
3
La descomposición (3) se obtiene haciendo lo siguiente. Para cada i escribimos (X
i
−
¯
X) en la forma}
(X
i
− \mu ( \theta)) −  ( 
¯
X − \mu ( \theta)). Desarrollando cuadrados obtenemos (X
i
−
¯
X ) 
2
= (X
i
− \mu ( \theta))}
2
+ (
¯
X − \mu ( \theta))
2
−
2(X
i
− \mu ( \theta))(}
¯
X − \mu ( \theta)). El resultado se obtiene observando que el promedio de los términos cruzados (X}
i
−
\mu ( \theta))(
¯
X − \mu ( \theta)) es igual a (
¯
X − \mu ( \theta))
2
. (Hacer la cuenta y verificarlo! ) 
7
para todo \theta, con desigualdad estricta para al menos un valor de $\theta$, entonces
ˆ
\theta
∗
se dice óptimo.
Cuando la comparación se restringe a los estimadores son insesgados, el estimador óptimo,
ˆ
\theta
∗
, se dice el estimador insesgado de varianza uniformemente mínima. Esta denominación
resulta de observar que estimadores insesgados la relación (8) adopta la forma
V
\theta
(
ˆ
\theta
∗
) \leq V
\theta
(
ˆ
\theta ) ,
para todo \theta, con desigualdad estricta para al menos un valor de $\theta$}.
**** Ejemplo 2.7. 
Sean X}
1
, X_2
, X
3
una muestra aleatoria de una variable aleatoria X tal que
E
\theta
[X] = \theta y V}
\theta
(X) = 1. Consideremos los estimadores
¯
X =}
X_1
+ X_2
+ X
3
3
y
ˆ
\theta =}
1
2
X_1
+
1
4
X_2
+
1
4
X
3
.
Según el Ejemplo 2.5 E}
\theta
[
¯
X] = \theta y V
\theta
(
¯
X) =}
1
3
. Tenemos también que
E
\theta
[
ˆ
\theta] =}
1
2
E
\theta
[X_1
] +
1
4
E
\theta
[X_2
] +
1
4
E
\theta
[X
3
] =
1
2
\theta +}
1
4
\theta +}
1
4
\theta = \theta
y
V
\theta
(
ˆ
\theta) =}
1
4
V
\theta
(X_1
) +
1
16
V
\theta
(X_2
) +
1
16
V
\theta
(X
3
) =
1
4
+
1
16
+
1
16
=
6
16
.
Como
¯
X y
ˆ
\theta son insesgados, resulta que}
¯
X es mejor que}
ˆ
\theta, pues V
\theta
(
¯
X ) < V}
\theta
(
ˆ
\theta) para todo \theta.
**** Ejemplo 2.8. 
Sea X}
1
, \dots , X
n
una muestra aleatoria de una variable aleatoria X \sim \mathcal{U} (0, \theta).
Vamos a considerar
ˆ
\theta_1
= 2
¯
X y
ˆ
\theta
2
= X
(n)
como estimadores para $\theta$ y estudiaremos su com
portamiento. Como E}
\theta
[X] = \theta/}2 y V}
\theta
(X) = \theta}
2
/{12, tenemos que}
E
\theta
[
ˆ
\theta_1
] = E}
\theta
[2
¯
X] = \theta y V
\theta
(
ˆ
\theta_1
) =
\theta
2
3n
. (9)
Por lo tanto,
ˆ
\theta_1
es un estimador insesgado para $\theta$}. En consecuencia,
ECM(
ˆ
\theta_1
) = V}
\theta
(
ˆ
\theta_1
) =
\theta
2
3n
. (10)
Por otro lado, la función densidad de X
(n)
está dada por f
\theta
(x) =
nx
n{−{1
\theta
n
1\{0 < x < \theta} \, de
donde se deduce que
E
\theta
[X
(n)
] =
n
n + 1}
\theta y V
\theta
(X
(n)
) =
n\theta
2
(n + 1)
2
(n + 2)
. (11)
Por lo tanto,
ˆ
\theta
2
es un estimador asintóticamente insesgado para $\theta$}. Combinando las identidades
(11) en (2), obtenemos
ECM(
ˆ
\theta
2
) = V}
\theta
(
ˆ
\theta
2
) + B
2
\theta
(
ˆ
\theta
2
) =
n\theta
2
(n + 1)
2
(n + 2)
+

n
n + 1}
\theta − \theta

2
=
n\theta
2
(n + 1)
2
(n + 2)
+
\theta
2
(n + 1)
2
=
2{\theta}
2
(n + 1)(n + 2)
. (12)
Es fácil, pero tedioso, ver que ECM(
ˆ
\theta
2
) < ECM(
ˆ
\theta_1
) para todo \theta y todo n. Por lo tanto, X
(n)
es mejor que 2
¯
X para todo \theta y todo n.
8
** Consistencia
Lo mínimo que se le puede exigir a un estimador puntual,
ˆ
\theta ( X_1
, \dots , X
n
), es que, en
algún sentido, se aproxime al verdadero valor del parámetro cuando el volumen de la muestra
aumenta. En otras palabras, si \theta \in \Theta es tal que F = F}
\theta
y X_1
, X_2
, \dots es una sucesión}
de variables aleatorias independientes cada una con distribución F , en algún sentido, debe
ocurrir que
ˆ
\theta ( X_1
, \dots , X
n
) \rightarrow \theta,
cuando n \rightarrow \infty} .
Por ejemplo, es deseable que el estimador
ˆ
\theta tenga la siguiente propiedad, llamada consis}
tencia débil{: para cada \epsilon > 0 debe cumplir que}
\lim_{n  \rightarrow \infty}
P
\theta
( | 
ˆ
\theta ( X_1
, \dots , X
n
) − \theta}| > \epsilon}) = 0. (13)
Más exigente, es pedirle que tenga la siguiente propiedad, llamada consistencia fuerte{:
P
\theta

\lim_{n  \rightarrow \infty}
ˆ
\theta ( X_1
, \dots , X
n
) = \theta}

= 1. (14)
Normalidad asintótica. También se le puede pedir una propiedad similar a la del teorema}
central límite, llamada normalidad asintótica{: existe \sigma = \sigma(\theta) > 0 tal que
\lim_{n  \rightarrow \infty}
P
\theta
\sqrt{}
n ( 
ˆ
\theta ( X_1
, \dots , X
n
) − \theta})
\sigma
\leq x
!
=
Z
x
−\infty
1
\sqrt{}
2 \pi 
e
−t
2
/{2}
dt (15)
**** Nota Bene 
L os problemas de consistencia y normalidad asintótica están relacionados con}
las leyes de los grandes números y el teorema central de límite. El siguiente ejemplo muestra
dicha relación para el caso en que se quiere estimar la media de una distribución.
**** Ejemplo 2.9 (Estimación de media)
Sea X = (X}
1
, \dots , X
n
) una muestra aleatoria de una
variable aleatoria cuya distribución pertenece a una familia F = \{F
\theta
: \theta \in \Theta{\}. Sean \mu(\theta) y
\sigma
2
(\theta) la media y la varianza correspondientes a la distribución F}
\theta
, respectivamente. Aplicando
la desigualdad de Chebychev a
¯
X se obtiene que para cada \epsilon > 0}
P
\theta



¯
X −}\mu ( \theta ) 


> \epsilon

\leq
V
\theta
(
¯
X ) 
\epsilon
2
=
1
n

\sigma
2
(\theta)
\epsilon
2

\rightarrow 0, 
cuando n \rightarrow \infty} .
Hasta aquí, lo único que hicimos es volver a demostrar la ley débil de los grandes números.
Lo que queremos subrayar es que en el contexto de la estimación de parámetros, la ley débil de}
los grandes números significa que el promedio de la muestra,
¯
X, es un estimador débilmente}
consistente para la la media de la distribución, \mu ( \theta).}
La consistencia fuerte del promedio, como estimador para la media es equivalente a la
Ley fuerte de lo s grandes números que afirma que: Si X_1
, X_2
, \dots es una sucesión de variables}
aleatorias independientes e idénticamente distribuidas y si existe E[X
i
] = \mu, entonces
P

\lim_{n  \rightarrow \infty}
¯
X = \mu

= 1.
La normalidad asintótica es equivalente al teorema central del límite.
9
\hypertarget{pfa}
**** Nota Bene 
De todas las propiedades de convergencia la consistencia débil es la
mas simple, en el sentido de que puede establecerse con unas pocas
herramientas técnicas. Para verificar la consistencia débil del
promedio para estimar la media solamente usamos la desigualdad de
Chebychev y las propiedades de la media y la varianza. El razonamiento
utilizado en el Ejemplo 2.9 se puede extender un poco más allá.
**** Teorema 2.10
Sea
ˆ
\theta un estimador de $\theta$ basado en una muestra aleatoria de volumen n. Si
ˆ
\theta
es asintóticamente insesgado y su varianza tiende a cero, entonces
ˆ
\theta es débilmente consistente.
**** Demostración 
El resultado se obtiene usando la desigualdad de Chebychev y la identidad}
(2):
P
\theta




ˆ
\theta − \theta



> \epsilon

\leq
1
\epsilon
2
E
\theta
h
(
ˆ
\theta − \theta ) 
2
i
=
1
\epsilon
2

V
\theta
(
ˆ
\theta) + B}
2
\theta
(
ˆ
\theta ) 

\rightarrow 0.
* Método de máxima verosimilitud
El método de máxima verosimilitud es un /"método universal"/para construir estimadores
puntuales. Su base intuitiva es la siguiente: si al realizar un experimento aleatorio se observa}
un resultado, este debe tener alta probabilidad de ocurrir.
Para hacer más precisa esa base intuitiva consideremos una muestra aleatoria, X =
(X_1
, \dots , X
n
), de una variable aleatoria discreta X con función de probabilidad f(x | \theta), \theta \in
\Theta, donde \Theta es el espacio paramétrico. La probabilidad de observar los resultados X_1
=
x
1
, \dots , X
n
= x
n
se calcula del siguiente modo:
P
\theta
(X_1
= x
1
, \dots , X
n
= x
n
) =
n
Y
{i=1}
P
\theta
(X
i
= x
i
) =
n
Y
{i=1}
f ( x
i
|{\theta ) . (16)}
Si los resultados observables deben tener una alta probabilidad de ocurrir y observamos que
X_1
= x
1
, \dots , X
n
= x
n
, entonces lo razonable sería elegir entre todos los parámetros posibles,
\theta \in \Theta, aquél (o aquellos) que maximicen (16). En consecuencia, se podría estimar \theta como el
valor (o los valores) de $\theta$ que hace máxima la probabilidad
Q
n
{i=1}
f ( x
i
|{\theta).}
** Estimador de máxima verosimilitud (EMV)
**** Definición 3.1 (EMV). Sea X una variable aleatoria cuya distribución per tenece a la familia}
paramétrica F = \{F
\theta
: \theta \in \Theta{\}. Un estimador de máxima verosimilitud de $\theta$, basado en los
valores x = (x
1
, \dots , x
n
) de una muestra aleatoria X = (X_1
, \dots , X
n
), es un valor
ˆ
\theta
_{mv}
\in \Theta que}
maximiza la función de verosimilitud
L ( \theta{|{x) := 
n
Y
{i=1}
f ( x
i
|{\theta ) , (17)}
donde, dependiendo de la naturaleza de las distribuciones de la familia F, f(x | \theta) es la función
de probabilidad o la función densidad de probabilidades de X.
10
\hypertarget{pfb}
Sobre la notación. Para destacar que el valor del estimador de máxima verosimilitud}
depende de los valores observados, x = (x
1
, \dots , x
n
), en lugar de
ˆ
\theta
_{mv}
escribiremos
ˆ
\theta
_{mv}
(x):
ˆ
\theta
_{mv}
=
ˆ
\theta
_{mv}
(x) := arg máx
\theta{\in{\Theta
L ( \theta{|{x ) . (18)
**** Ejemplo 3.2. 
Supongamos que tenemos una moneda que puede ser equilibrada o totalmente}
cargada para que salga cara. Lanzamos la moneda n veces y registramos la sucesión de caras
y cecas. Con esa información queremos estimar qué clase de moneda tenemos.
Cada lanzamiento de la moneda se modela con una variable aleatoria X con distribución
Bernoulli(\theta), donde $\theta$ es la probabilidad de que la moneda salga cara. El espacio paramétrico
es el conjunto \Theta = \1 / 2, 1{\}.
El estimador de máxima verosimilitud para $\theta$, basado en los valores x = (x
1
, \dots , x
n
) de
una muestra aleatoria X = (X_1
, \dots , X
n
) de la variable X, es el valor de
ˆ
\theta
_{mv}
(x) \in \Theta = \1 / 2, 1{\}
que maximiza la función de verosimilitud L(\theta | x ). Para encontrarlo comparamos los valores
de la función de verosimilitud L(1 / 2 | x ) y L(1 | x ):
L(1}/{2 | x ) =}
n
Y
{i=1}
f ( x
i
|{1 / 2) = (1 / 2)
n
, L(1 | x ) = 1
(
n
X
{i=1}
x
i
= n
)
.
En consecuencia, el estimador de máxima verosimilitud para $\theta$, basado en los valores x =
(x
1
, \dots , x
n
) de una muestra aleatoria X = (X_1
, \dots , X
n
) es
ˆ
\theta
_{mv}
(x) =
1
2
1
(
n
X
{i=1}
x
i
< n
)
+ 1}
(
n
X
{i=1}
x
i
= n
)
.
Por lo tanto, el estimador de máxima verosimilitud para $\theta$ basado en una muestra aleatoria
X = (X}
1
, \dots , X
n
) es
ˆ
\theta
_{mv}
(X) =
1
2
1
(
n
X
{i=1}
X
i
< n
)
+ 1}
(
n
X
{i=1}
X
i
= n
)
.
Por ejemplo, si en 10 lanzamientos de la moneda se observaron 10 caras, el estimador de
máxima verosimilitud para $\theta$ es
ˆ
\theta
_{mv}
= 1; en cambio si se observaron 8 caras y 2 cecas, el
estimador de máxima verosimilitud es
ˆ
\theta
_{mv}
= 1 / 2.
**** Ejemplo 3.3.

Sea X una variable aleatoria con función densidad dada por
f ( x | \theta) =}
1
2
(1 + \thetax)1\{x \in [−}1, 1]\, \theta \in [−}1, 1].
Supongamos que queremos hallar el estimador de máxima verosimilitud para $\theta$ basado en la
realización de una muestra aleatoria tamaño 1, X_1
. Si se observa el valor x
1
, la función de
verosimilitud adopta la forma
L ( \theta | x
1
) =
1
2
(1 + \thetax}
1
)
El gráfico de L(\theta | x}
1
) es un segmento de recta de pendiente x
1
. Como se trata de una recta el
máximo se alcanza en alguno de los extremos del intervalo \Theta = [−}1, 1]:
1. si x
1
< 0, el máximo se alcanza en \theta = −}1,}
11
\hypertarget{pfc}
2. si x
1
= 0, el máximo se alcanza en cualquiera de los valores del intervalo \Theta,
3. si x
1
> 0, el máximo se alcanza en \theta = 1.
Abusando de la notación tenemos que
ˆ
\theta
_{mv}
(x
1
) = −{1}\{x}
1
< 0{\} + \Theta{1{\}x
1
= 0{\} + 1\{x
1
> 0{\} .
Por lo tanto,
ˆ
\theta
_{mv}
(X_1
) = −{1}\{X}
1
< 0{\} + \Theta{1{\}X_1
= 0{\} + 1\{X_1
> 0{\} .
**** Ejemplo 3.4.

Sea X una variable aleatoria con función densidad dada por
f ( x | \theta) =}
1
2
(1 + \thetax)1\{x \in [−}1, 1]\, \theta \in [−}1, 1].
Supongamos que una muestra aleatoria de tamaño 2 arrojó los valores 1 / 2 y 1 / 4 y con esa
información queremos hallar el estimador de máxima verosimilitud para $\theta$}. La función de
verosimilitud adopta la forma
L ( \theta{|{1} /{2, 1}/{4) =}
1
4

1 + \theta_1
2

1 + \theta_1
4

,
y su gráfico es un segmento de parábola /"cóncava"/cuyas raíces son −}4 y −}2. Por lo tanto,
ˆ
\theta
_{mv}
(1 / 2, 1 / 4) = 1.
Supongamos ahora que una muestra aleatoria de tamaño 2 arrojó los valores 1 / 2 y −}1 / 4 y
con esa información queremos hallar el estimador de máxima verosimilitud para $\theta$}. La función
de verosimilitud adopta la forma
L ( \theta{|{1} /{2, −{1} /{3) =}
1
4

1 + \theta_1
2

1 − \theta_1
3

,
y su gráfico es un segmento de parábola /"convexa"/cuyas raíces son −}2 y 3. Por lo tanto,
ˆ
\theta
_{mv}
(1 / 2, −} 1 / 3) = 0.5.
3.2. Cálculo del EMV para familias regulares
Sea F = \{F
\theta
: \theta \in \Theta{\} una familia paramétrica de distribuciones y sea \{f(x | \theta) : \theta \in \Theta{\}
la familia de funciones de densidad (o de probabilidad) asociada. Diremos que la familia F}
es regular si satisface las siguientes condiciones:
1. El conjunto paramétrico \Theta \subset R
d
es abierto.
2. El soporte de las funciones f(x | \theta) no depende del parámetro. Esto es, existe un conjunto
S tal que sopf(·|{\theta}) := \{x \in R : f (x | \theta) > 0{\} = S para todo \theta \in \Theta.
3. Para cada x \in S , la función f(x | \theta) tiene derivadas parciales respecto de todas las
componentes \theta}
j
, j = 1, \dots , d}.
12
\hypertarget{pfd}
Supongamos ahora que X = (X_1
, \dots , X
n
) es una muestra aleatoria de tamaño n de una
variable aleatoria X con función de densidad (o de probabilidad) f(x | \theta), \theta \in \Theta, perteneciente
a una familia regular de distribuciones. Debido a que la familia es regular cada uno de los
valores observados pertenece al soporte común de las funciones f(x | \theta): x = (x
1
, \dots , x
n
) \in S_n
.
Por lo tanto, cualesquiera sean los valores observados, x = (x
1
, \dots , x
n
), vale que
L ( \theta{|{x) = 
n
Y
{i=1}
f ( x
i
|{\theta ) > 0}.
Esto habilita a tomar logaritmos y utilizar la propiedad /"el logaritmo del producto es igual}
a la suma de los logaritmos''. En consecuencia, para cada x = (x}
1
, \dots , x
n
) \in S_n
, la función
log L(\theta | x ) está bien definida y vale que
log L(\theta | x ) = log
n
Y
{i=1}
f ( x
i
|{\theta) =
n
X
{i=1}
log f(x
i
|{\theta ) . (19)}
Como el logaritmo natural log(·) es una función monótona creciente, maximizar la función
de verosimilitud L(\theta | x ) será equivalente a maximizar log L(\theta | x ). La ventaja de maximizar el
logaritmo de la función de verosimilitud es que, bajo las condiciones de regularidad enunciadas
previamente, los productos se convierten en sumas, aligerando considerablemente el trabajo
de cómputo del EMV ya que el EMV debe verificar el sistema de ecuaciones
\partial  log L ( \theta{|{x ) 
\partial \theta
j
= 0 j = 1, \dots , d. (20)
En vista de (19) el sistema de ecuaciones (20) se transforma en
n
X
{i=1}
\partial  log f ( x
i
|{\theta ) 
\partial \theta
j
= 0, j = 1, \dots , d. (21)
Por este camino llegamos al siguiente resultado que provee la herramienta adecuada para el
cálculo del EMV.
**** Lema 3.5. Sea X una variable aleatoria con función de densidad (o de probabilidad) f(x | \theta),}
\theta \in \Theta \subset R
d
, perteneciente a una familia regular de distribuciones. El estimador de máxima
verosimilitud de $\theta$, basado en los valores x = (x
1
, \dots , x
n
) de una muestra aleatoria X =
(X_1
, \dots , X
n
), es solución del siguiente sistema de ecuaciones:
n
X
{i=1}
ψ
j
(\theta | x}
i
) = 0 j = 1, \dots , d, (22)
donde, para cada x \in S , la funciones de $\theta$, ψ}
j
(\theta | x), j = 1, \dots , d, se definen por
ψ
j
(\theta | x) :=
\partial  log f ( x | \theta ) 
\partial \theta
j
. (23)
**** Nota Bene 
Por supuesto que las condiciones (22) son necesarias pero no suficientes para}
que \theta sea un máximo. Para asegurarse que \theta es un máximo deberán verificarse las condi
ciones de segundo orden. Además debe verificarse que no se trata de un máximo relativo sino
absoluto.
13
\hypertarget{pfe}
**** Nota Bene 
Si la función de densidad (o de probabilidad) f(x | \theta) de la variable aleatoria}
X pertenece a una familia regular uniparamétrica de distribuciones, i.e., cuando el espacio 
paramétrico \Theta es un subconjunto de la recta real R, el sistema de ecuaciones (22) se reduce
a una sola ecuación, denominada la ecuación de verosimilitud, 
n
X
{i=1}
ψ ( \theta | x
i
) = 0, (24)
donde, para cada x \in S , la función de $\theta$, ψ(\theta | x), se define por
ψ ( \theta | x) :=}
\partial  log f ( x | \theta ) 
\partial \theta
. (25)
**** Ejemplo 3.6 (Distribuciones de Bernoulli). Es fácil ver que la familia de distribuciones}
Bernoulli(\theta), \theta \in (0, 1), es una familia uniparamétrica regular con funciones de probabilidad
de la forma f(x | \theta) = (1 −{\theta})
1{−x}
\theta
x
, x = 0, 1. En consecuencia, para encontrar el estimador de
máxima verosimilitud para $\theta$ basado en una muestra aleatoria X = (X_1
, \dots , X
n
) podemos
usar el resultado del Lema 3.5.
En primer lugar hallamos la expresión de la función ψ(\theta | x) =
\partial  log f ( x | \theta ) 
\partial \theta
. Observando que
log f(x | \theta) = log(1 − \theta})
1{−x}
\theta
x
= (1 − x) log(1 −{\theta}) + x log \theta,}
y derivando respecto de $\theta$ obtenemos
ψ ( \theta | x) =}
1
1 − \theta
(x − 1) +
1
\theta
x
Por lo tanto, la ecuación de verosimilitud (24) adopta la forma
1
1 − \theta
n
X
{i=1}
(x
i
− 1) +}
1
\theta
n
X
{i=1}
x
i
= 0. (26)
Un poco de álgebra muestra que para cada pareja a \neq b vale que:
1
1 − \theta
a +}
1
\theta
b = 0 ⇔ \theta =}
b
b − a
. (27)
Sigue de (27), poniendo a =
P
n
{i=1}
(x
i
−{1) =}
P
n
{i=1}
x
i
−{n y b =
P
n
{i=1}
x
i
, que la solución de la
ecuación (26) es
\theta =}
1
n
n
X
{i=1}
x
i
.
Con un poco más de trabajo, se puede verificar que dicha solución maximiza el logaritmo de
la verosimilitud.
En resumen, si x = (x
1
, \dots , x
n
) son los valores observados de una muestra aleatoria
X = (X}
1
, \dots , X
n
), el estimador de máxima verosimilitud para $\theta$ es el promedio (o media)
muestral
ˆ
\theta
_{mv}
=
ˆ
\theta
_{mv}
(x) =
1
n
n
X
{i=1}
x
i
14
\hypertarget{pff}
Por lo tanto, el estimador de máxima verosimilitud para $\theta$, basado en una muestra aleatoria}
X = (X}
1
, \dots , X
n
) de una variable con distribución Bernoulli(\theta), es el promedio muestral}
ˆ
\theta
_{mv}
(X) =
1
n
n
X
{i=1}
X
i
. (28)
**** Nota Bene 
El estimador de máxima verosimilitud para $\theta$, basado en una muestra aleatoria
X = (X}
1
, \dots , X
n
), de una variable aleatoria con distribución Bernoulli(\theta),
¯
X =}
1
n
n
X
{i=1}
X
i
,
es una variable aleatoria. Subrayamos este hecho para que no se pierda de vista que los}
estimadores puntuales son funciones de la muestra ale
atoria X = (X_1
, \dots , X
n
) y por lo tanto
son variables aleatorias. En el Ejemplo 3.6, 
el parámetro \theta es la media de la distribución que
produce la muestra y el estimador de máxima verosimilitud para $\theta$ es el promedio muestral.
Por lo tanto,
ˆ
\theta
_{mv}
es un estimador insesgado, consistente y asintóticamente normal.
**** Nota Bene 
Si la muestra aleatoria arrojó los valores 1, 1, \dots , 1, es fácil ver que}
ˆ
\theta
_{mv}
= 1,
en cambio si arrojó 0, 0, \dots , 0 resulta que
ˆ
\theta
_{mv}
= 0. Estos resultados también coinciden con
el promedio de los valores observados. Por lo tanto, el resultado obtenido en (28) se puede
extender al caso en que \Theta = [0, 1].
**** Ejemplo 3.7 (Distribuciones de Bernoulli). Bajo el supuesto de que los valores de la secuencia}
0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0. (29)
fueron arrojados por una muestra aleatoria de tamaño 20 de una variable aleatoria X \sim
Bernoulli(\theta), el e stimador de máxima verosimilitud arrojará como resultado la siguiente esti
mación para el parámetro \theta}:
ˆ
\theta
_{mv}
(0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0) =
11
20
= 0.55
Con esta estimación podríamos decir que la ley que produce esos valores es la distribución de
Bernoulli (0.55). Por lo tanto, si queremos /"reproducir"/el generador de números aleatorios
que produjo esos resultados, debemos simular números aleatorios con distribución de Bernoulli
de parámetro 0.55.
**** Ejemplo 3.8 (Distribuciones normales con varianza conocida)
Sea X = (X}
1
, \dots , X
n
) una
muestra aleatoria de una variable aleatoria X \sim N}(\theta, \sigma}
2
), con varianza \sigma}
2
> 0 conocida y}
media \theta \in \Re} . La familia de distribuciones normales N(\theta, \sigma}
2
), \theta \in \Re}, es una familia regular
uniparamétrica con densidades de la forma
f ( x | \theta) =}
1
\sigma
\sqrt{}
2 \pi 
e
−
(x{−}\theta)
2
2 \sigma 
2
.
15
Usando el resultado del Lema 3.5 se puede ver que el estimador de máxima verosimilitud para}
\theta es}
ˆ
\theta
_{mv}
(X) =
1
n
n
X
{i=1}
X
i
=
¯
X.
En efecto, como
ψ ( \theta | x) =}
\partial  log f ( x | \theta ) 
\partial \theta
=
x − \theta
\sigma
2
la ecuación de verosimilitud (24) equivale a
n
X
{i=1}
(x
i
− \theta) = 0}.
El resultado se obtiene despejando \theta}.
**** Ejemplo 3.9 (Distribuciones normales). La familia de distribuciones normales}
\{N(\mu, \sigma
2
) : \mu \in \Re, \sigma}
2
> 0{\
es una familia regular con parámetro bidimensional \theta = (\mu, \sigma
2
) \in \Theta = R \times (0, \infty}). Para
encontrar el estimador de máxima verosimilitud del parámetro (\mu, \sigma
2
) basado en una muestra
aleatoria X = (X_1
, \dots , X
n
) usaremos los resultados del Lema 3.5. La densidad de cada
variable X es
f ( x | \mu, \sigma
2
) = (2 \pi )
−
1
2

\sigma
2

−
1
2
exp

−
(x − \mu)
2
2 \sigma 
2

con lo cual
log f(x | \mu, \sigma}
2
) = log(2 \pi )
−
1
2
−
1
2
log \sigma}
2
−
(x − \mu)
2
2 \sigma 
2
.
En consecuencia,
\partial  log f ( x | \mu, \sigma
2
)
\partial \mu
=
x − \mu
\sigma
2
y
\partial  log f ( x | \mu, \sigma
2
)
\partial \sigma
2
= −}
1
2 \sigma 
2
+
(x − \mu)
2
2( \sigma 
2
)
2
.
Luego el sistema de ecuaciones (22) se transforma en el sistema
1
\sigma
2
n
X
{i=1}
x
i
− n\mu}
!
= 0, 
1
2 \sigma 
2
−{n +
1
\sigma
2
n
X
{i=1}
(x
i
− \mu ) 
2
!
= 0.
que tiene como solución
\mu =}
1
n
n
X
{i=1}
x
i
= ¯{x,}
\sigma
2
=
1
n
n
X
{i=1}
(x
i
− ¯{x ) 
2
.
16
Se puede comprobar que en ese punto de coordenadas (\mu, \sigma
2
) se alcanza el máximo absoluto
de la función log L(\mu, \sigma
2
|{x).}
Resumiendo, cuando la muestra aleatoria X = (X_1
, \dots , X
n
) arroja los valores x =
(x
1
, \dots , x
n
), el estimador de máxima verosimilitud para (\mu, \sigma
2
) es el punto del conjun
to paramétrico R \times (0, \infty}) cuyas coordenadas son el promedio y la varianza muestrales:
ˆ \mu 
_{mv}
(x) =
1
n
P
n
{i=1}
x
i
= ¯{x y}
c
\sigma
2
_{mv}
(x) =
1
n
P
n
{i=1}
(x
i
− ¯{x ) 
2
.
Por lo tanto, el estimador de máxima verosimilitud para (\mu, \sigma 
2
), basado en una muestra
aleatoria X = (X_1
, \dots , X
n
) de variables normales, N(\mu, \sigma
2
), es el punto en R \times (0, \infty}) de
coordenadas aleatorias
ˆ \mu 
_{mv}
(X) =
¯
X,
c
\sigma
2
_{mv}
(X) =
1
n
n
X
{i=1}
(X
i
−
¯
X ) 
2
. (30)
*** Familias exponenciales
Muchos modelos estadísticos pueden considerarse como casos particulares de una familia
más general de distribuciones.
**** Definición 3.10 
(Familias exponenciales). Decimos que la distribución de una variable}
aleatoria X pertenece a una familia exponencial unidimensional de distribuciones, si podemos
escribir su función de probabilidad o su función densidad como
f ( x | \theta) = e
a ( \theta ) T  ( x)+}b ( \theta)+}S ( x ) 
, x \in S}, (31)
donde, a y b son funciones de $\theta$}; T y S son funciones de x y S no depende de $\theta$}.
**** Nota Bene 
Si las funciones a y b son derivables y el espacio paramétrico \Theta es abierto,}
las densidades (31) constituyen una familia regular uniparamétrica y en consecuencia, para
encontrar el estimador de máxima verosimilitud de $\theta$, basado en una muestra aleatoria X =
(X_1
, \dots , X
n
), se puede usar el resultado del Lema 3.5.
Debido a que el logaritmo de la densidad (31) es
log f(x | \theta) = a(\theta)T (x) + b(\theta) + S(x)
tenemos que
ψ ( \theta | x) =}
\partial  log f ( x | \theta ) 
\partial \theta
= a
′
(\theta)T(x) + b
′
(\theta)
y en consecuencia, la ecuación de verosimilitud (24) adopta la forma
a
′
(\theta)
n
X
{i=1}
T  ( x
i
) + nb}
′
(\theta) = 0.
Por lo tanto, el estimador de máxima verosimilitud para $\theta$ satisface la ecuación
−b
′
(\theta)
a
′
(\theta)
=
1
n
n
X
{i=1}
T  ( x
i
). (32)
17
**** Ejemplo 3.11 
(Distribuciones exponenciales). Sea X una variable aleatoria con distribución}
Exponencial( \lambda ), \lambda > 0. Podemos escribir
f ( x | \lambda) = \lambda e
−{\lambda x}
= e
−{\lambda x{+log \lambda}
Por lo tanto, la distribución de X pertenece a una familia exponencial unidimensional con
a ( \lambda) = −} \lambda, b ( \lambda) = log \lambda, T  ( x) = x, S ( x) = 0 y S = (0, \infty). La ecuación de verosimilitud (32)}
adopta la forma
1
\lambda
=
1
n
n
X
{i=1}
x
i
= ¯{x (33)}
cuya solución es \lambda = 1 / ¯{x. Se puede verificar que el valor de \lambda así obtenido maximiza el
logaritmo de la verosimilitud.
Si la muestra aleatoria X = (X_1
, \dots , X
n
) arrojó los valores x = (x
1
, \dots , x
n
), el estimador
de máxima verosimilitud para \lambda es
ˆ
\lambda
_{mv}
(x) = (¯{x ) 
−{1}
.
Por lo tanto, el estimador de máxima verosimilitud para \lambda, basado en una muestra ale
atoria
X = (X}
1
, \dots , X
n
) de variables con distribución Exponencial( \lambda ), es
ˆ
\lambda
_{mv}
(X) =
1
n
n
X
{i=1}
X
i
!
−{1}
.
**** Ejemplo 3.12 
(Distribuciones normales con media conocida). Sea X una variable aleatoria}
con distribución normal N(\mu, \sigma
2
), donde la media \mu es conocida y la varianza \sigma}
2
> 0. Podemos}
escribir
f ( x | \sigma
2
) =
1
\sqrt{}
2{\pi\sigma}
e
−
(x{−}\mu)
2
2 \sigma 
2
= e
−
1
2 \sigma 
2
(x{−}\mu)
2
−
1
2
log \sigma}
2
−{log}
\sqrt{}
2 \pi 
Por lo tanto, la distribución de X pertenece a una familia exponencial unidimensional con
a ( \sigma
2
) = −}
1
2 \sigma 
2
, b( \sigma 
2
) = −}
1
2
log \sigma}
2
, T (x) = (x − \mu)
2
, S(x) = −}log
\sqrt{}
2{\pi y S = R}. La ecuación
de verosimilitud (32) adopta la forma
1 / 2 \sigma 
2
1 / 2( \sigma 
2
)
2
=
1
n
n
X
{i=1}
(x
i
− \mu ) 
2
(34)
cuya solución es \sigma}
2
=
1
n
P
n
{i=1}
(x
i
− \mu ) 
2
. Se puede verificar que el valor de \sigma}
2
así obtenido
maximiza el logaritmo de la verosimilitud.
Si la muestra aleatoria X = (X_1
, \dots , X
n
) arrojó los valores x = (x
1
, \dots , x
n
), el estimador
de máxima verosimilitud para \sigma}
2
es
c
\sigma
2
_{mv}
(x) =
1
n
n
X
{i=1}
(x
i
− \mu ) 
2
.
Por lo tanto, el estimador de máxima verosimilitud para \sigma 
2
, basado en una muestra aleatoria
X = (X}
1
, \dots , X
n
) de variables con distribución N(\mu, \sigma
2
), es
c
\sigma
2
_{mv}
(X) =
1
n
n
X
{i=1}
(X
i
− \mu ) 
2
.
18
*** Malas noticias!
**** Ejemplo 3.13 (Fiabilidad)
Sea T_1
, \dots , T_n
una muestra aleatoria del tiempo de duración sin
fallas de una máquina cuya función intensidad de fallas es \lambda(t) = \betat}
\beta{−{1
1\{t > 0} \, donde el
parámetro de /"desgaste"/ \beta > 0 es desconocido. La densidad de cada tiempo T es
f ( t | \beta) = \betat
\beta{−{1
e
−t
\beta
1\{t > 0}\} (35)}
Observando que
log f(t | \beta) = log \beta + (\beta − 1) log t − t}
\beta
y derivando respecto de \beta se obtiene
\partial  log f ( x | \beta ) 
\partial \beta
=
1
\beta
+ log t − t}
\beta
log t.
Por lo tanto, la ecuación de verosimilitud (24) adopta la forma
n
\beta
+
n
X
{i=1}
log t
i
−
n
X
{i=1}
t
\beta
i
log t
i
= 0 (36)
La mala noticia es que la ecuación (36) no tiene una solución analítica explícita.
El ejemplo anterior muestra que en algunos casos la ecuación de verosimilitud no presenta
solución analítica explícita. En tales casos, los estimadores de máxima verosimilitud pueden
obtenerse mediante métodos numéricos.
Método de Newton-Raphson. El método de Newton-Raphson es un procedimiento it
erativo para obtener una raíz de una ecuación
g ( \theta) = 0, (37)
donde g(·) es una función suave. La idea es la siguiente: supongamos que \theta es una raíz de la
ecuación (37). Desarrollando g(·) en serie de Taylor en torno de un punto \theta_0
, obtenemos que
g ( \theta) \approx g ( \theta_0
) + (\theta − \theta_0
)g
′
(\theta_0
).
En consecuencia, si \theta_0
está cerca de una raíz \theta de la ecuación (37), debería ocurrir lo siguiente
\theta \approx \theta_0
−
g ( \theta_0
)
g
′
(\theta_0
)
. (38)
De la ecuación (38) obtenemos el procedimiento iterativo
\theta
{j+1}
= \theta}
j
−
g ( \theta
j
)
g
′
(\theta}
j
)
(39)
que se inicia con un valor \theta_0
y produce un nuevo valor \theta_1
a partir de (39) y así siguiendo,
hasta que el proceso se estabilice, o sea, hasta que |{\theta
{j+1}
−{\theta}
j
| < \epsilon para un \epsilon > 0 /"pequeño"/ y
prefijado.
19
**** Ejemplo 3.14 
(Continuación del Ejemplo 3.13). Para resolver la ecuación (36) usaremos el}
procedimiento de Newton-Raphson aplicado a la función
g ( \beta) =}
n
\beta
+
n
X
{i=1}
log t
i
−
n
X
{i=1}
t
\beta
i
log t
i
.
Como
g
′
( \beta ) = −}
n
\beta
2
−
n
X
{i=1}
t
\beta
i
(log t
i
)
2
,
el procedimiento iterativo (39) adopta la forma
\beta
{j+1}
= \beta}
j
+
n
\beta
+
P
n
{i=1}
log t
i
−
P
n
{i=1}
t
\beta
i
log t
i
n
\beta
2
+
P
n
{i=1}
t
\beta
i
(log t
i
)
2
. (40)
Generando una muestra aleatoria de tamaño n = 20 de una variable aleatoria T con
densidad dada por (35) con \beta = 2 e inicializando el procedimiento iterativo (40) con \beta}
1
=
¯
T
obtuvimos que
ˆ
\beta
_{mv}
= 2.3674.
Generando una muestra aleatoria de tamaño n = 10000 de una variable aleatoria T con
densidad dada por (35) con \beta = 2 e inicializando el procedimiento iterativo (40) con \beta}
1
=
¯
T
obtuvimos que
ˆ
\beta
_{mv}
= 1.9969.
** Cálculo del EMV para familias no regulares
Venía rápido, muy rápido y se le soltó un patín ...
Ahora mostraremos algunos ejemplos correspondientes a familias no regulares. En estos
casos hay que analizar dónde se realiza el máximo /"a mano''.
**** Ejemplo 3.15 
(Distribuciones de Bernoulli con parámetros discretos). Supongamos que los}
valores observados en la secuencia (29) que aparece en el Ejemplo 3.7 fueron arrojados por una
muestra aleatoria de tamaño n = 20 de una variable aleatoria X con distribución Bernoulli(p),
donde p = 0.45 o p = 0.65. La familia de distribuciones no es regular debido a que el espacio
paramétrico \0.45, 0.65{\} no es abierto. En esta situación no puede utilizarse la metodología
del Lema 3.5 pues conduce a resultados totalmente disparatados. Lo único que se puede hacer
es comparar los valores L(0.45 | x ), L(0.65 | x ) y quedarse con el valor de p \in \}0.45, 0.65{\} que
haga máxima la probabilidad de observar el resultado x:
L(0.45 | x ) = (0.45)
11
(0.55)
9
= (7.0567\dots)10
−{7}
L(0.65 | x ) = (0.65)
11
(0.35)
9
= (6.8969\dots)10
−{7}
.
Por lo tanto, el estimador de máxima verosimilitud, basado en las observaciones (29), será
ˆp
_{mv}
(0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0) = 0.45.
20
**** Ejemplo 3.16 
(Distribución uniforme). La familia \{U}(0, \theta) : \theta > 0{\} de distribuciones uni
formes no es una familia regular debido a que el soporte de la densidad de la distribución
U(0, \theta) es [0, \theta] (y depende claramente del valor del parámetro \theta). En esta situación tampoco}
puede utilizarse la metodología del Lema 3.5. En este caso \Theta = (0, \infty}) y las funciones de
densidad son de la forma
f ( x | \theta) =}
1
\theta_1\{0 \leq x \leq \theta\}.
La función de verosimilitud es
L ( \theta{|{x) = 
n
Y
{i=1}
1
\theta_1\{0 \leq x}
i
\leq \theta\} =}
1
\theta
n
n
Y
{i=1}
1\{0 \leq x}
i
\leq \theta\}
=
1
\theta
n
1

máx
{i=1,...,n
x
i
\leq \theta}

.
Si \theta < máx
i
x
i
, entonces L(\theta | x ) = 0. Si \theta \geq máx
i
x
i
, entonces L(\theta | x ) = \theta}
−n
, una función
decreciente en \theta}. En consecuencia, su máximo se alcanza en
\theta = máx}
{i=1,...,n
x
i
.
Por lo tanto, el estimador de máxima verosimilitud para $\theta$, basado en una muestra aleatoria}
X = (X}
1
, \dots , X
n
) de una variable aleatoria X \sim U(0 , \theta ) , es el máximo de la muestra}
ˆ
\theta
_{mv}
(X) = X
(n)
:= máx
{i=1,...,n
X
i
.
**** Ejemplo 3.17 
(Distribución uniforme). La familia \{U}(\theta − 1 / 2, \theta + 1 / 2) : \theta \in \Re\} de dis
tribuciones uniformes no es una familia regular debido a que el soporte de la densidad de
la distribución U(\theta − 1 / 2, \theta + 1 / 2) es [\theta − 1 / 2, \theta + 1 / 2] (y depende claramente del valor del
parámetro \theta). En este caso \Theta = R y las funciones de densidad son de la forma
f ( x | \theta) = 1{\}\theta − 1} /{2 \leq x \leq \theta + 1}/{2{\} .
La función de verosimilitud es
L ( \theta{|{x) = 
n
Y
{i=1}
1\{\theta − 1 / 2 \leq x}
i
\leq \theta + 1}/{2}\}
= 1}

máx
{i=1,...,n
x
i
− 1 / 2 \leq \theta \leq mín}
{i=1,...,n
x
i
+ 1 / 2

= 1}

x
(n)
− 1 / 2 \leq \theta \leq x
(1)
+ 1 / 2

,
pues
\theta − 1} /{2 \leq x
i
\leq \theta + 1}/{2, i = 1, \dots , n,}
si y solamente si
\theta \leq x
i
+ 1 / 2 y x
i
− 1 / 2 \leq \theta, i = 1, \dots , n,}
Como L(\theta | x ) se anula para $\theta$ < x}
(n)
y para $\theta$ > x}
(1)
+ 1 / 2 y es constantemente 1 en el
intervalo [x
(n)
−{1 / 2, x
(1)
+1 / 2], tenemos que cualquier punto de ese intervalo es un estimador
de máxima verosimilitud para $\theta$}. En particular,
ˆ
\theta(x) =}
x
(1)
+ x
(n)
2
es un estimador de máxima verosimilitud para $\theta$}. Etc...
21
** Principio de invariancia
En lo que sigue presentamos una propiedad bastante importante del método de máxima
verosimilitud.
**** Teorema 3.18 (Principio de invariancia). Sea X 
1
, \dots , X
n
una muestra aleatoria de una
variable a leatoria X cuya distribución pertenece a la familia paramétrica F = \{F
\theta
: \theta \in \Theta{\}.
Sea g : \Theta \rightarrow \Lambda una función biunívoca de \Theta sobre \Lambda}. Si
ˆ
\theta es un estimador de máxima}
verosimilitud para $\theta$, entonces g ( 
ˆ
\theta) es un estimador de máxima verosimilitud para \lambda = g ( \theta ) .}
**** Demostración 
Como \lambda = g(\theta) es una función biunívoca de \Theta sobre \Lambda, la función de}
verosimilitud L(\theta | x ) se puede expresar en función de \lambda ya que \theta = g
−{1}
( \lambda ). Denominemos a
la función de verosimilitud, como función de \lambda, p or L}
∗
(\lambda | x ). Es claro que
L
∗
(\lambda | x ) = L(g
−{1}
( \lambda ) | x ).
Sea
ˆ
\theta
_{mv}
\in \Theta un estimador de máxima verosimilitud para $\theta$ y sea}
ˆ
\lambda := g ( 
ˆ
\theta
_{mv}
) \in \Lambda su imagen
por g. Hay que mostrar que vale lo siguiente:
L
∗
(
ˆ
\lambda{|{x) = máx 
\lambda{\in{\Lambda
L
∗
(\lambda | x )
Pero esto es inmediato, debido a que
L
∗
(
ˆ
\lambda{|{x) = L ( g
−{1}
(
ˆ
\lambda) | x ) = L ( 
ˆ
\theta
_{mv}
|{x) = máx
\theta{\in{\Theta
L ( \theta{|{x) = máx 
\lambda{\in{\Lambda
L ( g
−{1}
( \lambda ) | x )
= máx
\lambda{\in{\Lambda
L
∗
(\lambda | x ).
Por lo tanto,
d
g ( \theta ) 
_{mv}
= g(
ˆ
\theta
_{mv}
).
**** Ejemplo 3.19. 
Sea X}
1
, \dots , X
n
una muestra aleatoria de la variable aleatoria X \sim N}(\mu, 1).
En el Ejemplo 3.8 vimos que ˆ \mu 
_{mv}
=
¯
X es el estimador de máxima verosimilitud para \mu}.
Queremos estimar
g ( \mu) = P}
\mu
(X \leq 0) = \Phi(− \mu ).
Por el principio de invariancia, tenemos que
g(ˆ \mu }
_{mv}
) = \Phi(−}
¯
X ) 
es el estimador de máxima verosimilitud para P
\mu
(X \leq 0).
**** Nota Bene En general, si \lambda = g(\theta), aunque g no sea biunívoca, se define el estimador de}
máxima verosimilitud de \lambda por
ˆ
\lambda = g ( 
ˆ
\theta
_{mv}
).
22
* Bibliografía consultada
Para redactar estas notas se consultaron los siguientes libros:
1. Bolfarine, H., Sandoval, M. C.: Introdu¸c˜ao `a Inferˆencia
   Estatística. SBM, Rio de Janeiro. (2001).
2. Borovkov, A. A.: Estadística matemática. Mir, Moscú. (1984).
3. Cramer, H.: Métodos matemáticos de estadística. Aguilar,
   Madrid. (1970).
4. Hoel P. G.: Introducción a la estadística matemática. Ariel,
   Barcelona. (1980).
5. Maronna R.: Probabilidad y Estadística Elementales para Estudiantes
   de Ciencias. Editorial Exacta, La Plata. (1995).
 
 
 
 
 
 
 
 







