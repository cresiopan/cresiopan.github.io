<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-12-09 Mon 19:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Concurrencia</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/res/nostyle"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="outline-container-org4a521ca" class="outline-2">
<h2 id="org4a521ca">Concurrencia y threads</h2>
<div class="outline-text-2" id="text-org4a521ca">
<p>
We use the word concurrency to refer to multiple activities that can
happen at the same time.
</p>


<div class="figure">
<p><img src="./img/4.1.png" alt="4.1.png" />
</p>
</div>

<p>
The key idea is to write a concurrent program — one with many
simultaneous activities — as a set of sequential streams of execution,
or threads, that interact and share results in very precise ways.
</p>

<p>
Threads let us define a set of tasks that run concurrently while the
code for each task is sequential. Each thread behaves as if it has its
own dedicated processor, as illustrated in Figure 4.1.
</p>

<p>
The thread abstraction lets the programmer create as many threads as
needed without worrying about the exact number of physical processors,
or exactly which processor is doing what at each instant. Of course,
threads are only an abstraction: the physical hardware has a limited
number of processors (and potentially only one!).
</p>

<p>
The operating system’s job is to provide the illusion of a nearly
infinite number of virtual processors even while the physical hardware
is more limited.
</p>
<pre class="example">
It sustains this illusion by transparently suspending and resuming
threads so that at any given time only a subset of the threads are
actively running.
</pre>
</div>

<div id="outline-container-org6d0606a" class="outline-3">
<h3 id="org6d0606a">Casos de uso de threads</h3>
<div class="outline-text-3" id="text-org6d0606a">
<p>
The intuition behind the thread abstraction is simple: in a program,
we can represent each concurrent task as a thread. Each thread
provides the abstraction of sequential execution similar to the
traditional programming model. In fact, we can think of a traditional
program as single-threaded with one logical sequence of steps as each
instruction follows the previous one.
</p>

<p>
A multi-threaded program is a generalization of the same basic
programming model. Each individual thread follows a single sequence of
steps as it executes statements, iterates through loops, calls/returns
from procedures, etc. However, a program can now have several such
threads executing at the same time.
</p>
</div>

<div id="outline-container-org1a4c0ae" class="outline-4">
<h4 id="org1a4c0ae">Razones para usar threads</h4>
<div class="outline-text-4" id="text-org1a4c0ae">
<ol class="org-ol">
<li>Program structure: expressing logically concurrent tasks. Programs
often interact with or simulate real-world applications that have
concurrent activities. Threads let you express an application’s
natural concurrency by writing each concurrent task as a separate
thread.</li>
<li>Responsiveness: shifting work to run in the background. To improve
user responsiveness and performance, a common design pattern is to
create threads to perform work in the background, without the user
waiting for the result.</li>
<li>Performance: exploiting multiple processors. Programs can use
threads on a multiprocessor to do work in parallel; they can do the
same work in less time or more work in the same elapsed time.  An
advantage to using threads for parallelism is that the number of
threads need not exactly match the number of processors in the
hardware on which it is running. The operating system transparently
switches which threads run on which processors.</li>
<li>Performance: managing I/O devices. To do useful work, computers
must interact with the outside world via I/O devices. By running
tasks as separate threads, when one task is waiting for I/O, the
processor can make progress on a different task.</li>
</ol>

<p>
The benefit of concurrency between the processor and the I/O is two-
fold:
</p>

<p>
First, processors are often much faster than the I/O systems with
which they interact, so keeping the processor idle during I/O would
waste much of its capacity. For example, the latency to read from disk
can be tens of milliseconds, enough to execute more than 10 million
instructions on a modern processor. After requesting a block from
disk, the operating system can switch to another program, or another
thread within the same program, until the disk completes and the
original thread is ready to resume.
</p>

<p>
Second, I/O provides a way for the computer to interact with external
entities, such as users pressing keys on a keyboard or a remote
computer sending network packets. The arrival of this type of I/O
event is unpredictable, so the processor must be able to work on other
tasks while still responding quickly to these external events.
</p>
</div>
</div>
</div>

<div id="outline-container-orgb6168b2" class="outline-3">
<h3 id="orgb6168b2">Abstraccion de Thread</h3>
<div class="outline-text-3" id="text-orgb6168b2">
<p>
A thread is a single execution sequence that represents a separately
</p>

<ul class="org-ul">
<li>Single execution sequence. Each thread executes a sequence of
instructions — assignments, conditionals, loops, procedures, and so
on — just as in the familiar sequential programming model.</li>
<li>Separately schedulable task. The operating system can run, suspend,
or resume a thread at any time.</li>
</ul>
</div>

<div id="outline-container-org7c342bb" class="outline-4">
<h4 id="org7c342bb">Ejecutar, Suspender y Resumir threads</h4>
<div class="outline-text-4" id="text-org7c342bb">
<p>
La ilusion de infinitos procesadores se logra medieante la ejecucion
de instrucciones de cada thread para que cada uno pueda progresar.
</p>

<p>
To map an arbitrary set of threads to a fixed set of processors,
operating systems include a <a id="org6680d56">thread scheduler</a> that can switch
between threads that are running and those that are ready but not
running. For example, in the previous Figure 4.1, a scheduler might
suspend thread 1 from processor 1, move it to the list of ready
threads, and then resume thread 5 by moving it from the ready list to
run on processor 1.
</p>

<p>
Switching between threads is transparent to the code being executed
within each thread. The abstraction makes each thread appear to be a
single stream of execution; this means the programmer can pay
attention to the sequence of instruction within a thread and not
whether or when that sequence may be (temporarily) suspended to let
another thread run.
</p>

<p>
Threads thus provide an execution model in which each thread runs on a
dedicated virtual processor with unpredictable and variable
speed. From the point of view of a thread’s code, each instruction
appears to execute immediately after the preceding one. However, the
scheduler may suspend a thread between one instruction and the next
and resume running it later.
</p>


<div class="figure">
<p><img src="./img/4.3.png" alt="4.3.png" />
</p>
</div>

<p>
Figure 4.3 illustrates a programmer’s view of a simple program and
three (of many) possible ways the program might be executed, depending
on what the scheduler does. From the thread’s point of view, other
than the speed of execution, the alternatives are equivalent. Indeed,
the thread would typically be unaware of which of these (or other)
executions actually occurs.
</p>

<p>
<img src="./img/4.4.png" alt="4.4.png" />
How threads are scheduled affects a thread’s interleavings with other
threads. Figure 4.4 shows some of the many possible interleavings of a
program with three threads.
</p>
</div>
</div>
</div>

<div id="outline-container-org1c8c2b1" class="outline-3">
<h3 id="org1c8c2b1">Thread API</h3>
<div class="outline-text-3" id="text-org1c8c2b1">
<p>
Figure 4.5 shows a simple API for using threads. This simplified API
is based on the POSIX standard pthreads API, but it omits some POSIX
options and error handling for simplicity.
</p>

<p>
there is no image 4.5.png
</p>

<p>
A good way to understand the simple threads API is that it provides a
way to invoke an <a id="org61adaa4">asynchronous procedure call</a>.
</p>

<p>
A normal procedure call passes a set of arguments to a function, runs
the function immediately on the caller’s stack, and when the function
is completed, returns control back to the caller with the result.
</p>

<p>
An <a href="#org61adaa4">asynchronous procedure call</a> separates the call from the return:
with thread<sub>create</sub>, the caller starts the function, but unlike a
normal procedure call, the caller continues execution concurrently
</p>
</div>

<div id="outline-container-org3954f16" class="outline-4">
<h4 id="org3954f16">Hello world multi-thread</h4>
<div class="outline-text-4" id="text-org3954f16">
<pre class="example">
#include &lt;stdio.h&gt;
#include "thread.h"

static void go(int n);

#define NTHREADS 10
static thread_t threads[NTHREADS];

int main(int argc, char **argv) {
    int i;
    long exitValue;

    for (i = 0; i &lt; NTHREADS; i++){
        thread_create(&amp;(threads[i]), &amp;go, i);
    }
    for (i = 0; i &lt; NTHREADS; i++){
        exitValue = thread_join(threads[i]);
        printf("Thread %d returned with %ld\n", i, exitValue);
    }
    printf("Main thread done.\n");
    return 0;
}

void go(int n) {
    printf("Hello from thread %d\n", n);
    thread_exit(100 + n);
    // not reached
}
</pre>

<p>
To illustrate how to use the simple threads API, Figure 4.6 shows a
very simple multi-threaded program written in ’C’. The main function
uses thread<sub>create</sub> to create 10 threads. The interesting arguments are
the second and third.
</p>

<ul class="org-ul">
<li>The second argument, go, is a function pointer — where the newly
created thread should begin execution.</li>
<li>The third argument, i, is passed to that function.</li>
</ul>

<p>
Thus, thread<sub>create</sub> initializes the i’th thread’s state so that it is
prepared to call the function go with the argument i.
</p>

<p>
When the scheduler runs the i’th thread, that thread runs the function
go with the value i as an argument and prints Hello from thread i. The
thread then returns the value (i + 100) by calling thread<sub>exit</sub>. This
call stores the specified value in a field in the thread<sub>t</sub> object so
that thread<sub>join</sub> can retrieve it.
</p>
</div>
</div>

<div id="outline-container-orge74250e" class="outline-4">
<h4 id="orge74250e">Paralelismo Fork join</h4>
<div class="outline-text-4" id="text-orge74250e">
<p>
Although the interface in Figure 4.5 is simple, it is remarkably
powerful.  Many multi-threaded applications can be designed using only
these thread operations and no additional synchronization. With
fork-join parallelism, a thread can create child threads to perform
work (“fork”, or thread<sub>create</sub>), and it can wait for their results
(“join”). Data may be safely shared between threads, provided it is
(a) written by the parent before the child thread starts or (b)
written by the child and read by the parent after the join.
</p>

<p>
If these sharing restrictions are followed, each thread executes
independently and in a deterministic fashion, unaffected by the
behavior of any other concurrently executing thread. The multiplexing
of threads onto processors has no effect other than performance.
</p>
</div>
</div>
</div>

<div id="outline-container-orgc41deff" class="outline-3">
<h3 id="orgc41deff">Estructuras de Datos de Threads y Ciclo de Vida</h3>
<div class="outline-text-3" id="text-orgc41deff">
<p>
As we have seen, each thread represents a sequential stream of
execution.  The operating system provides the illusion that each
thread runs on its own virtual processor by transparently suspending
and resuming threads.
</p>

<p>
For the illusion to work, the operating system must precisely save and
restore the state of a thread. However, because threads run either in
a process or in the kernel, there is also shared state that is not
saved or restored when switching the processor between threads.
</p>

<p>
Thus, to understand how the operating system implements the thread
abstraction, we must define both the per-thread state and the state
that is shared among threads. Then we can describe a thread’s life
cycle — how the operating system can create, start, stop, and delete
threads to provide the abstraction.
</p>


<div class="figure">
<p><img src="./img/4.5.png" alt="4.5.png" />
</p>
</div>
</div>

<div id="outline-container-org10e3ac6" class="outline-4">
<h4 id="org10e3ac6">Estado por Thread y <a href="#orgc720564">Thread Control Block</a> (TCB)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TCB">TCB</span></span></h4>
<div class="outline-text-4" id="text-org10e3ac6">
<p>
The operating system needs a data structure to represent a thread’s
state; a thread is like any other object in this regard. This data
structure is called the <a id="orgc720564">thread control block</a> (TCB). For every
thread the operating system creates, it creates one TCB.
</p>

<p>
The <a href="#orgc720564">thread control block</a> holds two types of per-thread information:
</p>
<ol class="org-ol">
<li>The state of the computation being performed by the thread.</li>
<li>Metadata about the thread that is used to manage the thread.</li>
</ol>
</div>

<div id="outline-container-org816f344" class="outline-5">
<h5 id="org816f344">Per-thread Computation State.</h5>
<div class="outline-text-5" id="text-org816f344">
<p>
To create multiple threads and to be able to start and stop each
thread as needed, the operating system must allocate space in the TCB
for the current state of each thread’s computation: a pointer to the
thread’s stack and a copy of its processor registers.
</p>

<ul class="org-ul">
<li>Stack. A thread’s stack is the same as the stack for a
single-threaded computation — it stores information needed by the
nested procedures the thread is currently running. For example, if a
thread calls foo(), foo() calls bar(), and bar() calls bas(), then
the stack would contain a stack frame for each of these three
procedures; each stack frame contains the local variables used by
the procedure, the parameters the procedure was called with, and the
return address to jump to when the procedure completes.</li>
</ul>
<p>
Because at any given time different threads can be in different states
  in their sequential computations — each can be in a different place
  in a different procedure called with different arguments from a
  different nesting of enclosing procedures — each thread needs its
  own stack.  When a new thread is created, the operating system
  allocates it a new stack and stores a pointer to that stack in the
  thread’s TCB. The stack is allocated in memory like any other data
  structure.
</p>
<ul class="org-ul">
<li>Copy of processor registers. A processor’s registers include not
only its general-purpose registers for storing intermediate values
for ongoing computations, but they also include special-purpose
registers, such as the instruction pointer and stack pointer.</li>
</ul>
<p>
To be able to suspend a thread, run another thread, and later resume
  the original thread, the operating system needs a place to store a
  thread’s registers when that thread is not actively running. In some
  systems, the general-purpose registers for a stopped thread are
  stored on the top of the stack, and the TCB contains only a pointer
  to the stack. In other systems, the TCB contains space for a copy of
  all processor registers.
</p>
</div>
</div>

<div id="outline-container-org2f4969e" class="outline-5">
<h5 id="org2f4969e">Per-thread Metadata.</h5>
<div class="outline-text-5" id="text-org2f4969e">
<p>
The TCB also includes per-thread metadata - information for managing
the thread. For example, each thread might have a thread ID,
scheduling priority, and status (e.g., whether the thread is waiting
for an event or is ready to be placed onto a processor).
</p>
</div>
</div>
</div>

<div id="outline-container-org8601be5" class="outline-4">
<h4 id="org8601be5">Estado Compartido</h4>
<div class="outline-text-4" id="text-org8601be5">
<p>
As opposed to per-thread state that is allocated for each thread, some
state is shared between threads running in the same process or within
the operating system kernel (Figure 4.8). In particular, program code
is shared by all threads in a process, although each thread may be
executing at a different place within that code. Additionally,
statically allocated global variables and dynamically allocated heap
variables can store information that is accessible to all threads.
</p>
</div>
</div>
</div>

<div id="outline-container-org843c128" class="outline-3">
<h3 id="org843c128">Ciclo de Vida de un thread</h3>
<div class="outline-text-3" id="text-org843c128">
<p>
Figure 4.9 shows the states of a thread durings its lifetime.
</p>


<div class="figure">
<p><img src="./img/4.9.png" alt="4.9.png" />
</p>
</div>
</div>

<div id="outline-container-orgeec545e" class="outline-4">
<h4 id="orgeec545e">INIT</h4>
<div class="outline-text-4" id="text-orgeec545e">
<p>
Thread creation puts a thread into its INIT state and allocates and
initializes per-thread data structures. Once that is done, thread
creation code puts the thread into the READY state by adding the
thread to the ready list. The ready list is the set of runnable
threads that are waiting their turn to use a processor. In practice,
the operating system typically uses a more sophisticated data
structure to keep track of runnable threads, such as a priority queue.
</p>
</div>
</div>

<div id="outline-container-orgdbbc5a5" class="outline-4">
<h4 id="orgdbbc5a5">READY</h4>
<div class="outline-text-4" id="text-orgdbbc5a5">
<p>
A thread in the READY state is available to be run but is not
currently running. Its TCB is on the ready list, and the values of its
registers are stored in its TCB. At any time, the scheduler can cause
a thread to transition from READY to RUNNING by copying its register
values from its TCB to a processor’s registers.
</p>
</div>
</div>

<div id="outline-container-org3879660" class="outline-4">
<h4 id="org3879660">RUNNING</h4>
<div class="outline-text-4" id="text-org3879660">
<p>
A thread in the RUNNING state is running on a processor. At this time,
its register values are stored on the processor rather than in the
TCB. A RUNNING thread can transition to the READY state in two ways:
</p>
<ul class="org-ul">
<li>The scheduler can <a href="#org10d4c14">preempt</a> a running thread and move it to the READY
state by: (1) saving the thread’s registers to its TCB and (2)
switching the processor to run the next thread on the ready list.</li>
<li>A running thread can voluntarily relinquish the processor and go
from RUNNING to READY by calling <a id="orgb309554">yield</a> (e.g., thread<sub><a href="#orgb309554">yield</a></sub> in
the thread library).</li>
</ul>
</div>
</div>

<div id="outline-container-org8da1f31" class="outline-4">
<h4 id="org8da1f31">WAITING</h4>
<div class="outline-text-4" id="text-org8da1f31">
<p>
A thread in the WAITING state is waiting for some event.  Whereas the
scheduler can move a thread in the READY state to the RUNNING state, a
thread in the WAITING state cannot run until some action by another
thread moves it from WAITING to READY.
</p>

<p>
While a thread waits for an event, it cannot make progress; therefore,
it is not useful to run it. Rather than continuing to run the thread
or storing the TCB on the scheduler’s ready list, the TCB is stored on
the waiting list of some <a href="#orgcc90e15">synchronization variable</a> associated with the
event. When the required event occurs, the operating system moves the
TCB from the <a href="#orgcc90e15">synchronization variable</a>’s waiting list to the
scheduler’s ready list, transitioning the thread from WAITING to
READY.
</p>
</div>
</div>

<div id="outline-container-org6f13136" class="outline-4">
<h4 id="org6f13136">FINISHED</h4>
<div class="outline-text-4" id="text-org6f13136">
<p>
A thread in the FINISHED state never runs again. The system can free
some or all of its state for other uses, though it may keep some
remnants of the thread in the FINISHED state for a time by putting the
TCB on a finished list. For example, the thread<sub>exit</sub> call lets a
thread pass its exit value to its parent thread via
thread<sub>join</sub>. Eventually, when a thread’s state is no longer needed
(e.g., after its exit value has been read by the join call), the
system can delete and reclaim the thread’s state.
</p>

<hr />

<p>
One way to understand these states is to consider where a thread’s TCB
and registers are stored, as shown in Figure 4.10. For example, all
threads in the READY state have their TCBs on the ready list and their
registers in the TCB. All threads in the RUNNING state have their TCBs
on the running list and their register values in hardware
registers. And all threads in the WAITING state have their TCBs on
various synchronization variables’ waiting lists.
</p>

<hr />
</div>
</div>
</div>

<div id="outline-container-org2e29d4e" class="outline-3">
<h3 id="org2e29d4e">Kernel Threads</h3>
<div class="outline-text-3" id="text-org2e29d4e">
<ul class="org-ul">
<li>Kernel threads. The simplest case is implementing threads inside the
operating system kernel, sharing one or more physical processors. A
<a id="org663f3ad">kernel thread</a> executes kernel code and modifies kernel data
structures. Almost all commercial operating systems today support
kernel threads.</li>
<li>Kernel threads and single-threaded processes. An operating system
with kernel threads might also run some single-threaded user
processes. As shown in Figure 4.11, these processes can invoke
system calls that run concurrently with kernel threads inside the
kernel.</li>
<li>Multi-threaded processes using kernel threads. Most operating
systems provide a set of library routines and system calls to allow
applications to use multiple threads within a single user-level
process. Figure 4.12 illustrates this case. These threads execute
user code and access user-level data structures. They also make
system calls into the operating system kernel. For that, they need a
kernel interrupt stack just like a normal single-threaded process.</li>
<li>User-level threads. To avoid having to make a system call for every
thread operation, some systems support a model where user-level
thread operations — create, <a href="#orgb309554">yield</a>, join, exit, and the
synchronization routines (other chapter) — are implemented entirely
in a user-level library, without invoking the kernel.</li>
</ul>


<div class="figure">
<p><img src="./img/4.11.png" alt="4.11.png" />
</p>
</div>


<div class="figure">
<p><img src="./img/4.12.png" alt="4.12.png" />
</p>
</div>
</div>

<div id="outline-container-org22d9b36" class="outline-4">
<h4 id="org22d9b36">Creando un thread</h4>
<div class="outline-text-4" id="text-org22d9b36">
<pre class="example">
// func is a pointer to a procedure the thread will run.
// arg is the argument to be passed to that procedure.
void
thread_create(thread_t *thread, void (*func)(int), int arg) {
    // Allocate TCB and stack
    TCB *tcb = new TCB();

    thread-&gt;tcb = tcb;
    tcb-&gt;stack_size = INITIAL_STACK_SIZE;
    tcb-&gt;stack = new Stack(INITIAL_STACK_SIZE);

    // Initialize registers so that when thread is resumed, it will start running at
    // stub.  The stack starts at the top of the allocated region and grows down.
    tcb-&gt;sp = tcb-&gt;stack + INITIAL_STACK_SIZE;
    tcb-&gt;pc = stub;

    // Create a stack frame by pushing stub’s arguments and start address
    // onto the stack: func, arg
    *(tcb-&gt;sp) = arg;
    tcb-&gt;sp--;
    *(tcb-&gt;sp) = func;
    tcb-&gt;sp--;

    // Create another stack frame so that thread_switch works correctly.
    // This routine is explained later in the chapter.
    thread_dummySwitchFrame(tcb);

    tcb-&gt;state = READY;
    readyList.add(tcb);   // Put tcb on ready list
}

void
stub(void (*func) (int), int arg) {
    (*func) (arg);     // Execute the function func()
    thread_exit(0);    // If func () does not call exit, call it here.
}
</pre>

<p>
Figure 4.13 shows the pseudo-code to allocate a new thread. The goal
of thread<sub>create</sub> is to perform an <a href="#org61adaa4">asynchronous procedure call</a> to func
with arg as the argument to that procedure. When the thread runs, it
will execute func(arg) concurrently with the calling thread.
</p>

<p>
There are three steps to creating a thread:
</p>
<ol class="org-ol">
<li>Allocate per-thread state. The first step in the thread constructor
is to allocate space for the thread’s per-thread state: the TCB and
stack.</li>
<li>Initialize per-thread state. To initialize the TCB, the thread
constructor sets the new thread’s registers to what they need to be
when the thread starts RUNNING. When the thread is assigned a
processor, we want it to start running func(arg). However, instead
of having the thread start in func, the constructor starts the
thread in a dummy function, stub, which in turn calls func.</li>
</ol>
<p>
We need this extra step in case the func procedure returns instead of
   calling thread<sub>exit</sub>. Without the stub, func would return to
   whatever random location is stored at the top of the stack!
   Instead, func returns to stub and stub calls thread<sub>exit</sub> to finish
   the thread. To start at the beginning of stub, the thread
   constructor sets up the stack as if stub was just called by normal
   code; the specifics will depend on the calling convention of the
   machine. In the pseudo-code, we push stub’s two arguments onto the
   stack: func and arg. When the thread starts running, the code in
   stub will access its arguments just like a normal procedure. In
   addition, we also push a dummy stack frame for thread<sub>switch</sub> onto
   the stack (more on this later).
</p>
<ol class="org-ol">
<li>Put TCB on ready list. The last step in creating a thread is to set
its state to READY and put the new TCB on the ready list, enabling
the thread to be scheduled.</li>
</ol>
</div>
</div>

<div id="outline-container-orgd64f0d2" class="outline-4">
<h4 id="orgd64f0d2">Eliminando un thread</h4>
<div class="outline-text-4" id="text-orgd64f0d2">
<p>
When a thread calls thread<sub>exit</sub>, there are two steps to deleting the
thread:
</p>
<ul class="org-ul">
<li>Remove the thread from the ready list so that it will never run
again.</li>
<li>Free the per-thread state allocated for the thread.</li>
</ul>

<p>
Although this seems easy, there is an important subtlety: if a thread
removes itself from the ready list and frees its own per-thread state,
then the program may break. For example, if a thread removes itself
from the ready list but an interrupt occurs before the thread finishes
de-allocating its state, there is a memory leak: that thread will
never resume to de- allocate its state.
</p>

<p>
Worse, suppose that a thread frees its own state? Can the thread
finish running the code in thread<sub>exit</sub> if it does not have a stack?
What happens if an interrupt occurs just after the running thread’s
stack has been de- allocated? If the context switch code tries to save
the current thread’s state, it will be writing to de-allocated memory,
possibly to storage that another processor has re-allocated for some
other data structure. The result could be corrupted memory, where the
specific behavior depends on the precise sequence of events. Needless
to say, such a bug would be very difficult to locate.
</p>

<p>
Fortunately, there is a simple fix: a thread never deletes its own
state.  Instead, some other thread must do it. On exit, the thread
transitions to the FINISHED state, moves its TCB from the ready list
to a list of finished threads the scheduler should never run. The
thread can then safely switch to the next thread on the ready
list. Once the finished thread is no longer running, it is safe for
some other thread to free the state of the thread.
</p>
</div>
</div>

<div id="outline-container-org8524657" class="outline-4">
<h4 id="org8524657">Context Switch de Threads&#xa0;&#xa0;&#xa0;<span class="tag"><span class="context">context</span>&#xa0;<span class="switch">switch</span></span></h4>
<div class="outline-text-4" id="text-org8524657">
<p>
To support multiple threads, we also need a mechanism to switch which
threads are RUNNING and which are READY.
</p>

<p>
A <a id="org7584417">thread context switch</a> suspends execution of a currently
running thread and resumes execution of some other thread. The switch
saves the currently running thread’s registers to the thread’s TCB and
stack, and then it restores the new thread’s registers from that
thread’s TCB and stack into the processor.
</p>

<p>
We need to answer several questions:
</p>
<ul class="org-ul">
<li>What triggers a context switch?</li>
<li>How does a voluntary context switch work?</li>
<li>How does an involuntary context switch differ from a voluntary one?</li>
<li>What thread should the scheduler choose to run next?</li>
</ul>

<hr />
</div>

<div id="outline-container-orgc2e6dc5" class="outline-5">
<h5 id="orgc2e6dc5">What Triggers a <a href="#org663f3ad">Kernel Thread</a> Context Switch? A <a href="#org7584417">thread context switch</a></h5>
<div class="outline-text-5" id="text-orgc2e6dc5">
<p>
can be triggered by either a voluntary call into the thread library,
or an involuntary interrupt or processor exception.
</p>

<ul class="org-ul">
<li>Voluntary. The thread could call a thread library function that
triggers a context switch. For example the thread<sub><a href="#orgb309554">yield</a></sub> call that
lets the currently running thread voluntarily give up the processor
to the next thread on the ready list. Similarly, the thread<sub>join</sub> and
thread<sub>exit</sub> calls suspend execution of the current thread and start
running a different one.</li>
<li>Involuntary. An interrupt or processor exception could invoke an
interrupt handler. The interrupt hardware saves the state of the
running thread and executes the handler’s code. The handler can
decide that some other thread should run, and then switch to
it. Alternatively, if the current thread should continue running,
the handler restores the state of the interrupted thread and resumes
execution. Other I/O hardware events also invoke interrupt handlers.</li>
</ul>

<p>
Regardless, the thread system must save the current processor state,
so that when the current thread resumes execution, it appears to the
thread as if the event never occurred except for some time having
elapsed. This provides the abstraction of thread execution on a
virtual processor with unpredictable and variable speed.
</p>
</div>

<div id="outline-container-orgf4819e7" class="outline-6">
<h6 id="orgf4819e7">Voluntary <a href="#org663f3ad">Kernel Thread</a> Context Switch</h6>
<div class="outline-text-6" id="text-orgf4819e7">
<pre class="example">
// We enter as oldThread, but we return as newThread.
// Returns with newThread’s registers and stack.
void thread_switch(oldThreadTCB, newThreadTCB) {
    pushad;                  // Push general register values onto the old stack.
    oldThreadTCB-&gt;sp = %esp; // Save the old thread’s stack pointer.
    %esp = newThreadTCB-&gt;sp; // Switch to the new stack.
    popad;            // Pop register values from the new stack.
    return;
}

void thread_yield() {
    TCB *chosenTCB, *finishedTCB;

    // Prevent an interrupt from stopping us in the middle of a switch.
    disableInterrupts();

    // Choose another TCB from the ready list.
    chosenTCB = readyList.getNextThread();
    if (chosenTCB == NULL) {
        // Nothing else to run, so go back to running the original thread.
    } else {
        // Move running thread onto the ready list.
        runningThread-&gt;state = ready;
        readyList.add(runningThread);
        thread_switch(runningThread, chosenTCB); // Switch to the new thread.
        runningThread-&gt;state = running;
    }

    // Delete any threads on the finished list.
    while ((finishedTCB = finishedList-&gt;getNextThread()) != NULL) {
        delete finishedTCB-&gt;stack;
        delete finishedTCB;
    }
    enableInterrupts();
}

// thread_create must put a dummy frame at the top of its stack:
// the return PC and space for pushad to have stored a copy of the registers.
// This way, when someone switches to a newly created thread,
// the last two lines of thread_switch work correctly.
void thread_dummySwitchFrame(newThread) {
    *(tcb-&gt;sp) = stub;      // Return to the beginning of stub.
    tcb-&gt;sp--;
    tcb-&gt;sp -= SizeOfPopad;
}
</pre>

<p>
The pseudo-code for thread<sub><a href="#orgb309554">yield</a></sub> first turns off interrupts to prevent
the thread system from attempting to make two context switches at the
same time. The pseudo-code then pulls the next thread to run off the
ready list (if any), and switches to it.
</p>

<p>
The thread<sub>switch</sub> code may seem tricky, since it is called in the
context of the old thread and finishes in the context of the new
thread. To make this work, thread<sub>switch</sub> saves the state of the
registers to the stack and saves the stack pointer to the TCB. It then
switches to the stack of the new thread, restores the new thread’s
state from the new thread’s stack, and returns to whatever program
counter is stored on the new stack.
</p>

<p>
A twist is that the return location may not be to thread<sub><a href="#orgb309554">yield</a></sub>! The
return is to whatever the new thread was doing beforehand. For
example, the new thread might have been WAITING in thread<sub>join</sub> and is
now READY to run.  The thread might have called thread<sub><a href="#orgb309554">yield</a></sub>. Or it
might be a newly created thread just starting to run.
</p>

<p>
It is essential that any routine that causes the thread to <a href="#orgb309554">yield</a> or
block call thread<sub>switch</sub> in the same way. Equally, to create a new
thread, thread<sub>create</sub> must set up the stack of the new thread to be as
if it had suspended execution just before performing its first
instruction. Then, if the newly created thread is the next thread to
run, a thread can call thread<sub><a href="#orgb309554">yield</a></sub>, switch to the newly created
thread, switch to its stack pointer, pop the register values off the
stack, and “return” to the new thread, even though it had never called
switch in the first place.
</p>
</div>
</div>

<div id="outline-container-org93e9cab" class="outline-6">
<h6 id="org93e9cab">Involuntary <a href="#org663f3ad">Kernel Thread</a> Context Switch</h6>
<div class="outline-text-6" id="text-org93e9cab">
<p>
When an interrupt, exception, or trap interrupts a running user-level
process: hardware and software work together to save the state of the
interrupted process, run the kernel’s handler, and restore the state
of the interrupted process.
</p>

<p>
The mechanism is almost identical when an interrupt or trap triggers a
thread switch between threads in the kernel.
</p>

<ol class="org-ol">
<li>Save the state. Save the currently running thread’s registers so
that the handler can run code without disrupting the interrupted
thread. Hardware saves some state when the interrupt or exception
occurs, and software saves the rest of the state when the handler
runs.</li>
<li>Run the kernel’s handler. Run the kernel’s handler code to handle
the interrupt or exception. Since we are already in kernel mode, we
do not need to change from user to kernel mode in this step. We
also do not need to change the stack pointer to the base of the
kernel’s interrupt stack. Instead, we can just push saved state or
handler variables onto the current stack, starting from the current
stack pointer.</li>
<li>Restore the state. Restore the next ready thread’s registers so
that the thread can resume running where it left off.</li>
</ol>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org1caca08" class="outline-3">
<h3 id="org1caca08">Combinando Kernel Threads y Procesos de usuario Mono-thread</h3>
</div>
<div id="outline-container-org6979925" class="outline-3">
<h3 id="org6979925">Implementando Procesos Multi-thread</h3>
</div>
<div id="outline-container-orgab67b36" class="outline-3">
<h3 id="orgab67b36">Abstracciones alternativas</h3>
</div>
</div>
<div id="outline-container-org0dd8e77" class="outline-2">
<h2 id="org0dd8e77">Sincronizando Acceso a Objetos Compartidos</h2>
<div class="outline-text-2" id="text-org0dd8e77">
<p>
If a program has <a id="org1ec8357">independent threads</a> that operate on completely
separate subsets of memory, we can reason about each thread
separately. In this case, reasoning about <a href="#org1ec8357">independent threads</a> differs
little from reasoning about a series of independent, single-threaded
programs.
</p>

<p>
However, most multi-threaded programs have both per-thread state
(e.g., a thread’s stack and registers) and shared state (e.g., shared
variables on the heap). <a id="orgccc6eb1">Cooperating threads</a> read and write
shared state.
</p>

<p>
Sharing state is useful because it lets threads communicate,
coordinate work, and share information.
</p>

<p>
The sequential model of reasoning does not work in programs with
<a href="#orgccc6eb1">cooperating threads</a>, for three reasons:
</p>
<ol class="org-ol">
<li>Program execution depends on the possible interleavings of threads’
access to shared state. For example, if two threads write a shared
variable, one thread with the value 1 and the other with the value
2, the final value of the variable depends on which of the threads’
writes finishes last.</li>
<li>Program execution can be nondeterministic. Different runs of the
same program may produce different results. For example, the
scheduler may make different scheduling decisions, the processor
may run at a different frequency, or another concurrently running
program may affect the cache hit rate. Even common debugging
techniques — such as running a program under a debugger,
recompiling with the -g option instead of -O, or adding a printf —
can change how a program behaves.</li>
<li>Compilers and processor hardware can reorder instructions. Modern
compilers and hardware reorder instructions to improve
performance. This reordering is generally invisible to
single-threaded programs; compilers and processors take care to
ensure that dependencies within a single sequence of instructions —
that is, within a thread — are preserved. However, reordering can
become visible when multiple threads interact through accessing
shared variables.</li>
</ol>

<p>
We introduce a structured synchronization approach to sharing state in
multi-threaded programs which is:
(1) structure the program to facilitate reasoning about concurrency,
and
(2) use a set of standard synchronization primitives to control access
to shared state.
</p>
</div>

<div id="outline-container-org35a65cd" class="outline-4">
<h4 id="org35a65cd">Challenges</h4>
<div class="outline-text-4" id="text-org35a65cd">
</div>
<div id="outline-container-orgd6a2933" class="outline-5">
<h5 id="orgd6a2933">Race Condition&#xa0;&#xa0;&#xa0;<span class="tag"><span class="raceCondition">raceCondition</span></span></h5>
<div class="outline-text-5" id="text-orgd6a2933">
<p>
A &lt;<a id="orge97cab4"></a> occurs when the behavior of a program depends on
the interleaving of operations of different threads. In effect, the
threads run a race between their operations, and the results of the
program execution depends on who wins the race.
</p>
</div>
</div>

<div id="outline-container-orgba32b7c" class="outline-5">
<h5 id="orgba32b7c">Operaciones atomicas</h5>
<div class="outline-text-5" id="text-orgba32b7c">
<p>
Atomic operations are indivisible operations that cannot be interleaved
with or split by other operations.
</p>
</div>
</div>

<div id="outline-container-orgb4a7f1a" class="outline-5">
<h5 id="orgb4a7f1a">Too much milk (Problema y solucion no optima)</h5>
<div class="outline-text-5" id="text-orgb4a7f1a">
<p>
We illustrate the problems with using atomic loads and stores using a
simple problem called, “Too Much Milk.”
</p>

<p>
The Too Much Milk problem models two roommates who share a
refrigerator and who — as good roommates — make sure the refrigerator
is always well stocked with milk. With such responsible roommates, the
following scenario is possible:
</p>

<p>
missig example
</p>

<p>
We can model each roommate as a thread and the number of bottles of
milk in the fridge with a variable in memory. If the only atomic
operations on shared state are atomic loads and stores to memory, is
there a solution to the Too Much Milk problem that ensures both safety
(the program never enters a bad state) and liveness (the program
eventually enters a good state)? Here, we strive for the following
properties:
</p>
<ul class="org-ul">
<li>Safety: Never more than one person buys milk.</li>
<li>Liveness: If milk is needed, someone eventually buys it.</li>
</ul>

<p>
Solution 1.
</p>
<ul class="org-ul">
<li>A roommate leaves a note on the fridge before going to the store.</li>
<li>To do this we set a flag when going to buy milk and to check this
flag before going to buy milk.</li>
</ul>

<p>
Each thread might run the following code:
</p>

<pre class="example">
if (milk==0) {       // if no milk
    if (note==0) {   // if no note
        note = 1;    // leave note
        milk++;      // buy milk
        note = 0;    // remove note
    }
}
</pre>

<p>
This implementation can violate safety, because TA might check for the
milk, then get context switched, then TB would run all its code, then
switch back to TA, and TA would go to buy more milk.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">// Thread A</td>
<td class="org-left">// Thread B</td>
</tr>

<tr>
<td class="org-left">if (milk==0) {</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">if (milk==0) {</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">if (note==0) {</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">note = 1;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">milk++;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">note = 0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">}</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">}</td>
</tr>

<tr>
<td class="org-left">if (note==0) {</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">note = 1;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">milk++;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">note = 0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">}</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">}</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
Solution 2. In solution 1, the roommate checks the note before setting
it.  This opens up the possibility that one roommate has already made
a decision to buy milk before notifying the other roommate of that
decision.  If we use two variables for the notes, a roommate can
create a note before checking the other note and the milk and making a
decision to buy.
</p>

<p>
Path A
</p>
<pre class="example">
noteA = 1;         // leave note
if (noteB==0) {    // if no note  A1
    if (milk==0) { // if no milk  A2
        milk++;    // buy milk    A3
    }
}
noteA = 0;         // remove note A
</pre>

<p>
Path B
</p>
<pre class="example">
noteB = 1;         // leave note
if (noteA==0) {    // if no note  B1
    if (milk==0) { // if no milk  B2
        milk++;    // buy milk    B3
    }              //             B4
}                  //             B5
</pre>

<p>
This solution is Safe but not Live, it is possible for both threads to
set their respective notes, for each thread to check the other
thread’s note, and for both threads to decide not to buy milk.
</p>

<p>
Solution 3. We ensure that at least one of the threads determines
whether the other thread has bought milk or not before deciding
whether or not to buy.
</p>

<p>
Path A
</p>
<pre class="example">
noteA = 1;         // leave note A
while (noteB==1) { // wait for no note B
    ;              // spin
}
if (milk==0) {     // if no milk M
    milk++;        // buy milk
}
noteA = 0;         // remove note A
</pre>

<p>
Path B
</p>
<pre class="example">
noteB = 1;          // leave note B
if (noteA==0) {     // if no note A
    if (milk==0) {  // if no milk
        milk++;     // buy milk
    }               //
}                   //
noteB = 0;          // remove note B
</pre>

<p>
This solution is both Safe and Live.
</p>
</div>
</div>

<div id="outline-container-org16f97af" class="outline-5">
<h5 id="org16f97af">Una Solucion Mejor</h5>
<div class="outline-text-5" id="text-org16f97af">
<p>
We write <a href="#orgb1ff876">shared objects</a> that use synchronization objects to coordinate
different threads’ access to shared state.
</p>

<p>
We have a primitive called a <a href="#org43286d2">lock</a> that only one thread at a time can
own. Then, we can solve the Too Much Milk problem by defining the
class for a Kitchen object with the following method:
</p>

<pre class="example">
Kitchen::buyIfNeeded() {
    lock.acquire();
    if (milk == 0) {     // if no milk
        milk++;          // buy milk
    }
    lock.release();
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org190c1fa" class="outline-4">
<h4 id="org190c1fa">Estructurando Objetos Compartidos</h4>
<div class="outline-text-4" id="text-org190c1fa">
<p>
Figure 5.1 illustrates, a multi-threaded program is built using <a href="#orgb1ff876">shared
objects</a> and a set of threads that operate on them.
</p>


<div class="figure">
<p><img src="./img/5.1.png" alt="5.1.png" />
</p>
</div>

<p>
<a id="orgb1ff876">Shared objects</a> are objects that can be accessed safely by
multiple threads.  All shared state in a program — including variables
allocated on the heap and static, global variables — should be
encapsulated in one or more <a href="#orgb1ff876">shared objects</a>.
</p>

<p>
Since <a href="#orgb1ff876">shared objects</a> encapsulate the program’s shared state, the main
loop code that defines a thread’s high-level actions need not concern
itself with synchronization details.
</p>

<p>
A <a id="orgcc90e15">synchronization variable</a> is a data structure used for
coordinating concurrent access to shared state. Both the interface and
the implementation of synchronization variables must be carefully
designed. In particular, we build <a href="#orgb1ff876">shared objects</a> using two types of
synchronization variables: locks and <a href="#org2d717b6">condition variables</a>.
</p>

<p>
Synchronization variables coordinate access to state variables, which
are just the normal member variables of an object that you are
familiar with from single-threaded programming.
</p>
</div>
</div>

<div id="outline-container-orgdce50a3" class="outline-3">
<h3 id="orgdce50a3">Locks: Exclusion Mutua&#xa0;&#xa0;&#xa0;<span class="tag"><span class="lock">lock</span></span></h3>
<div class="outline-text-3" id="text-orgdce50a3">
<p>
A <a id="org43286d2">lock</a> is a <a href="#orgcc90e15">synchronization variable</a> that provides &lt;&lt;&lt;mutual
exclusion&gt;&gt;&gt; — when one thread holds a <a href="#org43286d2">lock</a>, no other thread can hold
it (i.e., other threads are excluded). A program associates each <a href="#org43286d2">lock</a>
with some subset of shared state and requires a thread to hold the
<a href="#org43286d2">lock</a> when accessing that state. Then, only one thread can access the
shared state at a time.
</p>
</div>

<div id="outline-container-orga721173" class="outline-4">
<h4 id="orga721173">API de Locks</h4>
<div class="outline-text-4" id="text-orga721173">
<p>
A <a href="#org43286d2">lock</a> enables mutual exclusion by providing two methods:
<a href="#org43286d2">Lock</a>::acquire() and <a href="#org43286d2">Lock</a>::release(). These methods are defined as
follows:
</p>
<ul class="org-ul">
<li>A <a href="#org43286d2">lock</a> can be in one of two states: BUSY or FREE.</li>
<li>A <a href="#org43286d2">lock</a> is initially in the FREE state.</li>
<li><a href="#org43286d2">Lock</a>::acquire waits until the <a href="#org43286d2">lock</a> is FREE and then atomically makes
the <a href="#org43286d2">lock</a> BUSY.</li>
<li><a href="#org43286d2">Lock</a>::release makes the <a href="#org43286d2">lock</a> FREE. If there are pending acquire
operations, this state change causes one of them to proceed.</li>
</ul>

<p>
Using locks makes solving the Too Much Milk problem trivial. Both
threads run the following code:
</p>

<pre class="example">
lock.acquire();
if (milk == 0) {     // if no milk
    milk++;          // buy milk
}
lock.release();
</pre>

<p>
Formal Properties. A <a href="#org43286d2">lock</a> can be defined more precisly as follows.
</p>

<pre class="example">
A thread holds a lock if it has returned from a lock’s acquire method
more often than it has returned from a lock’s release method.
</pre>

<pre class="example">
A thread is attempting to acquire a lock if it has called but not yet
returned from a call to aquire on the lock.
</pre>

<p>
A <a href="#org43286d2">lock</a> should ensure the following three properties:
</p>
<ol class="org-ol">
<li>Mutual Exclusion. At most one thread holds the <a href="#org43286d2">lock</a>.</li>
<li>Progress. If no thread holds the <a href="#org43286d2">lock</a> and any thread attempts to
acquire the <a href="#org43286d2">lock</a>, then eventually some thread succeeds in acquiring
the <a href="#org43286d2">lock</a>.</li>
<li>Bounded waiting. If thread T attempts to acquire a <a href="#org43286d2">lock</a>, then there
exists a bound on the number of times other threads can
successfully acquire the <a href="#org43286d2">lock</a> before T does.</li>
</ol>
</div>
</div>

<div id="outline-container-org6146ae7" class="outline-4">
<h4 id="org6146ae7">Caso de estudio: Cola Limitada Thread-Safe</h4>
<div class="outline-text-4" id="text-org6146ae7">
<pre class="example">
// Thread-safe queue interface

const int MAX = 10;

class TSQueue {
  // Synchronization variables
    Lock lock;

  // State variables
    int items[MAX];
    int front;
    int nextEmpty;

  public:
    TSQueue();
    ~TSQueue(){};
    bool tryInsert(int item);
    bool tryRemove(int *item);
};

// Initialize the queue to empty
// and the lock to free.
TSQueue::TSQueue() {
    front = nextEmpty = 0;
}

// Try to insert an item. If the queue is
// full, return false; otherwise return true.
bool
TSQueue::tryInsert(int item) {
    bool success = false;

    lock.acquire();
    if ((nextEmpty - front) &lt; MAX) {
        items[nextEmpty % MAX] = item;
        nextEmpty++;
        success = true;
    }
    lock.release();
    return success;
}

// Try to remove an item. If the queue is
// full, return false; otherwise return true.
bool
TSQueue::tryInsert(int item) {
    bool success = false;

    lock.acquire();
    if ((nextEmpty - front) &lt; MAX) {
        items[nextEmpty % MAX] = item;
        nextEmpty++;
        success = true;
    }
    lock.release();
    return success;
}

// Try to remove an item. If the queue is
// empty, return false; otherwise return true.
bool
TSQueue::tryRemove(int *item) {
    bool success = false;

    lock.acquire();
    if (front &lt; nextEmpty) {
        *item = items[front % MAX];
        front++;
        success = true;
    }
    lock.release();
    return success;
}
</pre>


<div class="figure">
<p><img src="./img/5.4.png" alt="5.4.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org2c32ffa" class="outline-4">
<h4 id="org2c32ffa">Critical Sections</h4>
<div class="outline-text-4" id="text-org2c32ffa">
<p>
A <a id="org332cfc2">critical section</a> is a sequence of code that atomically
accesses shared state.  By ensuring that a thread holds the object’s
<a href="#org43286d2">lock</a> while executing any of its critical sections, we ensure that each
<a href="#org332cfc2">critical section</a> appears to execute atomically on its shared
state.
</p>

<p>
WARNING: Put <a href="#orgb1ff876">shared objects</a> on the heap, not the stack. The compiler
allocates automatic variables (sometimes called “local variables”,
with good reason) on the stack during procedure invocation. If one
thread passes a pointer or reference to one of its automatic variables
to another thread and later returns from the procedure where the
automatic variable was allocated, then that second thread now has a
pointer into a region of the first thread’s stack that may be used for
other purposes.
</p>
</div>
</div>
</div>

<div id="outline-container-orgfab441a" class="outline-3">
<h3 id="orgfab441a"><a href="#org2d717b6">Condition Variables</a>: Esperando por un Cambio&#xa0;&#xa0;&#xa0;<span class="tag"><span class="conditionVariable">conditionVariable</span></span></h3>
<div class="outline-text-3" id="text-orgfab441a">
<p>
<a id="org2d717b6">Condition variables</a> provide a way for one thread to wait for
another thread to take some action. For example, in the thread-safe
queue example in Figure 5.4, rather than returning an error when we
try to remove an item from an empty queue, we might wait until the
queue is non-empty, and then always return an item.
</p>

<p>
In all of these cases, we want a thread to wait for some action to
change the system state so that the thread can make progress.
</p>

<pre class="example">
int
TSQueue::remove() {
    int item;
    bool success;

    do {
        success = tryRemove(&amp;item);
    } until(success);
    return item;
}
</pre>
</div>

<div id="outline-container-org84842f3" class="outline-4">
<h4 id="org84842f3">Definicion</h4>
<div class="outline-text-4" id="text-org84842f3">
<p>
A <a id="orge7a9600">condition variable</a> is a synchronization object that lets a
thread efficiently wait for a change to shared state that is protected
by a <a href="#org43286d2">lock</a>. A <a href="#orge7a9600">condition variable</a> has three methods:
</p>
<ul class="org-ul">
<li>CV::wait(<a href="#org43286d2">Lock</a> *<a href="#org43286d2">lock</a>). This call atomically releases the <a href="#org43286d2">lock</a> and
suspends execution of the calling thread, placing the calling thread
on the <a href="#orge7a9600">condition variable</a>’s waiting list. Later, when the calling
thread is re-enabled, it re-acquires the <a href="#org43286d2">lock</a> before returning from
the wait call.</li>
<li>CV::signal(). This call takes one thread off the <a href="#orge7a9600">condition
variable</a>’s waiting list and marks it as eligible to run (i.e., it
puts the thread on the scheduler’s ready list). If no threads are on
the waiting list, signal has no effect.</li>
<li>CV::broadcast(). This call takes all threads off the <a href="#orge7a9600">condition
variable</a>’s waiting list and marks them as eligible to run. If no
threads are on the waiting list, broadcast has no effect.</li>
</ul>

<p>
A <a href="#orge7a9600">condition variable</a> is used to wait for a change to shared state, and
a <a href="#org43286d2">lock</a> must always protect updates to shared state. Thus, the
<a href="#orge7a9600">condition variable</a> API is designed to work in concert with locks. All
three methods (wait, signal, and broadcast) should only be called
while the associated <a href="#org43286d2">lock</a> is held.
</p>

<pre class="example">
SharedObject::someMethodThatWaits() {
    lock.acquire();

    // Read and/or write shared state here.

    while (!testOnSharedState()) {
        cv.wait(&amp;lock);
    }
    assert(testOnSharedState());

    // Read and/or write shared state here.

    lock.release();
}

SharedObject::someMethodThatSignals() {
    lock.acquire();

    // Read and/or write shared state here.

    // If state has changed in a way that
    // could allow another thread to make
    // progress, signal (or broadcast).

    cv.signal();

    lock.release();
}
</pre>

<p>
In this code, the calling thread first
acquires the <a href="#org43286d2">lock</a> and can then read and write the shared object’s state
variables. To wait until testOnSharedState succeeds, the thread calls
wait on the shared object’s <a href="#orge7a9600">condition variable</a> cv. This atomically puts the
thread on the waiting list and releases the <a href="#org43286d2">lock</a>, allowing other threads to
enter the <a href="#org332cfc2">critical section</a>. Once the waiting thread is signaled, it re-acquires
the <a href="#org43286d2">lock</a> and returns from wait. The monitor can then safely test the state
variables to see if testOnSharedState succeeds. If so, the monitor performs
its tasks, releases the <a href="#org43286d2">lock</a>, and returns.
</p>

<p>
The method someMethodThatSignals() shows the complementary code that
causes a waiting thread to wake up. Whenever a thread changes the
shared object’s state in a way that enables a waiting thread to make
progress, the thread must signal the waiting thread using the
<a href="#orge7a9600">condition variable</a>.
</p>
</div>
</div>

<div id="outline-container-orgcae2285" class="outline-4">
<h4 id="orgcae2285">Propiedades</h4>
<div class="outline-text-4" id="text-orgcae2285">
<ul class="org-ul">
<li>A <a href="#orge7a9600">condition variable</a> is memoryless.</li>
</ul>
<p>
The <a href="#orge7a9600">condition variable</a>, has no internal state other than a queue of
waiting threads. <a href="#org2d717b6">Condition variables</a> do not need their own state
because they are always used inside <a href="#orgb1ff876">shared objects</a> that have their own
state.
</p>

<p>
If no threads are currently on the <a href="#orge7a9600">condition variable</a>’s waiting list,
a signal or broadcast has no effect. No thread calls wait unless it
holds the <a href="#org43286d2">lock</a>, checks the state variables, and finds that it needs to
wait. After signal is called, if sometime later another thread calls
wait, it will block until the next signal (or broadcast) is called,
regardless of how many times signal has been called in the past.
</p>
<ul class="org-ul">
<li>CV::wait atomically releases the <a href="#org43286d2">lock</a>.</li>
</ul>
<p>
A thread always calls wait while holding a <a href="#org43286d2">lock</a>. The call to wait
atomically releases the <a href="#org43286d2">lock</a> and puts the thread on the <a href="#orge7a9600">condition
variable</a>’s waiting list.
</p>
<ul class="org-ul">
<li>When a waiting thread is re-enabled via signal or broadcast, it may</li>
</ul>
<p>
not run immediately.
</p>

<pre class="example">
wait must always be called from within a loop
</pre>

<p>
Because wait releases the <a href="#org43286d2">lock</a>, and because there is no guarantee of
atomicity between signal or broadcast and the return of a call to
wait, there is no guarantee that the checked-for state still
holds. Therefore, a waiting thread must always wait in a loop,
rechecking the state until the desired predicate holds.
</p>

<pre class="example">
...
while (predicateOnStateVariables(...)) {
    wait(&amp;lock);
}
...
</pre>

<p>
and not
</p>

<pre class="example">
...
if (predicateOnStateVariables(...)) {
    wait(&amp;lock);
}
...
</pre>
</div>
</div>

<div id="outline-container-org89d30ba" class="outline-4">
<h4 id="org89d30ba">Ciclo de Vida (Actualizado)</h4>
<div class="outline-text-4" id="text-org89d30ba">
<p>
A RUNNING thread that calls wait is put in the WAITING state. This is
typically implemented by moving the <a href="#orgc720564">thread control block</a> (TCB) from
the ready list to the <a href="#orge7a9600">condition variable</a>’s list of waiting
threads. Later, when some RUNNING thread calls signal or broadcast on
that <a href="#orge7a9600">condition variable</a>, one (if signal) or all (if broadcast) of the
TCBs on that <a href="#orge7a9600">condition variable</a>’s waiting list are moved to the ready
list. This changes those threads from the WAITING state to the READY
state. At some later time, the scheduler selects a READY thread and
runs it by moving it to the RUNNING state.  Eventually, the signaled
thread runs.
</p>

<p>
Locks are similar. A <a href="#org43286d2">lock</a> acquire on a busy <a href="#org43286d2">lock</a> puts the caller into
the WAITING state, with the caller’s TCB on a list of waiting TCBs
associated with the <a href="#org43286d2">lock</a>. Later, when the <a href="#org43286d2">lock</a> owner calls release,
one waiting TCB is moved to the ready list, and that thread
transitions to the READY state.
</p>

<p>
Notice that threads that are RUNNING or READY have their state located
at a pre-defined, “global” location: the CPU (for a RUNNING thread) or
the scheduler’s list of ready threads (for a READY thread). However,
threads that are WAITING typically have their state located on some
per-<a href="#org43286d2">lock</a> or per-condition-variable queue of waiting threads. Then, a
signal, broadcast, or release call can easily find and re-enable a
waiting thread for that particular <a href="#orge7a9600">condition variable</a> or <a href="#org43286d2">lock</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-org404fdde" class="outline-3">
<h3 id="org404fdde">Semaforos</h3>
</div>
</div>
<div id="outline-container-org1fed83e" class="outline-2">
<h2 id="org1fed83e">Sincronizacion</h2>
<div class="outline-text-2" id="text-org1fed83e">
</div>
<div id="outline-container-orgd914f87" class="outline-3">
<h3 id="orgd914f87"><a href="#org1bb589d">Deadlock</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="deadlock">deadlock</span></span></h3>
<div class="outline-text-3" id="text-orgd914f87">
<p>
A <a id="org1bb589d">deadlock</a> is a cycle of waiting among a set of threads, where
each thread waits for some other thread in the cycle to take some
action.
</p>

<p>
<a href="#org1bb589d">Deadlock</a> can occur in many different situations, but one of the
simplest is mutually recursive locking:
</p>

<pre class="example">
// Thread A

lock1.acquire();
lock2.acquire();
lock2.release();
lock1.release();

// Thread B

lock2.acquire();
lock1.acquire();
lock1.release();
lock2.release();
</pre>

<p>
We can also get into <a href="#org1bb589d">deadlock</a> with two locks and a <a href="#orge7a9600">condition variable</a>,
shown below:
</p>

<pre class="example">
// Thread A

lock1.acquire();
...
lock2.acquire();
while (need to wait) {
    cv.wait(&amp;lock2);
}
...
lock2.release();
...
lock1.release();
// Thread B

lock1.acquire();
...
lock2.acquire();
...
cv.signal();
lock2.release();
...
lock1.release();
</pre>

<p>
In <a id="org4ec2d1a">nested waiting</a>, one shared object calls into another shared
object while holding the first object's <a href="#org43286d2">lock</a>, and then waits on a
<a href="#orge7a9600">condition variable</a>.
</p>
</div>

<div id="outline-container-orge3b27ac" class="outline-4">
<h4 id="orge3b27ac">Condiciones para un <a href="#org1bb589d">Deadlock</a></h4>
<div class="outline-text-4" id="text-orge3b27ac">
<ol class="org-ol">
<li>Bounded resources. There are a finite number of threads that can
simultaneously use a resource.</li>
<li>No preemption. Once a thread acquires a resource, its ownership
cannot be revoked until the thread acts to release it.</li>
<li>Wait while holding. A thread holds one resource while waiting for
another. This condition is sometimes called multiple independent
requests because it occurs when a thread first acquires one
resource and then tries to acquire another.</li>
<li>Circular waiting. There is a set of waiting threads such that each
thread is waiting for a resource held by another.</li>
</ol>
</div>
</div>

<div id="outline-container-org2ecc41f" class="outline-4">
<h4 id="org2ecc41f">Prevencion de Deadlocks</h4>
<div class="outline-text-4" id="text-org2ecc41f">
<ol class="org-ol">
<li>Exploit or limit the behavior of the program. Often, we can change
the behavior of a program to prevent one of the four necessary
conditions for <a href="#org1bb589d">deadlock</a>, and thereby eliminate the possibility of
<a href="#org1bb589d">deadlock</a>.</li>
<li>Predict the future. If we can know what threads may or will do,
then we can avoid <a href="#org1bb589d">deadlock</a> by having threads wait (e.g., thread 2
can wait at step 2 above) before they would head into a possible
<a href="#org1bb589d">deadlock</a>.</li>
<li>Detect and recover. Another alternative is to allow threads to
recover or “undo” actions that take a system into a <a href="#org1bb589d">deadlock</a>.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org914fd80" class="outline-3">
<h3 id="org914fd80"><a href="#orgb03ca34">Starvation</a></h3>
<div class="outline-text-3" id="text-org914fd80">
<p>
In <a id="orgb03ca34">starvation</a>, a thread fails to make progress for an indefinite
period of time. <a href="#org1bb589d">Deadlock</a> is a form of <a href="#orgb03ca34">starvation</a> but with the stronger
condition: a group of threads forms a cycle where none of the threads
make progress because each thread is waiting for some other thread in
the cycle to take action. Thus, <a href="#org1bb589d">deadlock</a> implies <a href="#orgb03ca34">starvation</a>, but
<a href="#orgb03ca34">starvation</a> does not imply <a href="#org1bb589d">deadlock</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbe4bbbe" class="outline-2">
<h2 id="orgbe4bbbe">Scheduling&#xa0;&#xa0;&#xa0;<span class="tag"><span class="scheduling">scheduling</span></span></h2>
<div class="outline-text-2" id="text-orgbe4bbbe">
<p>
When there are multiple things to do, how do you choose which one to
do first?
</p>

<p>
When there are more runnable threads than processors, the &lt;&lt;&lt;processor
scheduling policy&gt;&gt;&gt; determines which threads to run first.
</p>

<p>
There is no one right answer; rather, any scheduling policy poses a
complex set of tradeoffs between various desirable properties.
</p>

<p>
Our discussion also assumes the scheduler has the ability to
<a id="org10d4c14">preempt</a> the processor and give it to some other task. Preemption
can happen either because of a timer interrupt, or because some task
arrives on the ready list with a higher priority than the current
task, at least according to some scheduling policy.
</p>
</div>

<div id="outline-container-orga4cb8cf" class="outline-3">
<h3 id="orga4cb8cf">defs</h3>
<div class="outline-text-3" id="text-orga4cb8cf">
<p>
A <a id="orgeeb506c">workload</a> is a set of tasks for some system to perform, along
with when each task arrives and how long each task takes to
complete. In other words, the <a href="#orgeeb506c">workload</a> defines the input to a
scheduling algorithm. Given a <a href="#orgeeb506c">workload</a>, a processor scheduler decides
when each task is to be assigned the processor.
</p>

<p>
Response time
</p>

<p>
turn around time
</p>
</div>
</div>

<div id="outline-container-orge783906" class="outline-3">
<h3 id="orge783906">Policies</h3>
<div class="outline-text-3" id="text-orge783906">
</div>
<div id="outline-container-org7545800" class="outline-4">
<h4 id="org7545800">FIFO</h4>
<div class="outline-text-4" id="text-org7545800">
<p>
Do each task in the order in which it arrives.
</p>

<p>
FIFO minimizes overhead, switching between tasks only when each one
completes.
</p>


<div class="figure">
<p><img src="./img/7.1.png" alt="7.1.png" />
</p>
</div>

<p>
If a task with very little work to do happens to land in
line behind a task that takes a very long time, then the system will
seem very inefficient.
</p>
</div>
</div>

<div id="outline-container-orgd950d58" class="outline-4">
<h4 id="orgd950d58">SJF (Shortest Job First)</h4>
<div class="outline-text-4" id="text-orgd950d58">
<p>
Suppose we could know how much time each task needed at the processor.
</p>

<p>
SJF is pessimal for variance in response time. By doing the shortest
tasks as quickly as possible, SJF necessarily does longer tasks as
slowly as possible.
</p>

<p>
SJF can suffer from <a href="#orgb03ca34">starvation</a> and frequent context switches. If
enough short tasks arrive, long tasks may never complete. Whenever a
new task on the ready list is shorter than the remaining time left on
the currently scheduled task, the scheduler will switch to the new
task. If this keeps happening indefinitely, a long task may never
finish.
</p>
</div>
</div>

<div id="outline-container-org9129f23" class="outline-4">
<h4 id="org9129f23">Round Robin</h4>
<div class="outline-text-4" id="text-org9129f23">
<p>
addresses <a href="#orgb03ca34">starvation</a>
</p>

<p>
tasks take turns running on the processor for a limited period of
time. The scheduler assigns the processor to the first task in the
ready list, setting a timer interrupt for some delay, called the
<a id="org40935cd">time quantum</a>. At the end of the quantum, if the task has not
completed, the task is preempted and the processor is given to the
next task in the ready list.  The preempted task is put back on the
ready list where it can wait its next turn. With Round Robin, there is
no possibility that a task will starve.
</p>


<div class="figure">
<p><img src="./img/7.2.png" alt="7.2.png" />
</p>
</div>

<p>
One consideration is overhead: if we have too short a <a href="#org40935cd">time quantum</a>,
the processor will spend all of its time switching and getting very
little useful work done. If we pick too long a <a href="#org40935cd">time quantum</a>, tasks
will have to wait a long time until they get a turn.
</p>


<div class="figure">
<p><img src="./img/7.3.png" alt="7.3.png" />
</p>
</div>

<p>
Figure 7.3 illustrates what happens for FIFO, SJF, and Round
Robin when several tasks start at roughly same time and are of the
same length. Round Robin will rotate through the tasks, doing a bit of
each, finishing them all at roughly the same time.
</p>
</div>
</div>

<div id="outline-container-org3fd19f5" class="outline-4">
<h4 id="org3fd19f5">Min Max Fairness</h4>
</div>

<div id="outline-container-org4cb21dc" class="outline-4">
<h4 id="org4cb21dc">MLFQ (Multi-Level Feedback Queue)</h4>
<div class="outline-text-4" id="text-org4cb21dc">
<p>
Goals:
</p>
<ul class="org-ul">
<li>Responsiveness. Run short tasks quickly, as in SJF.</li>
<li>Low Overhead. Minimize the number of preemptions, as in FIFO, and
minimize the time spent making scheduling decisions.</li>
<li><a href="#orgb03ca34">Starvation</a>-Freedom. All tasks should make progress, as in Round
Robin.</li>
<li>Background Tasks. Defer system maintenance tasks, such as disk
defragmentation, so they do not interfere with user work.</li>
<li>Fairness. Assign (non-background) processes approximately their
max-min fair share of the processor.</li>
</ul>

<p>
MFQ is an extension of Round Robin. Instead of only a single queue,
MFQ has multiple Round Robin queues, each with a different priority
level and <a href="#org40935cd">time quantum</a>. Tasks at a higher priority level <a href="#org10d4c14">preempt</a> lower
priority tasks, while tasks at the same level are scheduled in Round
Robin fashion.  Further, higher priority levels have shorter time
quanta than lower levels.
</p>

<p>
Tasks are moved between priority levels to favor short tasks over long
ones. A new task enters at the top priority level. Every time the task
uses up its <a href="#org40935cd">time quantum</a>, it drops a level; every time the task yields
the processor because it is waiting on I/O, it stays at the same level
and if the task completes it leaves the system.
</p>


<div class="figure">
<p><img src="./img/7.5.png" alt="7.5.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgace47f4" class="outline-4">
<h4 id="orgace47f4">MLFQ Multi procesador</h4>
<div class="outline-text-4" id="text-orgace47f4">
<p>
Exsite una MLFQ para cada procesador.
</p>

<p>
Each processor uses <a id="orge8de7e8">affinity scheduling</a>: once a thread is
scheduled on a processor, it is returned to the same processor when it
is re-scheduled, maximizing cache reuse. Each processor looks at its
own copy of the queue for new work to do; this can mean that some
processors can idle while others have work waiting to be
done. Rebalancing occurs only if the queue lengths are persistent
enough to compensate for the time to reload the cache for the migrated
threads.
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
Last update: 2019-12-09 19:32
</div>
</body>
</html>
