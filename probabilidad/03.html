<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-03-18 Mon 00:27 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Variables aleatorias: Momentos</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/res/org.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "left",
        displayIndent: "0",

        "HTML-CSS": { scale: %SCALE,
                        linebreaks: { automatic: "%LINEBREAKS" },
                        webFont: "%FONT"
                       },
        SVG: {scale: %SCALE,
              linebreaks: { automatic: "%LINEBREAKS" },
              font: "%FONT"},
        NativeMML: {scale: %SCALE},
        TeX: { equationNumbers: {autoNumber: "%AUTONUMBER"},
               MultLineWidth: "%MULTLINEWIDTH",
               TagSide: "right",
               TagIndent: "%TAGINDENT"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Variables aleatorias: Momentos</h1>
<div id="outline-container-orgd7e2e99" class="outline-2">
<h2 id="orgd7e2e99">Esperanza</h2>
<div class="outline-text-2" id="text-orgd7e2e99">
<p>
La información relevante sobre el comportamiento de una variable
aleatoria está contenida en su función de distribución. Sin embargo,
en la práctica, es útil disponer de algunos números representativos de
la variable aleatoria que resuman esa información.
</p>
</div>
<div id="outline-container-org35e0fea" class="outline-5">
<h5 id="org35e0fea">Motivación</h5>
<div class="outline-text-5" id="text-org35e0fea">
<p>
Se gira una rueda de la fortuna varias veces. En cada giro se puede
obtener alguno de los siguiente números x<sub>1</sub>, x
2
, &hellip; , x
k
-que representan la cantidad de dinero que se obtiene en el giro- con probabilidades p(x
1
), p(x
2
), &hellip; , p(x
k
), respectivamente. ¿Cuánto dinero
se /"espera"/obtener como recompensa /"por cada giro''? Los términos /"espera"/y /"por cada
giro"/son un tanto ambiguos, pero se pueden interpretar de la siguiente manera.
Si la rueda se gira n veces y n(x
i
) es la cantidad de veces que se obtiene x
i
, la cantidad total
de dinero recibida es
P
k
{i=1}
n ( x
i
)x
i
y la cantidad media por giro es &mu; =
1
n
P
k
{i=1}
n ( x
i
)x
i
. Interpretando las probabilidades como frecuencias relativas obtenemos que para n suficientemente
grande l a cantidad de dinero que se /"espera"/recibir /"por cada giro"/es
&mu; =}
1
n
k
X
{i=1}
x
i
n ( x
i
) =
k
X
{i=1}
x
i
n ( x
i
)
n
&asymp;
k
X
{i=1}
x
i
p ( x
i
).
2
</p>
</div>
</div>
<div id="outline-container-org2b1b36f" class="outline-3">
<h3 id="org2b1b36f">Definición</h3>
<div class="outline-text-3" id="text-org2b1b36f">
</div>
<div id="outline-container-org62f7b7a" class="outline-5">
<h5 id="org62f7b7a">Definición 1.1 (Esperanza de una variable discreta)</h5>
<div class="outline-text-5" id="text-org62f7b7a">
<p>
Sea X una variable aleatoria discreta.
La esperanza de X, denotada por E[X], es el promedio ponderado 
E[X] :=
X
x &isin; A
x{\mathbb{P}( X = x ) , (1)
donde A = \{x &isin; \Re : F (x) − F (x{−}) &gt; 0{\} es el conjunto de todos los átomos de la función
distribución de X.
</p>
</div>
</div>
<div id="outline-container-orgf42884c" class="outline-5">
<h5 id="orgf42884c">Ejemplo 1.2 (Esperanza de la función indicadora)</h5>
<div class="outline-text-5" id="text-orgf42884c">
<p>
Sea$(&Omega;, \mathcal{A}, \mathbb{P})$un espacio de probabilidad.
Para cualquier evento A &isin; A vale que
E[1\{&omega; &isin; A\] = 0 · (1 −} \mathbb{P}(A)) + 1 · \mathbb{P}(A) = \mathbb{P}(A). (2)
La esperanza como centro de gravedad. La noción de esperanza es análoga a la noción}
de centro de gravedad para un sistema de partículas discreto.
Se consideran n partículas ubicadas en los puntos x
1
, &hellip; , x
n
cuyos pesos respectivos son
p ( x
1
), &hellip; , p(x
n
). No se pierde generalidad si se supone que
P
n
{i=1}
p ( x
i
) = 1. El centro de
gravedad, c, del sistema es el punto respecto de la cual la suma de los momentos causados
por los pesos p(x
i
) es nula. Observando que
k
X
{i=1}
(x
i
− c ) p ( x}
i
) = 0 \iff c = 
k
X
{i=1}
x
i
p ( x
i
)
resulta que el centro de gravedad del sistema coincide con la esperanza de una variable aleato
ria X a valores en \{x}
1
, &hellip; , x
n
\} tal que \mathbb{P}(X = x}
i
) = p(x
i
).
1 3 6 10
c
Figura 1: Interpretación de la esperanza como centro de gravedad. Se considera un sis
tema de cuatro /"partículas"/de pesos p
i
proporcionales a las áreas de los círculos de radio
1 / 3, 2 / 3, 3 / 3, 4 / 3 centrados en los puntos x
i
= 1, 3, 6, 10, respectivamente. No se pierde gen
eralidad si se supone que el peso total del sistema es la unidad. El centro de gravedad del
sistema se encuentra en el punto c =
P
4
{i=1}
x
i
p
i
= 227 / 30 = 7.56 &hellip;}
3
La esperanza como promedio. Sea X una variable aleatoria a valores x}
1
, &hellip; , x
n
con
función de probabilidades
\mathbb{P}(X = x) =}
1
n
1\{x &isin; \{x}
1
, &hellip; , x
n
\\}.
Conforme a la Definición 1.1 la esperanza de X es
E[X] =}
n
X
{i=1}
x
i
\mathbb{P}(X = x}
i
) =
1
n
n
X
{i=1}
x
i
. (3)
Dicho en palabras: la esperanza de una variable aleatoria uniformemente distribuida sobre los
valores x
1
, x
2
, &hellip; , x
n
coincide con el promedio de dichos valores.
</p>
</div>
</div>
<div id="outline-container-org8985f81" class="outline-5">
<h5 id="org8985f81">Ejemplo 1.3 (Dado equilibrado).</h5>
<div class="outline-text-5" id="text-org8985f81">
<p>
Sea X el resultado del lanzamiento de un dado equilibrado.
De acuerdo con (3) l a esperanza de X es
E[X] =}
1
6
6
X
{x=1}
x =}
21
6
=
7
2
.
</p>
</div>
</div>
<div id="outline-container-orgd20a17e" class="outline-5">
<h5 id="orgd20a17e">Ejemplo 1.4 (Uniforme sobre el <i>"intervalo"</i>\1, 2, &hellip; , n{\})</h5>
<div class="outline-text-5" id="text-orgd20a17e">
<p>
La variable aleatoria del Ejemplo}
1.3 es un caso particular de una variable aleatoria discreta X uniformemente distribuida sobre
el /"i ntervalo"/de números enteros \1, 2, &hellip; , n{\} . De acuerdo con (3) la esperanza de X es
E[X] =}
1
n
n
X
{x=1}
x =}
1
n
</p>

<p>
n ( n + 1)
2

=
1 + n
2
.
</p>
</div>
</div>
<div id="outline-container-org494087a" class="outline-5">
<h5 id="org494087a">Ejemplo 1.5 (Moneda equilibrada).</h5>
<div class="outline-text-5" id="text-org494087a">
<p>
Sea N la cantidad de veces que debe lanzarse una mon
eda equilibrada hasta que salga cara. N es una variable aleatoria discreta a valores 1, 2, &hellip; tal
que \mathbb{P}(N = n) = (1 / 2)
n
, n = 1, 2, &hellip; . De acuerdo con la definición 1.1, la esperanza de N es
E[N] =}
&infin;
X
{n=1}
n{\mathbb{P}( N = n ) =}
&infin;
X
{n=1}
n
</p>

<p>
1
2

n
.
Derivando ambos lados de la igualdad
P
&infin;
{n=0}
x
n
= (1 −x)
−{1}
, que vale para |x| &lt; 1, se deduce
que
P
&infin;
{n=0}
nx
n{−{1
= (1 − x)
−{2}
y de allí resulta que
P
&infin;
{n=1}
nx
n
= x(1 − x)
−{2}
. Evaluando en
x = 1}/{2 se obtiene que}
E[N] =}
&infin;
X
{n=1}
n
</p>

<p>
1
2

n
=
</p>

<p>
1
2

1
2

−{2}
= 2.
La noción de esperanza se extiende a variables aleatorias absolutamente continuas cam}
biando en (1) la suma por la integral y la función de probabilidades \mathbb{P}(X = x), x &isin; A}, por la
densidad de probabilidades de la variable X.
4
</p>
</div>
</div>
<div id="outline-container-org6214edc" class="outline-5">
<h5 id="org6214edc">Definición 1.6 (Esperanza de una variable absolutamente continua)</h5>
<div class="outline-text-5" id="text-org6214edc">
<p>
Sea X una variable}
aleatoria absolutamente continua con densidad de probabilidades f<sub>X</sub>(x). La esperanza de X, 
denotada por E[X], se define por
E[X] :=}
Z
&infin;
−&infin;
xf<sub>X</sub>(x)dx. (4)
</p>
</div>
</div>
<div id="outline-container-orgd744758" class="outline-5">
<h5 id="orgd744758">Ejemplo 1.7 (Fiabilidad).</h5>
<div class="outline-text-5" id="text-orgd744758">
<p>
Sea T el tiempo de espera hasta que ocurre la primer falla en un}
sistema electrónico con función intensidad de fallas de la forma &lambda;(t) = 2{t{1{\}t &gt; 0{\}. La función
de distribución de T es F}
T
(t) =

1 − exp

−t
2

1\{t &gt; 0} \. En consecuencia, T es una variable
aleatoria absolutamente continua con densidad de probabilidad f
T
(t) = 2t exp

−t
2

1\{t &gt; 0}\}.
De acuerdo con l a definición 1.6, la esperanza de T es
E[T ] =}
Z
&infin;
−&infin;
tf
T
(t)dt =
Z
&infin;
0
t{2}t exp(−} t
2
)dt =
Z
&infin;
0
exp(−t}
2
)dt =
\sqrt{}
&pi;
2
.
La tercera igualdad se deduce de la fórmula de integración por partes aplicada a u = t y
v
′
= 2t exp(−t}
2
) y la cuarta se deduce de la identidad
R
&infin;
0
exp(−x}
2
/{2)dx =}
\sqrt{}
2{&pi;/}2 mediante
el c ambio de variables t = x/}
\sqrt{}
</p>
<ol class="org-ol">
<li></li>
</ol>
<p>
Extendiendo la noción a variables mixtas. La no c
ión de esperanza para variables}
mixtas se obtiene combinando las nociones anteriores.
</p>
</div>
</div>
<div id="outline-container-orgdc8c9fa" class="outline-5">
<h5 id="orgdc8c9fa">Definición 1.8 (Esperanza de una variable mixta)</h5>
<div class="outline-text-5" id="text-orgdc8c9fa">
<p>
Sea X una variable aleatoria mixta con}
función de distribución F}
X
(x). La esperanza de X, denotada por E[X], se define de la siguiente 
manera:
E[X] :=}
X
x{\inA}
x{\mathbb{P}( X = x) +}
Z
&infin;
−&infin;
xF
′
X
(x)dx, (5)
donde A = \{x &isin; \Re : F}
X
(x) − F
X
(x{−}) &gt; 0{\} es el conjunto de todos los átomos de F}
X
(x) y
F
′
X
(x) es una función que coincide con la derivada de F}
X
(x) en todos los puntos donde esa
función es derivable y vale 0 en otro lado.
</p>
</div>
</div>
<div id="outline-container-orgba68474" class="outline-5">
<h5 id="orgba68474">Ejemplo 1.9 (Mixtura).</h5>
<div class="outline-text-5" id="text-orgba68474">
<p>
Sea X una variable aleatoria mixta cuya función de distribución es}
F<sub>X</sub>(x) =

2x+5
8

1\{−{1 &le; x &lt; 1}\} + 1\{x &ge; 1}\. De acuerdo con la fórmula (5), la esperanza de
X es}
E[X] = −}1 · \mathbb{P}(X = −}1) + 1 · \mathbb{P}(X = 1) +}
Z
1
−{1}
F
′
X
(x)dx = −}
3
8
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
1
8
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
Z
1
−{1}
2
8
dx =}
1
4
.
</p>
</div>
</div>
<div id="outline-container-orgc60a890" class="outline-5">
<h5 id="orgc60a890">Nota Bene</h5>
<div class="outline-text-5" id="text-orgc60a890">
<p>
En todas las definiciones anteriores, se presupone que las series y/o integrales}
involucradas son absolutamente convergentes.
</p>
</div>
</div>
<div id="outline-container-org86bd569" class="outline-5">
<h5 id="org86bd569">Ejemplo 1.10</h5>
<div class="outline-text-5" id="text-org86bd569">
<p>
(Distribución de Cauchy). Sea X una variable aleatoria con distribución de
Cauchy. Esto es, X es absolutamente continua y admite una densidad de probabilidades de}
la forma
f ( x) =}
1
&pi;(1 + x
2
)
.
5
Debido a que
Z
&infin;
−&infin;
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">x</td>
<td class="org-left">{f ( x ) dx =</td>
</tr>
</tbody>
</table>
<p>
Z
&infin;
−&infin;
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">x</td>
</tr>
</tbody>
</table>
<p>
&pi;(1 + x
2
)
dx = &infin;},
X no tiene esperanza.
</p>
</div>
</div>
<div id="outline-container-orgdb47e04" class="outline-5">
<h5 id="orgdb47e04">Teorema 1.11.</h5>
<div class="outline-text-5" id="text-orgdb47e04">
<p>
Sea X una variable aleatoria no negativa (i.e., F<sub>X</sub>(x) = \mathbb{P}(X &le; x) = 0 para
todo x &lt; 0). Vale que
E[X] =}
Z
&infin;
0
[1 − F<sub>X</sub>(x)] dx. (6)
</p>
</div>
</div>
<div id="outline-container-orge386e62" class="outline-5">
<h5 id="orge386e62">Demostración</h5>
<div class="outline-text-5" id="text-orge386e62">
<p>
El argumento principal está contenido en la Figura 2. E l caso general se}
deduce usando téc nicas de /"paso al límite''.
p
2
p
3
p
k
1
x
1
p
1
p
k{−{1
x
2
x
3
x
k{−{1
x
k
0
Figura 2: Argumento geométrico que muestra la validez de la identidad (6) en e l caso en que
X es no negativa, discreta y a valores 0 &le; x
1
&lt; x
2
&lt; &ctdot; &lt; x
k
. Si p
i
= \mathbb{P}(X = x
i
), el área
de la región sombreada es la suma x
1
p
1
</p>
<ul class="org-ul">
<li>&ctdot; + x</li>
</ul>
<p>
k
p
k
= E[X] de las áreas de los rectángulos
horizontales y coincide con la integral de la altura \mathbb{P}(X &gt; x).
</p>
</div>
</div>
<div id="outline-container-org6d2e794" class="outline-5">
<h5 id="org6d2e794">Corolario 1.12.</h5>
<div class="outline-text-5" id="text-org6d2e794">
<p>
Sea X una variable aleatoria con función de distribución F<sub>X</sub>(x). Vale que
E[X] =}
Z
&infin;
0
[1 − F<sub>X</sub>(x)] dx −
Z
0
−&infin;
F<sub>X</sub>(x)dx. (7)
</p>
</div>
</div>
<div id="outline-container-org316408b" class="outline-5">
<h5 id="org316408b">Demostración</h5>
<div class="outline-text-5" id="text-org316408b">
<p>
Ejercicio.
6
</p>
</div>
</div>
<div id="outline-container-orgf6c771c" class="outline-5">
<h5 id="orgf6c771c">Nota Bene</h5>
<div class="outline-text-5" id="text-orgf6c771c">
<p>
Las identidades (6) y (7) son interesantes porque muestran que para calcular}
la esperanza de una variable aleatoria basta conocer su función de distribución. De hecho, la
identidad (7) ofrece una definición alternativa y unificada de la noción de esperanza.
</p>
</div>
</div>
<div id="outline-container-orgb45d13e" class="outline-5">
<h5 id="orgb45d13e">Ejemplo 1.13.</h5>
<div class="outline-text-5" id="text-orgb45d13e">
<p>
Una máquina fue diseñada para prestar servicios en una instalación produc
tiva. La máquina se enciende al iniciar la jornada laboral y se apaga al finalizar la misma. Si
durante ese perío do la máquina falla, se la repara y en esa tarea se consume el resto de la
jornada.
Suponiendo que la función intensidad de fallas de la máquina es una constante &lambda; &gt; 0 (y
que el tiempo se mide en jornadas laborales), hallar el máximo valor de &lambda; que permita asegurar
con una probabilidad mayor o igual que 2/3 que la máquina prestará servicios durante una
jornada laboral completa. Para ese valor de &lambda;, hallar (y graficar) la función de distribución
del tiempo, T , de funcionamiento de la máquina durante una jornada laboral y calcular el
tiempo medio de funcionamiento, E[T ].
Solución. Si T<sub>1</sub>
es el tiempo que transcurre desde que se enciende la máquina hasta que
ocurre la primer falla, el evento /"la máquina funciona durante una jornada laboral completa''
se describe mediante \{T<sub>1</sub>
&gt; 1{\}. Queremos hallar el máximo &lambda; &gt; 0 tal que \mathbb{P}(T<sub>1</sub>
&gt; 1) &ge; 2}/{3.
Debido a que la función intensidad de fallas es una constante &lambda; se tiene que \mathbb{P}(T}
1
&gt; t) = e
−{&lambda; t}
.
En consecuencia, \mathbb{P}(T}
1
&gt; 1) &ge; 2}/{3 \iff e
− &lambda; 
&ge; 2 / 3 \iff &lambda; &le; −{log(2 / 3). Por lo tanto,}
&lambda; = −}log (2}/{3). En tal caso, \mathbb{P}(T &gt; 1) = 2}/{3.
0
1 / 3
1
1
Figura 3: Gráfico de la función de distribución de T .
El tiempo de funcionamiento de la máquina por jornada laboral es T = mín\{T<sub>1</sub>
, 1{\}. Para}
t &gt; 0 vale que}
F
T
(t) = \mathbb{P}(T &le; t) = 1 −\mathbb{P}(T &gt; t) = 1 − \mathbb{P}(mín\{T<sub>1</sub>
, 1{\} &gt; t ) 
= 1 − \mathbb{P}(T}
1
&gt; t)1{\}1 &gt; t{\} = 1 − e
log(2 / 3)t<sub>1</sub>\{t &lt; 1}\}
=

1 − e}
log(2 / 3)t

1\{0 &le; t &lt; 1}\} + 1\{t &ge; 1\}.
7
Como T &gt; 0 y conocemos la función \mathbb{P}(T &gt; t) lo más sencillo para calcular la esperanza
es usar l a fórmula E[T ] =
R
&infin;
0
\mathbb{P}(T &gt; t)dt}:}
E[T ] =}
Z
&infin;
0
\mathbb{P}(T &gt; t)dt =}
Z
1
0
e
log(2 / 3)t
dt =}
e
log(2 / 3)t
log(2 / 3)





1
0
=
2 / 3 − 1
log(2 / 3)
=
−{1 / 3}
log(2 / 3)
&asymp; 0.822&hellip;}
</p>
</div>
</div>
</div>
<div id="outline-container-orgf9a38e3" class="outline-3">
<h3 id="orgf9a38e3">Cálculo</h3>
<div class="outline-text-3" id="text-orgf9a38e3">
<p>
Sea X una variable aleatoria cuya función de distribución conocemos. Queremos calcular
la esperanza de alguna función de X, digamos, g(X). ¿Cómo se puede efectuar ese cálculo?
Una manera es la siguiente: (1) Hallamos la función de distribución de la variable aleatoria
Y = g ( X) a partir del conocimiento que tenemos sobre la distribución de X:}
F<sub>Y</sub>(y) := \mathbb{P}(Y &le; y) = \mathbb{P}(g(X) &le; y) = P

X &isin; g
−{1}
(−&infin;, y]

.
(2) Usando la distribución de Y calculamos la esperanza E[g(X)] = E[Y ] por definición.
</p>
</div>
<div id="outline-container-org81a1dae" class="outline-5">
<h5 id="org81a1dae">Ejemplo 1.14.</h5>
<div class="outline-text-5" id="text-org81a1dae">
<p>
Sea X una variable aleatoria discreta tal que \mathbb{P}(X = 0) = 0.2, \mathbb{P}(X = 1) = 0.5}
y \mathbb{P}(X = 2) = 0.3. Queremos calcular E[X<sub>2</sub>
]. Poniendo Y = X<sub>2</sub>
obtenemos una variable
aleatoria a valores en \0
2
, 1}
2
, 2}
2
\} tal que \mathbb{P}(Y = 0) = 0.2 \mathbb{P}(Y = 1) = 0.5 y \mathbb{P}(Y = 4) = 0.3.
Por definición, E[X<sub>2</sub>
] = E[Y ] = 0(0.2) + 1(0.5) + 4(0.3) = 1.7.
</p>
</div>
</div>
<div id="outline-container-org75a7eca" class="outline-5">
<h5 id="org75a7eca">Ejemplo 1.15.</h5>
<div class="outline-text-5" id="text-org75a7eca">
<p>
Sea X una variable aleatori a con distribución uniforme sobre el intervalo}
(0, 1). Queremos calcular E[X
3
]. Ponemos Y = X
3
y calculamos su función de distribución:
para cada 0 &lt; y &lt; 1 vale que F}
Y
(y) = \mathbb{P}(Y &le; y) = \mathbb{P}(X
3
&le; y) = \mathbb{P}(X &le; y
1 / 3
) = y
1 / 3
.
Derivando F}
Y
(y) obtenemos la densidad de probabilidad de Y : f<sub>Y</sub>(y) =
1
3
y
−{2 / 3}
1\{0 &lt; y &lt; 1\}.
Por definición,
E[X}
3
] = E[Y ] =
Z
&infin;
−&infin;
yf<sub>Y</sub>(y)dy =
Z
1
0
y
1
3
y
−{2 / 3}
dy =}
1
3
Z
1
0
y
1 / 3
dy =}
1
3
3
4
y
4 / 3




1
0
=
1
4
.
</p>
</div>
</div>
<div id="outline-container-orgde6579c" class="outline-5">
<h5 id="orgde6579c">Nota Bene</h5>
<div class="outline-text-5" id="text-orgde6579c">
<p>
Existe una manera mucho más simple para calcular la esperanza de Y = g(X)
que no recurre al procedimiento de determinar primero la distribución de Y para luego calcular
su esperanza por definición. El Teorema siguiente muestra cómo hacerlo.
</p>
</div>
</div>
<div id="outline-container-org193f685" class="outline-5">
<h5 id="org193f685">Teorema 1.16.</h5>
<div class="outline-text-5" id="text-org193f685">
<p>
Sea X una variable aleatoria y sea g : R &rarr; \Re una función tal que g(X)
también es una variable aleatoria.
(a) Si X es discreta con átomos en el conjunto A, entonces
E[g(X)] =}
X
x{\inA}
g ( x)\mathbb{P}(X = x ) . (8)
(b) Si X es continua con densidad de probabilidad f<sub>X</sub>(x) y g(X) es continua, entonces
E[g(X)] =}
Z
&infin;
−&infin;
g ( x ) f<sub>X</sub>(x)dx. (9)
8
(c) Si X es mixta,
E[g(X)] =}
X
x{\inA}
g ( x)\mathbb{P}(X = x) +}
Z
&infin;
−&infin;
g ( x ) F
′
X
(x)dx, (10)
donde A es el conjunto de todos los átomos de F}
X
(x) y F}
′
X
(x) es un función que coincide
con la derivada de F}
X
(x) en todos los puntos donde esa función es derivable y vale cero en
otro lado.
</p>
</div>
</div>
<div id="outline-container-org2920f8e" class="outline-5">
<h5 id="org2920f8e">Demostración</h5>
<div class="outline-text-5" id="text-org2920f8e">
<p>
Para simplificar la demostración supondremos que g &ge; 0.
(a) Por el Teorema 1.11 tenemos que
E[g(X)] =}
Z
&infin;
0
\mathbb{P}(g(X) &gt; y)dy =}
Z
&infin;
0
X
x{\inA}
1\{g ( x ) &gt; y}\\mathbb{P}(X = x) 
!
dy
=
X
x{\inA}
</p>

<p>
Z
&infin;
0
1\{g ( x ) &gt; y}\dy

\mathbb{P}(X = x) =}
X
x{\inA}
g ( x)\mathbb{P}(X = x ) .
(b) Por el Teorema 1.11 tenemos que
E[g(X)] =}
Z
&infin;
0
\mathbb{P}(g(X) &gt; y)dy =}
Z
&infin;
0
Z
\{x{: g ( x ) &gt;y\}
f ( x ) dx
!
dy
=
Z
&infin;
−&infin;
Z
g ( x ) 
0
dy
!
f ( x ) dx =}
Z
&infin;
−&infin;
g ( x ) f ( x ) dx.
(c) Se obtiene combinando adecuadamente los resultados (a) y (b).
</p>
</div>
</div>
<div id="outline-container-org2643b9d" class="outline-5">
<h5 id="org2643b9d">Ejemplo 1.17.</h5>
<div class="outline-text-5" id="text-org2643b9d">
<p>
Aplicando la parte (a) del Teorema 1.16 al Ejemplo 1.14 
se obtiene}
E[X}
2
] = 0
2
(0.2) + 1
2
(0.5) + 2
2
(0.3) = 1.7.
</p>
</div>
</div>
<div id="outline-container-orgffc9cbb" class="outline-5">
<h5 id="orgffc9cbb">Ejemplo 1.18.</h5>
<div class="outline-text-5" id="text-orgffc9cbb">
<p>
Aplicando la parte (b) del Teorema 1.16 al Ejemplo 1.15 
se obtiene}
E[X}
3
] =
Z
1
0
x
3
dx =}
1
4
.
</p>
</div>
</div>
<div id="outline-container-org86fa2d7" class="outline-5">
<h5 id="org86fa2d7">Teorema 1.19 (Cálculo de Esperanzas)</h5>
<div class="outline-text-5" id="text-org86fa2d7">
<p>
Sea X un vector aleatorio y sea g : \Re}
n
&rarr; \Re una
función tal que g(X) es una variable aleatoria. Si la variable aleatoria g(X) tiene esperanza
finita, entonces
E[g(X)] =}



P
x
g(x)p
X
(x) en el caso discreto, 
R
R
n
g(x)f<sub>X</sub>(x) dx en el caso continuo, 
donde, según sea el caso, p
X
(x) y f<sub>X</sub>(x) son la función de probabilidad y la densidad conjunta
del vector X, respectivamente.
9
\hypertarget{pfa}
</p>
</div>
</div>
<div id="outline-container-orgd5bc380" class="outline-5">
<h5 id="orgd5bc380">Demostración</h5>
<div class="outline-text-5" id="text-orgd5bc380">
<p>
Enteramente análoga a la que hicimos en dimensión 1.
Sobre el cálculo de esperanzas. El Teorema 1.19 es una herramienta práctica para}
calcular esperanzas. Su resultado establece que si queremos calcular la esperanza de una
transformación unidimensional del vector X, g(X), no neces itamo s calcular la distribución
de g(X). La esperanza E[g(X)] puede calcularse directamente a partir del conocimiento de la
distribución conjunta de X.
</p>
</div>
</div>
<div id="outline-container-org1b2319c" class="outline-5">
<h5 id="org1b2319c">Corolario 1.20 (Esp eranza de las marginales).</h5>
<div class="outline-text-5" id="text-org1b2319c">
<p>
Sea X = (X}
1
, &hellip; , X
n
) un vector aleatorio.
Si la variable X
i
tiene esperanza finita, entonces
E[X}
i
] =



P
x
x
i
p
X
(x) en el caso discreto, 
R
R
n
x
i
f<sub>X</sub>(x) dx en el caso continuo.
</p>
</div>
</div>
</div>
<div id="outline-container-orgb052ff9" class="outline-3">
<h3 id="orgb052ff9">Propiedades</h3>
<div class="outline-text-3" id="text-orgb052ff9">
<p>
(a) Si X = 1, entonces E[X] = 1.
(b) Monotonía. Si X<sub>1</sub>
y X<sub>2</sub>
son dos variables aleatorias tales que X<sub>1</sub>
&le; X<sub>2</sub>
, entonces
E[X}
1
] &le; E[X<sub>2</sub>
].
(c) Si X es una variable aleatoria tal que E[X
n
] es finita y a
0
, a
1
, &hellip; , a
n
son constantes,
entonces
E
"
n
X
{k=0}
a
k
X
k
\#
=
n
X
{k=0}
a
k
E[X}
k
]. (11)
(d) Linealidad. Si las variables aleatorias X<sub>1</sub>
, &hellip; , X
n
tienen esperanza finita y a
1
, a
2
, &hellip; , a
n
son constantes, entonces
E
"
n
X
{i=1}
a
i
X
i
\#
=
n
X
{i=1}
a
i
E[X}
i
]. (12)
(e) Regla del producto independiente. Si l as variables aleatorias X<sub>1</sub>
, &hellip; , X
n
tienen esper
anza finita y son independientes, entonces el producto tiene esperanza finita y coincide con
el producto de las esperanzas:
E
"
n
Y
{i=1}
X
i
\#
=
n
Y
{i=1}
E[X}
i
]. (13)
</p>
</div>
<div id="outline-container-org77c13a9" class="outline-5">
<h5 id="org77c13a9">Demostración</h5>
<div class="outline-text-5" id="text-org77c13a9">
<p>
(a) es consecuencia inmediata de la Definición 1.1 porque \mathbb{P}(X = 1) = 1.
(b) es consecuencia del Teorema 1.11 y de que para todo x &isin; \Re vale que F}
X<sub>1</sub>
(x) &ge; F
X<sub>2</sub>
(x).
(c) es c onsecuencia inmediata del Teorema 1.16. (d) es consecuencia inmediata del Teorema
1.19. (e) es consecuencia del Teorema 1.19 y de la factorización de la distribución conjunta
como producto de las distribuciones marginales.
10
\hypertarget{pfb}
</p>
</div>
</div>
</div>
<div id="outline-container-org0349ef7" class="outline-3">
<h3 id="org0349ef7">Dividir y conquistar</h3>
<div class="outline-text-3" id="text-org0349ef7">
</div>
<div id="outline-container-orgedfb5a5" class="outline-5">
<h5 id="orgedfb5a5">Teorema 1.21.</h5>
<div class="outline-text-5" id="text-orgedfb5a5">
<p>
Sea$(&Omega;, \mathcal{A}, \mathbb{P})$un espacio de probabilidad y sea X : &Omega; &rarr; \Re  una variable}
aleatoria. Sea A &sub; \Re un conjunto tal que \{X &isin; A\} = \{&omega; &isin; &Omega; : X(&omega;) &isin; A\} &isin; A}. Si
\mathbb{P}(X &isin; A) &gt; 0, entonces}
E[X | X &isin; A] =}
1
\mathbb{P}(X &isin; A)
E[X{1{\}X &isin; A{\]. (14)
</p>
</div>
</div>
<div id="outline-container-org94d4ec6" class="outline-5">
<h5 id="org94d4ec6">Demostración</h5>
<div class="outline-text-5" id="text-org94d4ec6">
<p>
Para simplificar la exposición vamos a suponer que la variable aleatoria X}
es discreta. Por la Definición 1.1 tenemos que
E[X | X &isin; A] =}
X
{x &isin; X(&Omega;)}
xp
X | {X &isin; A}
(x) =
X
{x &isin; X(&Omega;)}
x
\mathbb{P}(X = x)
\mathbb{P}(X &isin; A)
1\{x &isin; A\}
=
1
\mathbb{P}(X &isin; A)
X
{x &isin; X(&Omega;)}
x{1{\}x &isin; A{\\mathbb{P}( X = x) =}
1
\mathbb{P}(X &isin; A)
E[X{1{\}X &isin; A{\].
La última igualdad es consecuencia del Teorema 1.16.
</p>
</div>
</div>
<div id="outline-container-org6aa7cec" class="outline-5">
<h5 id="org6aa7cec">Ejemplo 1.22.</h5>
<div class="outline-text-5" id="text-org6aa7cec">
<p>
Sea X el resultado del tiro de un dado equilibrado y sea A = \2, 4, 6{\}. De}
acuerdo con (14) la esperanza de X | X &isin; A es
E[X | X &isin; A] =}
1
\mathbb{P}(X &isin; A)
E[X{1{\}X &isin; A{\] =}
1
1 / 2
</p>

<p>
2
6
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
4
6
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
6
6

= 4.
Resultado que por otra parte es intuitivamente evidente.
</p>
</div>
</div>
<div id="outline-container-orgab3e3b4" class="outline-5">
<h5 id="orgab3e3b4">Teorema 1.23 (Fórmula de probabilidad total)</h5>
<div class="outline-text-5" id="text-orgab3e3b4">
<p>
Sea X una variable aleatoria. Si A}
1
, &hellip; , A<sub>n</sub>
es una partición medible de R tal que \mathbb{P}(X &isin; A}
i
) &gt; 0, i = 1, &hellip; , n}. Entonces,
E[X] =}
n
X
{i=1}
E[X | X &isin; A<sub>i</sub>
]\mathbb{P}(X &isin; A}
i
). (15)
</p>
</div>
</div>
<div id="outline-container-orgb70c352" class="outline-5">
<h5 id="orgb70c352">Demostración</h5>
<div class="outline-text-5" id="text-orgb70c352">
<p>
Descomp onemos la variable X como una suma de variables (dependientes}
de la partición) X =
P
n
{i=1}
X{1{\}X &isin; A<sub>i</sub>
\. Como la esperanza es un operador lineal tenemos}
que
E[X] =}
n
X
{i=1}
E[X{1{\}X &isin; A<sub>i</sub>
\] =}
n
X
{i=1}
E[X | X &isin; A<sub>i</sub>
]\mathbb{P}(X &isin; A}
i
).
La última igualdad se obtiene de (14).
</p>
</div>
</div>
<div id="outline-container-org55f04a8" class="outline-5">
<h5 id="org55f04a8">Nota Bene</h5>
<div class="outline-text-5" id="text-org55f04a8">
<p>
Sea g : R &rarr; \Re una función tal que g(X) es una variable aleatoria. Bajo las}
hipótesis del Teorema 1.23 también vale que
E[g(X)] =}
n
X
{i=1}
E[g(X)|X &isin; A<sub>i</sub>
]\mathbb{P}(X &isin; A}
i
). (16)
La fórmula (16) se puede extender sin ninguna dificultad al caso multidimensional.
11
\hypertarget{pfc}
</p>
</div>
</div>
<div id="outline-container-org1680c7a" class="outline-5">
<h5 id="org1680c7a">Ejemplo 1.24</h5>
<div class="outline-text-5" id="text-org1680c7a">
<p>
(Dividir y conquistar). Todas las mañanas Lucas llega a la estación del subte}
entre las 7:10 y las 7:30 (con distribución uniforme en el intervalo). El subte llega a la estación
cada quince minutos comenzando a las 6:00. Calcular la media del tiempo que tiene que esperar
Lucas hasta subirse al subte.
Sea X el horario en que Lucas llega a la estación del subte. El tiempo que tiene que esperar
hasta subirse al subte se descri be por
T = (7.15 − X)1{\}X &isin; [7 : 10}, 7 : 15]\} + (7 : 30 − X)1{\}X &isin; (7 : 15}, 7 : 30]\} .
Ahora bien, dado que X &isin; [7 : 10, 7 : 15], la distribución de T es uniforme sobre el intervalo
[0, 5] minutos y dado que X &isin; (7 : 15, 7 : 30] la distribución de T es uniforme sobre el intervalo
[0, 15] minutos. De acuerdo con (16)
E[T ] =}
5
2
</p>

<p>
5
20

</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
15
2
</p>

<p>
15
20

= 6.25.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org73903be" class="outline-2">
<h2 id="org73903be">Varianza</h2>
<div class="outline-text-2" id="text-org73903be">
</div>
<div id="outline-container-org7a185a0" class="outline-3">
<h3 id="org7a185a0">Definición</h3>
<div class="outline-text-3" id="text-org7a185a0">
<p>
La esperanza de una variable aleatoria X, E[X], también se conoce como la media o el
primer momento de X. La cantidad E[X
n
], n &ge; 1, se llama el n{-ésimo momento de X. Si la 
esperanza E[X] es finita, la cantidad E[(X − E [X])
n
] se ll ama el n -ésimo momento central.}
Después de la esper anza la siguiente cantidad en orden de importancia para resumir el
comportamiento de una variable aleatoria X es su segundo momento central también llamado
la varianza de X}.
</p>
</div>
<div id="outline-container-orgdf79ab4" class="outline-5">
<h5 id="orgdf79ab4">Definición 2.1 (Varianza)</h5>
<div class="outline-text-5" id="text-orgdf79ab4">
<p>
Sea X una variable aleatoria con esperanza finita. La varianza
de X se define por
V(X) := E

(X − E [X])
2

. (17)
En otras palabras, la varianza de X es la esperanza de la variable aleatoria (X − E [X])
2
.
Puesto que (X − E [X])
2
sólo puede tomar valores no negativos, la varianza es no negativa.
La varianza de X es una de las formas más utilizadas para medir la dispersión de los
valores de X respecto de su media. Otra medida de dispersión es el desvío estándar de X,
que se define como la raíz cuadrada de la varianza y se denota &sigma;(X):
&sigma; ( X) :=}
p
V(X). (18)
A diferencia de la varianza, el desvío estándar de una variable aleatoria es más fácil de
interpretar porque tiene las mismas unidades de X.
</p>
</div>
</div>
<div id="outline-container-org77a8330" class="outline-5">
<h5 id="org77a8330">Nota Bene</h5>
<div class="outline-text-5" id="text-org77a8330">
<p>
Grandes valores de V(X) significan grandes variaciones de los valores de X}
alrededor de la media. Al contrario, pequeños valores de V(X) implican una pronunciada
concentración de la masa de la distribución de probabilidades en un entorno de la media. En
el caso extremo, cuando la varianza es 0, la masa total de la distribución de probabilidades se
concentra en la media. Estas afirmaciones pueden hacerse más precisas y serán desarrolladas
en la sección 4.
12
\hypertarget{pfd}
</p>
</div>
</div>
</div>
<div id="outline-container-org86bc7d9" class="outline-3">
<h3 id="org86bc7d9">Cálculo</h3>
<div class="outline-text-3" id="text-org86bc7d9">
<p>
Una manera /"brutal"/de calcular V(X) es calcular la función de distribución de la variable
aleatoria (X − E [X])
2
y usar la definición de esperanza. En lo que sigue mostraremos una
manera más simple de realizar ese tipo cálculo.
Proposición 2.2 (Expresión de la varianza en términos de los momentos). Sea X una variable}
aleatoria con primer y segundo momentos finitos, entonces
V(X) = E[X}
2
] − E[X]
2
. (19)
En palabras, la varianza es la diferencia entre el segundo momento y el cuadrado del primer
momento.
</p>
</div>
<div id="outline-container-org6b6cfad" class="outline-5">
<h5 id="org6b6cfad">Demostración</h5>
<div class="outline-text-5" id="text-org6b6cfad">
<p>
Desarrollar el cuadrado (X −{E [X])
2
y usar las propiedades de la esperanza.
Poniendo (X − E [X])
2
= X<sub>2</sub>
− 2{X{E[X] + E[X]
2
se obtiene
V(X) = E[X}
2
] − 2{X{E[X] + E[X]
2
= E[X<sub>2</sub>
] − 2{E[X]
2
</p>
<ul class="org-ul">
<li>E[X]</li>
</ul>
<p>
2
= E[X<sub>2</sub>
] − E[X]
2
.
</p>
</div>
</div>
<div id="outline-container-org59ff8a6" class="outline-5">
<h5 id="org59ff8a6">Ejemplo 2.3 (Varianza de la función indicadora)</h5>
<div class="outline-text-5" id="text-org59ff8a6">
<p>
Sea$(&Omega;, \mathcal{A}, \mathbb{P})$un espacio de probabilidad.
Para cualquier evento A &isin; A vale que
V(1\{&omega; &isin; A\}) = E[1\{&omega; &isin; A\ 
2
] − E[1\{&omega; &isin; A\]
2
= \mathbb{P}(A) − \mathbb{P}(A)
2
= \mathbb{P}(A)(1 − \mathbb{P}(A)). (20)
</p>
</div>
</div>
<div id="outline-container-org294bf2b" class="outline-5">
<h5 id="org294bf2b">Ejemplo 2.4 (Dado equilibrado).</h5>
<div class="outline-text-5" id="text-org294bf2b">
<p>
Sea X el resultado del lanzamiento de un dado equilibrado.
Por el Ejemplo 1.3 sabemos que E[X] = 7 / 2. Por otra parte
E[X}
2
] =
6
X
{x=1}
x
2
\mathbb{P}(X = x) =}
1
6
6
X
{x=1}
x
2
=
1 + 4 + 9 + 16 + 25 + 36
6
=
91
6
.
Por lo tanto, de acuerdo con la Proposición 2.2, la varianza de X es
V(X) =}
91
6
−
</p>

<p>
7
2

2
=
32
12
=
8
3
.
</p>
</div>
</div>
<div id="outline-container-orgfaa00fd" class="outline-5">
<h5 id="orgfaa00fd">Ejemplo 2.5 (Fiabilidad).</h5>
<div class="outline-text-5" id="text-orgfaa00fd">
<p>
Sea T el tiempo de espera hasta que ocurre la primer falla en}
un sistema electrónico con función intensidad de fallas de la forma &lambda;(t) = 2{t{1{\}t &gt; 0{\}. Por el
</p>
</div>
</div>
<div id="outline-container-org3603d85" class="outline-5">
<h5 id="org3603d85">Ejemplo 1.7</h5>
<div class="outline-text-5" id="text-org3603d85">
<p>
sabemos que E[T ] =
\sqrt{}
&pi;/{2. Por otra parte,}
E[T<sub>2</sub>
] =
Z
&infin;
−&infin;
t
2
f ( t ) dt =}
Z
&infin;
0
t
2
2t exp(−t}
2
)dt =
Z
&infin;
0
xe
−x
dx = 1}.
La tercera igualdad se obtiene mediante el cambio de variables t
2
= x y la cuarta se deduce
usando l a fórmula de integración por partes aplicada a u = x y v
′
= e
−x
.
Por lo tanto, de acuerdo con la Proposición 2.2, la varianza de T es
V(T ) = 1 −
</p>

<p>
\sqrt{}
&pi;
2

2
= 1 −}
&pi;
4
.
13
\hypertarget{pfe}
</p>
</div>
</div>
</div>
<div id="outline-container-org99d8200" class="outline-3">
<h3 id="org99d8200">Propiedades</h3>
<div class="outline-text-3" id="text-org99d8200">
<p>
Proposición 2.6. Para todo a, b &isin; \Re 
V(aX + b) = a}
2
V(X). (21)
</p>
</div>
<div id="outline-container-org48f5009" class="outline-5">
<h5 id="org48f5009">Demostración</h5>
<div class="outline-text-5" id="text-org48f5009">
<p>
Por definición,}
V(aX + b) = E[(aX + b − E[aX + b])
2
] = E[a
2
(X − E [X])
2
] = a
2
V(X).
Para obtener la segunda igualdad usamos que E[aX + b] = a{E[X] + b.
Error cuadrático medio. Una manera de /"representar"/la variable aleatoria X mediante}
un valor fijo c &isin; \Re es hallar el valor c que minimice el llamado error cuadrático medio, 
E[(X − c)
2
].
</p>
</div>
</div>
<div id="outline-container-org216404e" class="outline-5">
<h5 id="org216404e">Teorema 2.7 (Pitágoras)</h5>
<div class="outline-text-5" id="text-org216404e">
<p>
Sea X una variable aleatoria con esperanza y varianza finitas.
Para toda constante c &isin; \Re vale que
E[(X − c)
2
] = V(X)
2
</p>
<ul class="org-ul">
<li>(E[X] − c)</li>
</ul>
<p>
2
.
En particular, el valor de c que minimiza el error cuadrático medio es la esperanza de X,
E[X].
</p>
</div>
</div>
<div id="outline-container-orgc25c430" class="outline-5">
<h5 id="orgc25c430">Demostración</h5>
<div class="outline-text-5" id="text-orgc25c430">
<p>
Escribiendo X{−}c en la forma X{−{E [X]+{E[X]−c y desarrollando cuadrados}
se obtiene (X −}c)
2
= (X −{E [X])
2
+(E[X]−c)
2
+2(X −{E [X])(E[X]−c). El resultado se obtiene
tomando esperanza en ambos lados de la igualdad y observando que E[X − E [X]] = 0.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org3ca78b0" class="outline-2">
<h2 id="org3ca78b0">Covarianza</h2>
<div class="outline-text-2" id="text-org3ca78b0">
</div>
<div id="outline-container-org6101058" class="outline-3">
<h3 id="org6101058">Definición</h3>
<div class="outline-text-3" id="text-org6101058">
</div>
<div id="outline-container-org17eeb0f" class="outline-5">
<h5 id="org17eeb0f">Definición 3.1 (Covarianza)</h5>
<div class="outline-text-5" id="text-org17eeb0f">
<p>
Sean X e Y dos variables aleatorias de varianzas finitas definidas
sobre el mismo espacio de probabilidad \((\Omega,
\mathcal{A},\mathbb{P})\). La covarianza de X e Y se define por
</p>


<p>
Cov ( X, Y ) := E[(X − E[X]) (Y − E[ Y ])]. (22)
</p>
</div>
</div>
</div>
<div id="outline-container-org56b223a" class="outline-3">
<h3 id="org56b223a">Cálculo</h3>
<div class="outline-text-3" id="text-org56b223a">
<p>
Proposición 3.2. Sean X e Y dos variables aleatorias definidas sobre
el mismo espacio de} probabilidad \((\Omega, \mathcal{A},
\mathbb{P})\). Si los segundos momentos de las variables al eatorias X
e Y son finitos, se tiene que
</p>

<p>
Cov ( X, Y ) = E[XY ] − E[X]E[Y ]}. (23)
</p>
</div>
<div id="outline-container-org2e1794c" class="outline-5">
<h5 id="org2e1794c">Demostración</h5>
<div class="outline-text-5" id="text-org2e1794c">
<p>
La esperanza del producto E[XY ] es finita porque las esperanzas E[X}
2
] y
E[Y}
2
] son finitas y vale que |{xy}| &le;}
1
2
(x
2
</p>
<ul class="org-ul">
<li>y</li>
</ul>
<p>
2
). Usando la propiedad distributiva del producto
y la linealidad de la esperanza tenemos que
E[(X − E[X]) (Y − E[Y ])] = E[XY − E[Y ]X − E[X]Y + E[X]E[Y ]]
= E[XY ] − E[Y ]E[X] − E[X]E[Y ] + E[X]E[Y ]
= E[XY ] − E[X]E[Y ].
</p>
</div>
</div>
<div id="outline-container-org9ec5b28" class="outline-5">
<h5 id="org9ec5b28">Ejemplo 3.3.</h5>
<div class="outline-text-5" id="text-org9ec5b28">
<p>
Sea$(&Omega;, \mathcal{A}, \mathbb{P})$un espacio de probabilidad y sean A &isin; \(A\) y \(B\) &isin; A dos eventos de}
probabilidad positiva. Consideremos las variables aleatorias X = 1\{&omega; &isin; A\} e Y = 1\{&omega; &isin; B\} .
Entonces,
Cov ( X, Y ) = E[XY ] − E[X]E[Y ]}
= \mathbb{P}(XY = 1) − \mathbb{P}(X = 1)\mathbb{P}(Y = 1)
= \mathbb{P}(X = 1, Y = 1) − \mathbb{P}(X = 1)\mathbb{P}(Y = 1).
La segunda y la tercera igualdad se obtienen de (2) observando que XY es una variable a
valores 0 o 1 que vale 1 si y solo si X e Y son ambas 1.
Notamos que
Cov ( X, Y  ) &gt; 0 \iff \mathbb{P}(X = 1, Y = 1) &gt; \mathbb{P}(X = 1)\mathbb{P}(Y = 1) }
\iff
\mathbb{P}(X = 1, Y = 1)
\mathbb{P}(X = 1)
&gt; \mathbb{P}( Y = 1)
\iff \mathbb{P}(Y = 1} |{X = 1) &gt; \mathbb{P}( Y = 1).
En palabras, la covarianza de X e Y es positiva si y solamente si la condición X = 1 aumenta
la probabilidad de que Y = 1.
</p>
</div>
</div>
<div id="outline-container-org776cfc0" class="outline-5">
<h5 id="org776cfc0">Ejemplo 3.4.</h5>
<div class="outline-text-5" id="text-org776cfc0">
<p>
En una urna hay 6 bolas rojas y 4 bolas negras. Se extraen 2 bolas al azar sin}
reposición. Consideramos los eventos
A<sub>i</sub>
= \sale una bola roja en la i-ésima extracción{\, i = 1, 2, 
y definimos las variables aleatorias X<sub>1</sub>
y X<sub>2</sub>
como las funciones indicadoras de los eventos
A<sub>1</sub>
y A<sub>2</sub>
respectivamente. De acuerdo con el Ejemplo anterior es intuitivamente claro que
Cov ( X<sub>1</sub>
, X<sub>2</sub>
) &lt; 0. (¿Por qué?  ) 
Cov ( X<sub>1</sub>
, X<sub>2</sub>
) = \mathbb{P}(X<sub>1</sub>
= 1, X}
2
= 1) − \mathbb{P}(X<sub>1</sub>
= 1)\mathbb{P}(X<sub>2</sub>
= 1) = \mathbb{P}(A<sub>1</sub>
&cap; A<sub>2</sub>
) − \mathbb{P}(A<sub>1</sub>
)\mathbb{P}(A<sub>2</sub>
)
=
6
10
&times;
5
9
−
6
10
</p>

<p>
5
9
&times;
6
10
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
6
9
&times;
4
10

= −}
2
75
= −}0.02666&#x2026;.
</p>
</div>
</div>
<div id="outline-container-org1d0e976" class="outline-5">
<h5 id="org1d0e976">Nota Bene</h5>
<div class="outline-text-5" id="text-org1d0e976">
<p>
Se puede mostrar que Cov(X , Y ) &gt; 0 es una indicación de que Y tiende a}
crecer cuando X lo hace, mientras que Cov(X,Y) &lt; 0 es una indicación de que Y decrece
cuando X crece.
15
</p>
</div>
</div>
</div>
<div id="outline-container-org27016f5" class="outline-3">
<h3 id="org27016f5">Propiedades</h3>
<div class="outline-text-3" id="text-org27016f5">
</div>
<div id="outline-container-orge720a34" class="outline-5">
<h5 id="orge720a34">Lema 3.5 (Propiedades)</h5>
<div class="outline-text-5" id="text-orge720a34">
<p>
Para variables aleatorias X, Y, Z y constantes a, valen las
siguientes propiedades
</p>

<ol class="org-ol">
<li>$Cov(X, X) = V(X),$</li>
<li>$Cov(X,Y) = Cov(Y, X),$</li>
<li>$Cov(aX, Y ) = aCov(X,Y),$</li>
<li>$Cov(X, Y + Z) = Cov(X,Y) + Cov(X, Z).$</li>
</ol>
</div>
</div>
<div id="outline-container-org02b0bed" class="outline-5">
<h5 id="org02b0bed">Demostración</h5>
<div class="outline-text-5" id="text-org02b0bed">
<p>
Ejercicio
</p>

<p>
Sobre la esperanza del producto. Si se conoce la covarianza y la
esperanza de las marginales, l a identidad (23) puede ser útil para
calcular la esperanza del producto: E[XY ] = E[X]E[Y ] + Cov(X,Y).
</p>
</div>
</div>
<div id="outline-container-org3223178" class="outline-5">
<h5 id="org3223178">Nota Bene</h5>
<div class="outline-text-5" id="text-org3223178">
<p>
Si X e Y son independientes, Cov(X, Y) = 0 porque E[XY ] = E[X]E[Y
]. Pero la recíproca no es cierta.
</p>
</div>
</div>

<div id="outline-container-org32e761e" class="outline-5">
<h5 id="org32e761e">Ejemplo 3.6 (Dos bolas en dos urnas)</h5>
<div class="outline-text-5" id="text-org32e761e">
<p>
El experimento aleatorio consiste en ubicar dos
bolas distinguibles en dos urnas. Sean N la cantidad de urnas ocupadas y X
i
la cantidad
de bolas en la urna i. El espacio muestral se puede representar de la siguiente manera &Omega; =
\(1, 1); (1, 2); (2, 1); (2, 2)\. La función de probabilidad conjunta de N y X
1
se muestra en el Cuadro 1
N  &setminus;  X<sub>1</sub>
0 1 2 p
N
1 1/4 0 1/4 1/2
2
0 1/2 0 1/2
p
X<sub>1</sub>
1/4 1/2 1/4
Cuadro 1: Función de probabilidad conjunta de (N, X}
1
).
Para calcular la esperanza del producto NX}
1
usamos el Teorema 1.19
E[NX<sub>1</sub>
] = 1 · 1 · p}
N,X<sub>1</sub>
(1, 1) + 1 · 2 · p}
N,X<sub>1</sub>
(1, 2) + 2 · 1 · p}
N,X<sub>1</sub>
(2, 1) + 2 · 2 · p}
N,X<sub>1</sub>
(2, 2)
= 1 · 0 + 2 · 1 / 4 + 2 · 1 / 2 + 4 · 0 = 3 / 2.
Es fácil ver que E[N] = 3 / 2 y E[X<sub>1</sub>
] = 1. Por lo tanto, Cov(N, X}
1
) = 0. Sin embargo, las
variables N y X<sub>1</sub>
no son i ndependientes.
</p>
</div>
</div>
</div>
<div id="outline-container-org79967d0" class="outline-3">
<h3 id="org79967d0">Varianza de sumas</h3>
<div class="outline-text-3" id="text-org79967d0">
<p>
Usando las propiedades de la covarianza enunciadas en Lema 3.5 se puede demostrar que
Cov


n
X
{i=1}
X
i
,
m
X
{j=1}
Y
j


=
n
X
{i=1}
m
X
{j=1}
Cov ( X
i
, Y
j
) (24)
16
En particular , se obtiene que
V
n
X
{i=1}
X
i
!
= Cov}


n
X
{i=1}
X
i
,
n
X
{j=1}
X
j


=
n
X
{i=1}
V(X}
i
) + 2
n
X
{i=1}
X
j&lt;i
Cov ( X
i
, Y
j
). (25)
</p>

<p>
Finalmente, si las variables son independientes
V
n
X
{i=1}
X
i
!
=
n
X
{i=1}
V(X}
i
). (26)
</p>
</div>
</div>
</div>
<div id="outline-container-orgacc4a0a" class="outline-2">
<h2 id="orgacc4a0a">Algunas desigualdades</h2>
<div class="outline-text-2" id="text-orgacc4a0a">
</div>
<div id="outline-container-org01958ed" class="outline-3">
<h3 id="org01958ed">Cauchy-Schwartz</h3>
<div class="outline-text-3" id="text-org01958ed">
</div>
<div id="outline-container-orga97b151" class="outline-5">
<h5 id="orga97b151">Teorema 4.1 (Cauchy-Schwartz)</h5>
<div class="outline-text-5" id="text-orga97b151">
<p>
E[|{XY |] &le; (E[X} 2 ]E[Y 2 ]) 1 / 2 (27)
</p>
</div>
</div>
<div id="outline-container-orgf269714" class="outline-5">
<h5 id="orgf269714">Demostración</h5>
<div class="outline-text-5" id="text-orgf269714">
<p>
Observar que para todo t &isin; \Re :}
0 &le; E[(t | X{| + |Y |)
2
] = t
2
E[X}
2
] + 2{t{E[|{XY |] + E[Y
2
].
</p>

<p>
Como la función cuadrática en t que aparece en el lado derecho de la igualdad tiene a lo sumo
una raíz real se deduce que
4{E[|{XY |]
2
− 4{E[X}
2
]E[Y
2
] &le; 0.
Por lo tanto,
E[|{XY |]
2
&le; E[X<sub>2</sub>
]E[Y
2
].
</p>
</div>
</div>
<div id="outline-container-org00c4e8c" class="outline-5">
<h5 id="org00c4e8c">Corolario 4.2</h5>
<div class="outline-text-5" id="text-org00c4e8c">
<p>
Sea X una variable aleatoria tal que E[X 
2
] &lt; &infin;. Si a &lt; E[X], entonces}
\mathbb{P}(X &gt; a) &ge;
(E[X] − a)
2
E[X}
2
]
.
</p>
</div>
</div>
<div id="outline-container-org3bbfcd5" class="outline-5">
<h5 id="org3bbfcd5">Demostración</h5>
<div class="outline-text-5" id="text-org3bbfcd5">
<p>
De la desigualdad X}1\{X &gt; a\} &le; |X}1\{X &gt; a\}| y de la propiedad de
monotonía de la esperanza se deduce que
E[X{1{\}X &gt; a{\] &le; E[|{X{1} \{X &gt; a\}|]. (28)
Aplicando la desigualdad de Cauchy-Schwartz a |{X{1} \{X &gt; a\}| se obtiene que
E[|{X{1} \{X &gt; a\}|] &le; (E[X}
2
]E[1\{X &gt; a\
2
])
1 / 2
= (E[X<sub>2</sub>
]\mathbb{P}(X &gt; a))
1 / 2
(29)
Observando que X = X{1{\}X &gt; a{\} + X{1{\}X &le; a{\} y que X{1{\}X &le; a{\} &le; a se deduce que
E[X] = E[X{1{\}X &gt; a{\] + E[X{1{\}X &le; a{\] &le; E[X{1{\}X &gt; a{\] + a}
17
y en consecuencia,
E[X] − a &le; E[X{1{\}X &gt; a{\]. (30)
Combinando las desigualdades (30), (28) y (29) se obtiene que
E[X] − a &le; (E[X}
2
]\mathbb{P}(X &gt; a))
1 / 2
y como E[X] − a &gt; 0, elevando al cuadrado, se concluye que
(E[X] − a)
2
&le; E[X<sub>2</sub>
]\mathbb{P}(X &gt; a).
El resultado se obtiene despejando.
</p>
</div>
</div>
</div>
<div id="outline-container-orgfe73ece" class="outline-3">
<h3 id="orgfe73ece">Chebyshev</h3>
<div class="outline-text-3" id="text-orgfe73ece">
</div>
<div id="outline-container-orgf8ff27a" class="outline-5">
<h5 id="orgf8ff27a">Teorema 4.3 (Desigualdad de Chebyshev)</h5>
<div class="outline-text-5" id="text-orgf8ff27a">
<p>
Sea &varphi; : R &rarr; \Re tal que &varphi; &ge; 0 y A &isin; B(R) . Sea 
i
A
:= ínf\{&varphi;}(x) : x &isin; A{\. Entonces, 
i
A
\mathbb{P}(X &isin; A) &le; E[&varphi;(X)] (31)
</p>
</div>
</div>
<div id="outline-container-org62bda56" class="outline-5">
<h5 id="org62bda56">Demostración</h5>
<div class="outline-text-5" id="text-org62bda56">
<p>
La definición de i}
A
y el hecho de que &varphi; &ge; 0 implican que
i
A<sub>1</sub>\{X &isin; A\} &le; &varphi; ( X ) 1\{X &isin; A\} &le; &varphi; ( X ) 
El resultado se obtiene tomando esperanza.
En lo que sigue enunciaremos algunos corol arios que se obtienen como casos particulares
del Teorema 4.3.
</p>
</div>
</div>
<div id="outline-container-org029d572" class="outline-5">
<h5 id="org029d572">Corolario 4.4 (Desigualdad de Markov)</h5>
<div class="outline-text-5" id="text-org029d572">
<p>
Sea X una variable aleatoria a valores no negativos.
Para cada a &gt; 0 vale que
\mathbb{P}(X &ge; a) &le;
E[X]
a
. (32)
</p>
</div>
</div>
<div id="outline-container-org69238dc" class="outline-5">
<h5 id="org69238dc">Demostración</h5>
<div class="outline-text-5" id="text-org69238dc">
<p>
Aplicar la desigualdad de Chebyshev usando la función &varphi;(x) = x restringi
da a la semi-r ecta no negativa [0, &infin;}) y el conjunto A = [a, &infin;}) para obtener
a{\mathbb{P}( X &ge; a) &le; E[&varphi; ( X)] = E[X].
y despejar.
</p>
</div>
</div>
<div id="outline-container-org979a122" class="outline-5">
<h5 id="org979a122">Corolario 4.5.</h5>
<div class="outline-text-5" id="text-org979a122">
<p>
Sea a &gt; 0} . Vale que}
\mathbb{P}(X &gt; a) &le;
1
a
2
E[X}
2
]. (33)
</p>
</div>
</div>
<div id="outline-container-org3a7967b" class="outline-5">
<h5 id="org3a7967b">Demostración</h5>
<div class="outline-text-5" id="text-org3a7967b">
<p>
Aplicar la desigualdad de Chebyshev usando la función &varphi;(x) = x}
2
y el
conjunto A = (a, &infin;}) para obtener
a
2
\mathbb{P}(X &gt; a) &le; E[X}
2
]
y despejar.
</p>
</div>
</div>
<div id="outline-container-org30f3fbf" class="outline-5">
<h5 id="org30f3fbf">Corolario 4.6 (Pequeña desigualdad de Chebyshev)</h5>
<div class="outline-text-5" id="text-org30f3fbf">
<p>
Sea X una variable aleatoria de vari
anza finita. Para cada a &gt; 0 vale que
\mathbb{P}(|X − E[X]| &ge; a) &le;
V(X)
a
2
. (34)
18
</p>
</div>
</div>
<div id="outline-container-org441d982" class="outline-5">
<h5 id="org441d982">Demostración</h5>
<div class="outline-text-5" id="text-org441d982">
<p>
Debido a que (X − E [X])
2
es una variable aleatoria no negativa podemos
aplicar l a desigualdad de Markov (poniendo a
2
en lugar de a) y obtenemos
P

(X − E [X])
2
&ge; a
2

&le;
E[(X − E[X])
2
]
a
2
=
V(X)
a
2
.
La desigualdad (X − E [X])
2
&ge; a
2
es equivalente a la desigualdad |X − E[X]| &ge; a}. Por lo
tanto,
\mathbb{P}(|X − E[X]| &ge; a) &le;
V(X)
a
2
.
Lo que concluye la demostración.
</p>
</div>
</div>
<div id="outline-container-org9bc7c36" class="outline-5">
<h5 id="org9bc7c36">Nota Bene</h5>
<div class="outline-text-5" id="text-org9bc7c36">
<p>
Grosso modo la pequeña desigualdad de Chebyshev establece que si la varianza
es pequeña, los grandes desvíos respecto de la media son improbables.
</p>
</div>
</div>
<div id="outline-container-org8bf32e8" class="outline-5">
<h5 id="org8bf32e8">Corolario 4.7.</h5>
<div class="outline-text-5" id="text-org8bf32e8">
<p>
Sea X una variable aleatoria con varianza finita, entonces para cada &alpha; &gt; 0}
\mathbb{P}(|X − E[X]| &ge; &alpha;&sigma;}(X)) &le;
1
&alpha;
2
. (35)
El resultado se obtiene poniendo a = &alpha;&sigma;(X) en la pequeña desigualdad de Chebyshev.
</p>
</div>
</div>
<div id="outline-container-orgc9c44e0" class="outline-5">
<h5 id="orgc9c44e0">Ejemplo 4.8.</h5>
<div class="outline-text-5" id="text-orgc9c44e0">
<p>
La cantidad X de artículos producidos por un fábrica durante una semana es}
una variable aleatoria de media 500.
(a) ¿Qué puede decirse sobre la probabilidad de que la producción semanal supere los
1000 artículos? Por la desigualdad de Markov,
\mathbb{P}(X &ge; 1000) &le;
E[X]
1000
=
500
1000
=
1
2
.
(b) Si la varianza de la producción semanal es conocida e igual a 100, ¿qué puede decirse
sobre la probabilidad de que la producción semanal se encuentre entre 400 y 600 artículos?
Por la desigualdad de Chebyshev,
\mathbb{P}(|X − 500{| &ge; 100) &le;
&sigma;
2
(100)
2
=
1
100
.
Por lo tanto, \mathbb{P}(|X − 500{| &lt; 100) &ge; 1 −}
1
100
=
99
100
, la probabilidad de que la producción
semanal se encuentre entre 400 y 600 artículos es al menos 0.99.
El que mucho abarca poco aprieta. Las desigualdades de Markov y Chebyshev son im
portantes porque nos permiten deducir cotas sobre las probabilidades cuando solo se conocen
la media o la media y la varianza de la distribución de probabilidades. Sin embargo, debe
tenerse en cuenta que las desigualdades de Markov y de Chebyshev producen cotas universales
que no dependen de las distribuciones de las variables aleatorias (dependen pura y exclusiva
mente de los valores de la esperanza y de la varianza). Por este motivo su comportamiento
será bastante heterogéneo: en algunos casos producirán cotas extremadamente finas, pero en
otros c asos solamente cotas groseras.
19
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org2820203" class="outline-2">
<h2 id="org2820203">La ley débil de los grandes números</h2>
<div class="outline-text-2" id="text-org2820203">
</div>
<div id="outline-container-org24333b2" class="outline-5">
<h5 id="org24333b2">Teorema 5.1 (Le y débil de los grandes números)</h5>
<div class="outline-text-5" id="text-org24333b2">
<p>
Sea \(X_1, X2, \dots\) una sucesión de variables
aleatorias independientes idénticamente distribuidas, tales que V(X<sub>1</sub>) &lt; &infin; . Sea S<sub>n</sub>
, n &ge; 1, la
sucesión de las sumas parciales definida por S<sub>n</sub>
:=
P
n
{i=1}
X
i
. Entonces, para cualquier &epsilon; &gt; 0
lim<sub>n  &rarr; &infin;</sub>
P
</p>

<p>




S<sub>n</sub>
n
− E[X<sub>1</sub>
]




&gt; &epsilon;

= 0.
</p>
</div>
</div>
<div id="outline-container-org41f69b3" class="outline-5">
<h5 id="org41f69b3">Demostración</h5>
<div class="outline-text-5" id="text-org41f69b3">
<p>
Se obtiene aplicando la desigualdad de Chebyshev a la variable aleatoria
S<sub>n</sub>
/n. 
Usando que la esperanza es un operador lineal se obtiene que
E [S<sub>n</sub>
/n] =}
1
n
E
"
n
X
{i=1}
X
i
\#
=
1
n
n
X
{i=1}
E[X}
i
] = E[X<sub>1</sub>
].
Como las variables X<sub>1</sub>
, X<sub>2</sub>
, &hellip; son independientes tenemos que}
V (S<sub>n</sub>
/n) =}
1
n
2
V
n
X
{i=1}
X
i
!
=
1
n
2
n
X
{i=1}
V(X}
i
) =
V(X}
1
)
n
.
Entonces, por la desigualdad de Chebyshev, obtenemos la siguiente estimación
P
</p>

<p>




S<sub>n</sub>
n
− E[X<sub>1</sub>
]




&gt; &epsilon;

&le;
V(X}
1
)
n&epsilon;
2
. (36)
Como V(X<sub>1</sub>
) &lt; &infin; el lado derecho de la última desigualdad tiende a 0 cuando n &rarr; &infin;} .
</p>
</div>
</div>
<div id="outline-container-orga4dce7b" class="outline-5">
<h5 id="orga4dce7b">Nota Bene</h5>
<div class="outline-text-5" id="text-orga4dce7b">
<p>
La ley débil de los grandes números establecida en el Teorema 5.1 sir ve como}
base para la noción intuitiva de probabilidad como medida de las frecuencias relativas. La
proposición /"en una larga serie de ensayos idénticos la frecuencia relativa del evento A se
aproxima a su probabilidad \mathbb{P}(A)"/se puede hacer teóricamente más precisa de la siguiente
manera: el resultado de cada ensayo se representa por una variable aleatoria (independiente de
las demás) que vale 1 cuando se obtiene el evento A y vale cero en caso contrario. La expresión
/"una larga serie de ensayos"/adopta la forma de una sucesión X<sub>1</sub>
, X<sub>2</sub>
, &hellip; de variables aleatorias}
independientes cada una con la misma distribución que la indicadora del evento A. Notar que
X
i
= 1 significa que /"en el i-ésimo ensayo ocurrió el evento A"/y la suma parcial S<sub>n</sub>
=
P
n
{i=1}
X
i
representa la /"frecuencia del evento A"/en los primeros n ensayos. Puesto que E[X<sub>1</sub>
] = \mathbb{P}(A)
y V(X<sub>1</sub>
) = \mathbb{P}(A)(1 − \mathbb{P}(A)) la estimación (36) adopta la forma
P
</p>

<p>




S<sub>n</sub>
n
− \mathbb{P}(A)}




&gt; &epsilon;

&le;
\mathbb{P}(A)(1 − \mathbb{P}(A))
n&epsilon;
2
. (37)
Por lo tanto, la probabilidad de que la frecuencia relativa del evento A se desvíe de su prob
abilidad \mathbb{P}(A) en más de una cantidad prefijada &epsilon;, puede hacerse todo lo c hica que se qui era,
siempre que la cantidad de ensayos n sea suficientemente grande.
</p>
</div>
</div>
<div id="outline-container-org962da1b" class="outline-5">
<h5 id="org962da1b">Ejemplo 5.2 (Encuesta electoral).</h5>
<div class="outline-text-5" id="text-org962da1b">
<p>
Se quiere estimar la proporción del electorado que pre
tende votar a un cierto candidato. Cuál deb e ser el tamaño muestral para garantizar un
determinado e rror entre la proporción poblacional, p, y la proporción muestral S 
n
/n{?}
20
Antes de resolver este problema, debemos reﬂexionar sobre la definición de error. Habit}
ualmente, cuando se habla de error, se trata de un número real que expresa la (in)capacidad
de una cierta cantidad de representar a otra. En los problemas de estimación estadística,
debido a que una de las cantidades es una variable aleatoria y l a otra no lo es, no es posible
interpretar de un modo tan sencillo el significado de la palabra error.
Toda medida muestral tiene asociada una incerteza (o un riesgo) expresada por un modelo
probabilístico. En este problema consideramos que el voto de cada elector se comporta como
una variable aleatoria X tal que \mathbb{P}(X = 1) = p y \mathbb{P}(X = 0) = 1{−p, donde X = 1 significa que
el elector vota por el candidato considerado. Por lo tanto, cuando se habla de que quer emos
encontrar un tamaño muestral suficiente para un determinado error máximo, por ejemplo
0.02, tenemos que hacerlo con una medida de certeza asociada. Matemáticamente, queremos
encontrar n tal que P



S<sub>n</sub>
n
− p


&le; 0.02}

&ge; 0.9999 o, equivalentemente, queremos encontrar n}
tal que
P
</p>

<p>




S<sub>n</sub>
n
− p




&gt; 0.02}

&le; 0.0001.
Usando la estimación (37) se deduce que
P
</p>

<p>




S<sub>n</sub>
n
− p




&gt; 0.02}

&le;
p(1 − p ) 
n(0.02)
2
.
El numerador de la fracc ión que aparece en el l
ado derecho de la estimación depende de p y
el valor de p es desconocido. Sin embargo, sabemos que p(1 −p) es una parábola convexa con
raíces en p = 0 y p = 1 y por lo tanto su máximo ocurre cuando p = 1 / 2, esto es p(1{−p) &le; 1 / 4.
En l a peor hipótesis tenemos:
P
</p>

<p>




S<sub>n</sub>
n
− p




&gt; 0.02}

&le;
1
4n(0.02)
2
.
Como máximo estamos dispuestos a correr un riesgo de 0.0001 y en el peor caso tenemos aco
tada la máxima incerteza por (4n(0.02)
2
)
−{1}
. El problema se reduce a resolver la desigualdad
(4n(0.02)
2
)
−{1}
&le; 0.0001. Por lo tanto,}
n &ge; ((0}.0001)
˙
4(0.02)
2
)
−{1}
= 6250000.
Una cifra absurdamente grande!! Más adelante, mostraremos que existen métodos más sofisti
cados que permiten disminuir el tamaño de la muestra.
21
</p>
</div>
</div>
</div>
<div id="outline-container-orga46b211" class="outline-2">
<h2 id="orga46b211">Distribuciones particulares</h2>
<div class="outline-text-2" id="text-orga46b211">
<p>
Para facilitar referencias posteriores presentaremos tablas de
esperanzas y varianzas de algunas distribuciones importantes de uso
frecuente y describiremos el método para obtener las.
</p>
</div>
<div id="outline-container-orgf43db95" class="outline-3">
<h3 id="orgf43db95">Discretas</h3>
<div class="outline-text-3" id="text-orgf43db95">
<p>
No. Nombre Probabilidad Soporte Esperanza Varianza
</p>
</div>
<div id="outline-container-org028879a" class="outline-4">
<h4 id="org028879a">1. Uniforme</h4>
<div class="outline-text-4" id="text-org028879a">
<p>
1
b{−}a{+1}
a &le; x &le; b  ( a + b ) /{2 (b − a)(b − a − 2)}/{12}
</p>
</div>
</div>
<div id="outline-container-org83a2ba1" class="outline-4">
<h4 id="org83a2ba1">2. Bernoulli p</h4>
<div class="outline-text-4" id="text-org83a2ba1">
<p>
x
(1 − p)
1{−x}
x &isin; \{0}, 1{\} p p(1 − p ) 
</p>
</div>
</div>
<div id="outline-container-orgbaf7a8a" class="outline-4">
<h4 id="orgbaf7a8a">3. Binomial</h4>
<div class="outline-text-4" id="text-orgbaf7a8a">
<p>

n
x

p
x
(1 − p)
n{−}x
0 &le; x &le; n np np}(1 − p)
</p>
</div>
</div>
<div id="outline-container-org76c182b" class="outline-4">
<h4 id="org76c182b">4. Geométrica (1 − p)</h4>
<div class="outline-text-4" id="text-org76c182b">
<p>
x{−{1
p x &isin; N 1 /p (1 − p ) /p
2
</p>
</div>
</div>
<div id="outline-container-org6ba176e" class="outline-4">
<h4 id="org6ba176e">5. Poisson</h4>
<div class="outline-text-4" id="text-org6ba176e">
<p>
&lambda;
x
x{!}
e
− &lambda; 
x &isin; N
0
&lambda; &lambda;
Cuadro 2: Esperanza y varianza de algunas distribuciones discretas de uso frecuente.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf5c5e5b" class="outline-3">
<h3 id="orgf5c5e5b">Continuas</h3>
<div class="outline-text-3" id="text-orgf5c5e5b">
<p>
No. Nombre Densidad Soporte Esperanza Varianza
</p>
</div>
<div id="outline-container-org63eb3e7" class="outline-4">
<h4 id="org63eb3e7">1. Uniforme</h4>
<div class="outline-text-4" id="text-org63eb3e7">
<p>
1
b{−}a
x &isin; [ a, b] (a + b ) /{2 (b − a ) 
2
/{12}
</p>
</div>
</div>
<div id="outline-container-orgffc3968" class="outline-4">
<h4 id="orgffc3968">2. Exponencial &lambda; e}</h4>
<div class="outline-text-4" id="text-orgffc3968">
<p>
−{&lambda; x}
x &gt; 0 1}/&lambda; 1}/&lambda;
2
</p>
</div>
</div>
<div id="outline-container-org0624f33" class="outline-4">
<h4 id="org0624f33">3. Gamma</h4>
<div class="outline-text-4" id="text-org0624f33">
<p>
&lambda;
&nu;
&Gamma;( &nu; )
x
&nu;{−{1
e
−{&lambda; x}
x &gt; 0 &nu;/&lambda; &nu;/&lambda;
2
</p>
</div>
</div>
<div id="outline-container-org2c30265" class="outline-4">
<h4 id="org2c30265">4. Beta</h4>
<div class="outline-text-4" id="text-org2c30265">
<p>
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
x
&nu;
1
−{1}
(1 − x)
&nu;
2
−{1}
x &isin; (0}, 1)
&nu;
1
&nu;
1
</p>
<ul class="org-ul">
<li>&nu;</li>
</ul>
<p>
2
&nu;
1
&nu;
2
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;</li>
</ul>
<p>
2
)
2
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;</li>
</ul>
<p>
2
+1)
</p>
<ol class="org-ol">
<li>Normal</li>
</ol>
<p>
1
\sqrt{}
2{&pi;&sigma;}
e
−(x}−{&mu; ) 
2
/{2}&sigma;
2
x &isin; \Re &mu; &sigma;
2
Cuadro 3: Esperanza y varianza de algunas distribuciones continuas de uso frecuente.
</p>
</div>
</div>
</div>
<div id="outline-container-orge0cf577" class="outline-3">
<h3 id="orge0cf577">Cuentas con variables discretas</h3>
<div class="outline-text-3" id="text-orge0cf577">
</div>
<div id="outline-container-orgf6353e2" class="outline-4">
<h4 id="orgf6353e2">1. Distribución uniforme discreta.</h4>
<div class="outline-text-4" id="text-orgf6353e2">
<p>
Sean a y b dos números enteros tales que a &lt; b}. Se dice que la variable aleatoria X tiene
distribución uniforme sobre el <i>"intervalo"</i> de números enteros [a, b] := \{a, a + 1, &hellip; , b{\}, y se
denota X &sim; \mathcal{U} [a, b], si X es discreta y tal que
\mathbb{P}(X = x) =}
1
b − a + 1}
1\{x &isin; \{a, a + 1, &hellip; , b\}\}.
Notando que la distribución de X coincide con la de la variable X
∗
</p>
<ul class="org-ul">
<li>a − 1, donde X</li>
</ul>
<p>
∗
está uniformemente distribuida sobre \1, &hellip; , b − a + 1{\, resulta que
E[X] = E[X}
∗
] + a − 1 =
1 + (b − a + 1)
2
</p>
<ul class="org-ul">
<li>a − 1 =</li>
</ul>
<p>
a + b
2
.
Para calcular la varianza de X, consideramos primero el caso más simple donde a = 1 y b = n.
Por inducción en n se puede ver que
E[X}
2
] =
1
n
n
X
{k=1}
k
2
=
(n + 1)(2n + 1)
6
.
La varianza puede obtenerse en términos de los momentos de orden 1 y 2:
V(X) = E[X}
2
] − E[X]
2
=
(n + 1)(2n + 1)
6
−
(n + 1)
2
4
=
(n + 1)[2(2n + 1) − 3(n + 1)]
12
=
n
2
− 1}
12
.
Para el caso general, notamos que la variable aleatoria uniformemente
distribuida sobre [a, b] tiene la misma varianza que la variable
aleatoria uniformemente distribuida sobre [1, b{−}a}+1], puesto que
esas dos variables difieren en la constante a −} 1. Por lo tanto, la
varianza buscada se obtiene de la fórmula anterior sustituyendo n = b
− a + 1
V(X) =}
(b − a + 1)
2
− 1}
12
=
(b − a)(b − a + 2)
12
.
</p>
</div>
</div>
<div id="outline-container-org6a70575" class="outline-4">
<h4 id="org6a70575">2. Distribución Bernoulli.</h4>
<div class="outline-text-4" id="text-org6a70575">
<p>
Sea p &isin; (0, 1). Se dice que la variable aleatoria X tiene distribución Bernoulli de parámetro}
p, y se denota X &sim; Bernoulli(}p), si X es discreta y tal que}
\mathbb{P}(X = x) = p}
x
(1 − p)
1{−x}
, donde x = 0, 1}.
Por definición,
E[X] = 0 · \mathbb{P}(X = 0) + 1 · \mathbb{P}(X = 1) = 0 · (1 − p) + 1 · p = p.}
Por otra parte,
E[X}
2
] = 0
2
· \mathbb{P}(X = 0) + 1
2
· \mathbb{P}(X = 1) = p. 
Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= p − p}
2
= p(1 − p).
</p>
</div>
</div>
<div id="outline-container-orge9e2502" class="outline-4">
<h4 id="orge9e2502">3. Distribución Binomial.</h4>
<div class="outline-text-4" id="text-orge9e2502">
<p>
Sean p &isin; (0, 1) y n &isin; N . Se dice que la variable aleatoria X tiene distribución Binomia
l}
de parámetros n y p, y se denota X &sim; Binomial (}n, p), si X es discreta y tal que
\mathbb{P}(X = x) =}
</p>

<p>
n
x

p
x
(1 − p)
n{−}x
, donde x = 0, 1, &hellip; , n.
Por definición,
E[X] =}
n
X
{x=0}
x{\mathbb{P}( X = x) =}
n
X
{x=0}
x
</p>

<p>
n
x

p
x
(1 − p)
n{−}x
=
n
X
{x=1}
x<sub>n</sub>{!}
(n − x)!x!
p
x
(1 − p)
n{−}x
=
n
X
{x=1}
n{!}
(n − x)!(x − 1)!
p
x
(1 − p)
n{−}x
= np}
n
X
{x=1}
(n − 1)!
(n − x)!(x − 1)!
p
x{−{1
(1 − p)
n{−}x
= np}
n{−{1
X
y{=0}
</p>

<p>
n − 1
y

p
y
(1 − p)
n{−{1}−}y
= np(p + (1 − p))
n{−{1
= np.
Análogamente se puede ver que
E[X}
2
] = np((n − 1)p + 1).
Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= np((n − 1)p + 1) − (np)
2
= np((n − 1)p + 1 − np}) = np(1 − p).
</p>
</div>
</div>
<div id="outline-container-org2827801" class="outline-4">
<h4 id="org2827801">4. Distribución Geométrica.</h4>
<div class="outline-text-4" id="text-org2827801">
<p>
Sea p &isin; (0, 1). Se dice que la variable aleatoria X tiene distribución Geométrica de}
parámetro p, y se denota X &sim; Geométrica(p), si X es discreta y tal que 
\mathbb{P}(X = x) = (1 − p)
x{−{1
p{1{\}x &isin; N\}.
Por definición,
E[X] =}
&infin;
X
{x=1}
x{\mathbb{P}( X = x) =}
&infin;
X
{x=1}
x(1 − p ) 
x{−{1
p = p
&infin;
X
{x=1}
x(1 − p ) 
x{−{1
.
La serie se calcula observando que x(1 − p)
x{−{1
= −}
d
dp
(1 − p)
x
y recordando que las series de
potencias se pueden derivar término a término:
&infin;
X
{x=1}
x(1 − p ) 
x{−{1
= −}
d
dp
&infin;
X
{x=1}
(1 − p)
x
= −}
d
dp

p
−{1}
− 1}

= p
−{2}
.
Por lo tanto, E[X] = p · p}
−{2}
= 1{/p}.
24
Para calcular V(X) usaremos la misma técnica: derivamos dos veces ambos lado s de la
igualdad
P
&infin;
{x=1}
(1 − p)
x{−{1
= p
−{1}
y obtenemos
2p
−{3}
=
d
2
dp
2
p
−{1}
=
d
2
dp
2
&infin;
X
{x=1}
(1 − p)
x{−{1
=
&infin;
X
{x=1}
(x − 1)(x − 2)(1 − p)
x{−{3
=
&infin;
X
{x=1}
(x + 1)x(1 − p)
x{−{1
=
&infin;
X
{x=1}
x
2
(1 − p)
x{−{1
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
&infin;
X
{x=1}
x(1 − p ) 
x{−{1
.
Multiplicando por p los miembros de las igualdades obtenemos, 2p
−{2}
= E[X<sub>2</sub>
] + E[X] =
E[X}
2
] + p
−{1}
. En consecuencia, E[X<sub>2</sub>
] = 2p
−{2}
− p
−{1}
. Por lo tanto,
V(X) = E[X}
2
] − E[X]
2
= 2p
−{2}
− p
−{1}
− p
−{2}
= p
−{2}
− p
−{1}
= p
−{2}
(1 − p).
</p>
<ol class="org-ol">
<li>Distribución de Poisson.</li>
</ol>
<p>
Sea &lambda; &gt; 0. Se dice que la variable aleatoria X tiene distribución de Poisson de intensidad}
&lambda;, y se denota X &sim; Poisson(}&lambda;), si X es discreta y tal que}
\mathbb{P}(X = x) =}
&lambda;
x
x{!}
e
− &lambda; 
1\{x &isin; N
0
\}.
Por definición,
E[X] =}
&infin;
X
{x=0}
x{\mathbb{P}( X = x) =}
&infin;
X
{x=0}
x
&lambda;
x
x{!}
e
− &lambda; 
= &lambda; e}
− &lambda; 
&infin;
X
{x=1}
x
&lambda;
x{−{1
x{!}
= &lambda; e}
− &lambda; 
&infin;
X
{x=1}
&lambda;
x{−{1
(x − 1)!
= &lambda; e}
− &lambda; 
e
&lambda;
= &lambda;.
Derivando término a término, se puede ver que
E[X}
2
] =
&infin;
X
{x=0}
x
2
\mathbb{P}(X = x) =}
&infin;
X
{x=0}
x
2
&lambda;
x
x{!}
e
− &lambda; 
= &lambda; e}
− &lambda; 
&infin;
X
{x=1}
x
2
&lambda;
x{−{1
x{!}
= &lambda; e}
− &lambda; 
&infin;
X
{x=1}
x&lambda;
x{−{1
(x − 1)!
= &lambda; e}
− &lambda; 
d
d&lambda;
&infin;
X
{x=1}
&lambda;
x
(x − 1)!
= &lambda; e}
− &lambda; 
d
d&lambda;

&lambda; e
&lambda;

= &lambda; e}
− &lambda; 

e
&lambda;
</p>
<ul class="org-ul">
<li>&lambda; e}</li>
</ul>
<p>
&lambda;

= &lambda; + &lambda;}
2
.
Por lo tanto,
V(X) = E[X}
2
] − E[X] = &lambda; + &lambda;}
2
− &lambda;}
2
= &lambda;.
</p>
</div>
</div>
</div>
<div id="outline-container-org7a57e98" class="outline-3">
<h3 id="org7a57e98">Cuentas con variables continuas</h3>
<div class="outline-text-3" id="text-org7a57e98">
</div>
<div id="outline-container-orga2ae247" class="outline-4">
<h4 id="orga2ae247">1. Distribución uniforme.</h4>
<div class="outline-text-4" id="text-orga2ae247">
<p>
Sean a &lt; b}. Se dice que la variable aleatoria X tiene distribución uniforme sobre el}
intervalo [a, b], y se denota X &sim; \mathcal{U} [a, b], si X es absolutamente continua con densidad de}
probabilidades
f ( x) =}
1
b − a
1\{x &isin; [a, b]\}.
25
\hypertarget{pf1a}
Por definición,
E[X] =}
Z
&infin;
−&infin;
xf ( x ) dx =}
Z
&infin;
−&infin;
x
1
b − a
1\{x &isin; [a, b]\dx = 
1
b − a
Z
b
a
x dx =}
1
b − a
</p>

<p>
b
2
− a
2
2

=
a + b
2
.
Por otra parte,
E[X}
2
] =
Z
&infin;
−&infin;
x
2
f ( x ) dx =}
1
b − a
Z
b
a
x
2
dx =}
1
b − a
</p>

<p>
b
3
− a
3
3

=
a
2
</p>
<ul class="org-ul">
<li>ab + b</li>
</ul>
<p>
2
3
.
Finalmente,
V(X) = E[X}
2
] − E[X]
2
=
a
2
</p>
<ul class="org-ul">
<li>ab + b</li>
</ul>
<p>
2
3
−
</p>

<p>
a + b
2

2
=
a
2
− 2{ab + b}
2
12
=
(b − a)
2
12
.
</p>
</div>
</div>
<div id="outline-container-org2ee1f94" class="outline-4">
<h4 id="org2ee1f94">2. Distribución exponencial.</h4>
<div class="outline-text-4" id="text-org2ee1f94">
<p>
Sea &lambda; &gt; 0. Se dice que la variable aleatoria X tiene distribución exponencial de intensi
dad &lambda;, y se denota X &sim; Exp(}&lambda;), si X es absolutamente continua con función densidad de
probabilidades
f ( x) = &lambda; e
−{&lambda; x}
1\{x &ge; 0\}.
El cálculo de E[X] y V(X) se reduce al caso X &sim; Exp(1). Basta observar que Y &sim; Exp( &lambda; )
si y solo si Y = &lambda;}
−{1}
X, donde X &sim; Exp(1) y usar las identidades E[}&lambda;
−{1}
X] = &lambda;
−{1}
E[X] y}
V( &lambda; }
−{1}
X) = &lambda;
−{2}
V(X). En lo que sigue suponemos que X &sim; Exp(1).
Integrando por partes se obtiene,
E[X] =}
Z
&infin;
−&infin;
xf ( x ) dx =}
Z
&infin;
−&infin;
xe
−x
1\{x &ge; 0\} =
Z
&infin;
0
&lambda; xe
−x
dx = −} xe
−x




&infin;
0
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
Z
&infin;
0
e
−x
dx
= 1.
Por otra parte,
E[X}
2
] =
Z
&infin;
−&infin;
x
2
f ( x ) dx =}
Z
&infin;
0
x
2
e
−x
dx = −} x
2
e
−x


&infin;
0
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
Z
&infin;
0
2{xe}
−x
dx = 2}.
Por lo tanto, V(X) = E[X<sub>2</sub>
] − E[X]
2
= 2 − 1 = 1.
</p>
</div>
</div>
<div id="outline-container-org0426be6" class="outline-4">
<h4 id="org0426be6">3. Distribución gamma.</h4>
<div class="outline-text-4" id="text-org0426be6">
<p>
La función gamma se define por
&Gamma;(t) :=
Z
&infin;
0
x
t{−{1
e
−x
dx t &gt; 0}.
Integrando por partes puede verse que &Gamma;(t) = (t − 1)&Gamma;(t − 1) para todo t &gt; 0. De aquí se
deduce que la función gamma interpola a los números factoriales en el sentido de que
&Gamma;(n + 1) = n! para n = 0, 1, &hellip;}
Sean &lambda; &gt; 0 y &nu; &gt; 0. Se dice que la variable aleatoria X tiene distribución gamma de parámetros}
&nu;, &lambda;, , y se denota X &sim; &Gamma;(}&nu;, &lambda;), si X es absolutamente continua con función densidad de}
probabilidades
f ( x) =}
&lambda;
&nu;
&Gamma;( &nu; )
x
&nu;{−{1
e
−{&lambda; x}
1\{x &gt; 0}\}.
El cálculo de E[X] y V(X) se reduce al caso X &sim; &Gamma;(&nu;, 1). Para ello, basta observar que Y &sim;
&Gamma;(&nu;, &lambda;) si y solo si Y = &lambda;}
−{1}
X, donde X &sim; &Gamma;(}&nu;, 1) y usar las identidades E[&lambda;
−{1}
X] = &lambda;
−{1}
E[X]
y V( &lambda; 
−{1}
X) = &lambda;
−{2}
V(X). En lo que sigue suponemos que X &sim; &Gamma;(&nu;, 1)
E[X] =}
Z
&infin;
0
xf ( x ) dx =}
Z
&infin;
0
1
&Gamma;( &nu; )
x
&nu;
e
−x
dx =}
1
&Gamma;( &nu; )
&Gamma;(&nu; + 1) = &nu;.
Del mismo mo do se puede ver que E[X<sub>2</sub>
] = (&nu; + 1)&nu; = &nu;}
2
</p>
<ul class="org-ul">
<li>&nu;}. Por lo tanto, V(X) =</li>
</ul>
<p>
E[X}
2
] − E[X]
2
= &nu;}.
</p>
</div>
</div>
<div id="outline-container-org8460458" class="outline-4">
<h4 id="org8460458">4. Distribución beta</h4>
<div class="outline-text-4" id="text-org8460458">
<p>
Sean &nu;}
1
&gt; 0 y &nu;
2
&gt; 0. Se dice que la variable aleatoria X tiene distribución beta de
parámetros &nu;}
1
, &nu;}
2
, y se denota X &sim; &beta;( &nu; 
1
, &nu;
2
), si X es absolutamente continua con función
densidad de probabilidades
f ( x) =}
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
x
&nu;
1
−{1}
(1 − x)
&nu;
2
−{1}
1\{x &isin; (0, 1\}.
Por definición,
E[X] =}
Z
&infin;
−&infin;
xf ( x ) dx =}
Z
&infin;
−&infin;
x
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
x
&nu;
1
−{1}
(1 − x)
&nu;
2
−{1}
1\{x &isin; (0, 1}\dx
=
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
Z
1
0
x
&nu;
1
(1 − x)
&nu;
2
−{1}
dx =}
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>1)&Gamma;( &nu;</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
=
&nu;
1
&nu;
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
Por otra parte,
E[X}
2
] =
Z
&infin;
−&infin;
x
2
f ( x ) dx =}
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
Z
1
0
x
&nu;
1
+1
(1 − x)
&nu;
2
−{1}
dx
=
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
)&Gamma;( &nu; 
2
)
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>2)&Gamma;( &nu;</li>
</ul>
<p>
2
)
&Gamma;( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>2)</li>
</ul>
<p>
=
&nu;
1
( &nu; 
1
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
Finalmente,
V(X) = E[X}
2
] − E[X]
2
=
&nu;
1
( &nu; 
1
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
−
</p>

<p>
&nu;
1
&nu;
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2

2
=
&nu;
1
&nu;
2
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
)
2
( &nu; 
1
</p>
<ul class="org-ul">
<li>&nu;}</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>1)</li>
</ul>
<p>
.
</p>
</div>
</div>
<div id="outline-container-orga893331" class="outline-4">
<h4 id="orga893331">5. Distribución normal.</h4>
<div class="outline-text-4" id="text-orga893331">
<p>
Sean &mu; &isin; \Re y &sigma; &gt; 0. Se dice que la variable aleatoria X tiene distribución normal de}
parámetros &mu;, &sigma;}
2
, y se denota X &sim; N}(&mu;, &sigma;
2
), si X es absolutamente continua con función
densidad de probabilidades
f ( x) =}
1
\sqrt{}
2{&pi;&sigma;}
e
−(x}−{&mu; ) 
2
/{2}&sigma;
2
.
El cálculo de E[X] y V(X) se reduce al caso X &sim; N}(0, 1). Para ello, basta observar que
Y &sim; N ( &mu;, &sigma;
2
) si y solo si Y = \sigmaX + &mu;, donde X &sim; N}(0, 1) y usar las identidades E[\sigmaX + &mu;] =
&sigma;{E[X]+ &mu; y V(\sigmaX + &mu;) = &sigma;
2
V(X). En lo que sigue suponemos que X &sim; N}(0, 1) y denotamos}
su densidad mediante
&varphi; ( x) =}
1
\sqrt{}
2 &pi; 
e
−x
2
/{2}
Es evidente que E[X] = 0. En consecuencia,
V(X) = E[X}
2
] =
Z
&infin;
−&infin;
x
2
&varphi; ( x ) dx
Observando que &varphi;}
′
(x) = −{x&varphi;}(x) e integrando por partes se obtiene,
V(X) =}
Z
&infin;
−&infin;
x ( x&varphi; ( x))dx = −} x&varphi; ( x ) 




&infin;
−&infin;
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
Z
&infin;
−&infin;
&varphi; ( x ) dx = 0 + 1}.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org81e256f" class="outline-2">
<h2 id="org81e256f">Bibliografía consultada</h2>
<div class="outline-text-2" id="text-org81e256f">
<p>
Para redactar estas notas se consultaron los siguientes libros:
</p>
<ol class="org-ol">
<li>Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to
Probability. M.I.T. Lecture Notes. (2000)</li>
<li>Bil lingsley, P.: Probability and Measure. John Wiley &amp; Sons, New
York. (1986)</li>
<li>Durrett, R. Elementary Probability for Applications. Cambridge
University Press, New York. (2009)</li>
<li>Feller, W.: An introduction to Probability Theory and Its
Applications. Vol. 1. John Wiley &amp; Sons, New York. (1957)</li>
<li>Kolmogorov, A. N.: The Theory of Probability. Mathematics. Its
Content, Methods, and Meaning. Vol 2. The M.I.T. Press,
Massachusetts. (1963) pp. 229-264.</li>
<li>Ross, S.: Introduction to Probability and Statistics for Engineers
and Scientists. Academic Press, San D iego. (2004)</li>
<li>Ross, S.: Introduction to Probability Models. Academic Press, San D
iego. (2007)</li>
<li>Soong, T. T.: Fundamentals of Probability and Statistics for
Engineers. John Wiley &amp; Sons Ltd. (2004)</li>
</ol>
</div>
</div>
</div>
<div id="postamble" class="status">
Last update: 2019-03-18 00:27
</div>
</body>
</html>
