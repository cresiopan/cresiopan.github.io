<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-08 Fri 15:45 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Vectores Aleatorios</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/res/nostyle"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous"/>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>
<body>
<div id="content">
<div id="outline-container-org0f61b65" class="outline-2">
<h2 id="org0f61b65">Vectores Aleatorios</h2>
<div class="outline-text-2" id="text-org0f61b65">
</div>
<div id="outline-container-org69cb093" class="outline-5">
<h5 id="org69cb093">Notación</h5>
<div class="outline-text-5" id="text-org69cb093">
<p>
Para simplificar la escritura usaremos las siguientes notaciones. Los
puntos del espacio n-dimensional \(\Re^n, n \geq 2\), se denotan en
negrita, \(x = (x_1, \dots , x_n)\). La desigualdad \(y \leq x\) significa
que \(y_i \leq x_i\) para todo \(i = 1, \dots , n\) y se puede interpretar
diciendo que y está al <i>sudoeste</i> de \(x\). El conjunto de todos los
puntos al <i>sudoeste</i> de \(x\) será denotado mediante \(S_x := \{y \in
\Re^n : y \leq x\}\). Finalmente, cualquiera sea el subconjunto de
índices \(J = \{i_1, \dots , i_m\} \subset \{1, \dots , n\}\)
denotaremos mediante \(x_J \in \Re^m\) al punto m-dimensional que se
obtiene de \(x\) quitándole todas las coordenadas que tengan índices
fuera de \(J\). Por ejemplo, si \(J = \{1, 2\}\), entonces \(x_J = (x_1,
x_2)\).
</p>
</div>
</div>
<div id="outline-container-org30e3fca" class="outline-5">
<h5 id="org30e3fca">Definición 1.1</h5>
<div class="outline-text-5" id="text-org30e3fca">
<p>
Un vector aleatorio sobre un espacio de probabilidad \((\Omega,
\mathcal{A}, \mathbb{P})\) es una función \(X = (X_1, \dots , X_n) :
\Omega \rightarrow \Re^n\) tal que para todo \(x \in \Re^n\)
</p>

<p>
\[\{X \in S_x\} = \{\omega \in \Omega : X(\omega) \leq x\} \in
\mathcal{A}\]
</p>
</div>
</div>
<div id="outline-container-org9b1dba5" class="outline-3">
<h3 id="org9b1dba5">Distribución conjunta</h3>
<div class="outline-text-3" id="text-org9b1dba5">
<p>
La función de distribución (conjunta) \(F_X: \Re^n \rightarrow [0, 1]\)
del vector aleatorio \(X\) se define por
</p>


\begin{equation}F_X (x) := \mathbb{P}(X \in S_x)\end{equation}
</div>
<div id="outline-container-org6e57947" class="outline-5">
<h5 id="org6e57947">Cálculo de probabilidades</h5>
<div class="outline-text-5" id="text-org6e57947">
<p>
La función de distribución conjunta resume toda la información
relevante sobre el comportamiento de las variables aleatorias \(X_1,
\dots , X_n\) . Para fijar ideas, consideremos el caso más simple: \(n =
2\). Si \(a_1< b_1\) y \(a_2< b_2\) vale que <sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>

\begin{equation}\mathbb{P}(a_1< X_1 \leq b_1, a_2< X_2 \leq b_2) = F(b_1, b_2) − F (a_1, b_2) − F (b_1, a_2) + F (a_1, a_2)\end{equation}

<p>
La identidad (2) permite calcular la probabilidad de observar al vector \((X_1,
X_2)\) en el rectángulo \((a_1, b_1] \times (a_2, b_2]\).  La fórmula n-dimensional
análoga de (2) es complicada y no es relevante para el desarrollo posterior. (Se
obtiene aplicando la fórmula de inclusión-exclusión para calcular la
probabilidad de la unión de eventos.)
</p>

<p>
Figura 1: Esquema de la demostración de la identidad (2). El
rectángulo \((a_1, b_1] \times (a_2, b_2]\) se puede representar en la
forma \(S_{(b_1,b_2)} \setminus \left(S_{(a_1,b_2)} \cup
S_{(b_1,a_2)}\right)\).
</p>
</div>
</div>
<div id="outline-container-org4caf1b6" class="outline-5">
<h5 id="org4caf1b6">Clasificación</h5>
<div class="outline-text-5" id="text-org4caf1b6">
</div>
<div id="outline-container-org7ba7264" class="outline-6">
<h6 id="org7ba7264">Vectores aleatorios discretos</h6>
<div class="outline-text-6" id="text-org7ba7264">
<p>
El vector aleatorio \(X\) se dice discreto cuando existe un conjunto
numerable \(A \subset \Re^n\) tal que \(\mathbb{P}(X \in A) = 1\). En tal caso, las
variables aleatorias \(X_1, \dots , X_n\) son discretas y la función \(p_X:
\Re^n \rightarrow [0, 1]\) definida por
</p>
\begin{equation}p_X(x) := \mathbb{P}(X = x)\end{equation}
<p>
se llama la función de probabilidad conjunta de \(X\). Su relación con
la función de distribución conjunta es la siguiente \[F_X(x) =
\displaystyle\sum_{y\in S_x} p_X(y)\]
</p>
</div>
</div>
<div id="outline-container-org27fc219" class="outline-6">
<h6 id="org27fc219">Vectores aleatorios continuos</h6>
<div class="outline-text-6" id="text-org27fc219">
<p>
El vector aleatorio \(X = (X_1, \dots , X_n)\) se dice continuo cuando
existe una función \(f_X: \Re^n \rightarrow \Re^+\), llamada densidad de
probabilidades conjunta de \(X_1, \dots , X_n\) tal que \[F_X (x) =
\int_{S_x} f_X (y) dy\] (Para evitar dificultades relacionadas con el
concepto de integración supondremos que las densidades son
seccionalmente continuas.)
</p>
</div>
</div>
<div id="outline-container-orgf14593c" class="outline-6">
<h6 id="orgf14593c">Vectores aleatorios mixtos</h6>
<div class="outline-text-6" id="text-orgf14593c">
<p>
El vector aleatorio \(X\) se dice mixto si no es continuo ni discreto.
</p>
</div>
</div>
<div id="outline-container-org8ec48e7" class="outline-6">
<h6 id="org8ec48e7">Cálculo de probabilidades</h6>
<div class="outline-text-6" id="text-org8ec48e7">
<p>
Dependiendo del caso, la función de probabilidad conjunta \(p_X (x)\), o la
densidad conjunta \(f_X(x)\), resume toda la información relevante sobre el
comportamiento del vector aleatorio \(X\). Más precisamente, para todo conjunto \(A
\subset \Re^n\) <i>suficienteqmente regular</i>, vale que
</p>

<p>
\[\mathbb{P}(X \in A) = \left\{\begin{array}{cc} %} \sum_{x \in A}
p_X(x)\text{ en el caso discreto,} \\ \int_{A} f_X(x)dx\text{ en el
caso continuo}.  \end{array}\right.\]
</p>
</div>
</div>
</div>
<div id="outline-container-org1e7b0b5" class="outline-5">
<h5 id="org1e7b0b5">Ejemplo 1.2</h5>
<div class="outline-text-5" id="text-org1e7b0b5">
<p>
Sea \((X, Y)\) un vector aleatorio continuo con densidad conjunta
\(f_{X,Y(x, y)}\). Si \(a < b\) y \(c < d\), entonces
</p>

\begin{equation}
\mathbb{P}(a < X \leq b, c < Y \leq d) = \int_a^b \int_c^d f_{X,Y} (x, y) dxdy\end{equation}
</div>
</div>

<div id="outline-container-org685ee96" class="outline-5">
<h5 id="org685ee96">Ejemplo 1.3 (Distribución uniforme)</h5>
<div class="outline-text-5" id="text-org685ee96">
<p>
Sea \(\Lambda \subset \Re^2\) una región acotada de área \(|\Lambda|\). Si
la densidad conjunta de un vector aleatorio continuo \((X, Y)\) es de la
forma
</p>


\begin{equation}f_{X,Y} (x, y) = \frac{1}{|\Lambda|}\textbf{1}\{(x, y) \in \Lambda\}\end{equation}

<p>
diremos que \((X, Y)\) está uniformemente distribuido sobre \(\Lambda\) y
escribiremos \((X, Y) \sim \mathcal{U}(\Lambda)\).  Sea \(B \subset
\Lambda\) una sub-región de \(\Lambda\) de área \(|B|\). La probabilidad de
que \((X, Y) \in B\) se calcula del siguiente modo
</p>


\begin{equation}\mathbb{P}((X, Y) \in B) = \iint_B f_{X,Y}(x, y)dx dy = \iint_B \frac{1}{|\Lambda|} dx dy = \frac{|B|}{|\Lambda|}\end{equation}

<p>
En otras palabras, la probabilidad de que \((X, Y) \in B\) es la
proporción del área de la región \(\Lambda\) contenida en la sub-región
\(B\).
</p>
</div>
</div>
<div id="outline-container-org5682a5e" class="outline-5">
<h5 id="org5682a5e">Ejemplo 1.4</h5>
<div class="outline-text-5" id="text-org5682a5e">
<p>
Sea \((X, Y)\) un vector aleatorio uniformemente distribuido sobre el
cuadrado \([0, 1] \times [0, 1]\). ¿Cuánto vale \(\mathbb{P}(XY > 1 /
2)\)?  Debido a que el cuadrado \([0, 1] \times [0, 1]\) tiene área 1 la
probabilidad requerida es el área de la región \(B = \{(x, y) \in [0,
1] \times [0, 1] : xy > 1 / 2\}\). Ahora bien,
</p>


\begin{equation}(x, y) \in B \iff y > 1/2x\end{equation}

<p>
y como \(y \leq 1\), la desigualdad del lado derecho de (7) sólo es
posible si \(1 / 2 \leq x\). Vale decir,
</p>

<p>
\[B = \{(x, y) : 1 / 2 \leq x \leq 1, 1 / 2x < y \leq 1\}\]
</p>

<p>
En consecuencia,
</p>

\begin{align*}
\mathbb{P}(XY > 1 / 2) &= |B| = \iint_B 1 dx dy = \int_{\frac{1}{2}}^{1}\left(\int_{\frac{1}{2}}^1 1 dy \right) dx =
\int_{\frac{1}{2}}^1 \left(1-\frac{1}{2x}\right)dx\\
&= \frac{1}{2} + \frac{1}{2} \log(\frac{1}{2}) = \frac{1}{2} (1 - \log 2)
\approx 01534\dots\end{align*}
</div>
</div>
</div>

<div id="outline-container-org4804cb2" class="outline-3">
<h3 id="org4804cb2">Distribuciones marginales</h3>
<div class="outline-text-3" id="text-org4804cb2">
<p>
Sea \(X = (X_1, \dots , X_n)\) un vector aleatorio n-dimensional y sea
\(F_X(x)\) su función de distribución conjunta. La coordenadas de \(X\)
son variables aleatorias. Cada variable individual \(X_i\) tiene su
correspondiente función de distribución
</p>


\begin{equation}F_{X_i}(x_i) = \mathbb{P}(X_i \leq x_i)\end{equation}

<p>
Para enfatizar la relación entre \(X_i\) y el vector \(X = (X_1, \dots ,
X_n)\) se dice que \(F_{X_i}(x_i)\) es la función de distribución
marginal de \(X_i\) o la i-ésima marginal de \(X\).
</p>
</div>
<div id="outline-container-org8671374" class="outline-5">
<h5 id="org8671374">Nota Bene</h5>
<div class="outline-text-5" id="text-org8671374">
<p>
Observar que, para cada \(i = 1, \dots , n\), la función de distribución
marginal de \(X_i, F_{X_i}(x_i)\), se obtiene de la función de
distribución conjunta \(F_X(x_1, \dots , x_n)\) fijando el valor de
\(x_i\) y haciendo \(x_j \rightarrow \infty\) para toda \(j \neq i\).
</p>
</div>
</div>
<div id="outline-container-orga9e9ea1" class="outline-4">
<h4 id="orga9e9ea1">Marginales discretas</h4>
<div class="outline-text-4" id="text-orga9e9ea1">
</div>
<div id="outline-container-org799c8f5" class="outline-5">
<h5 id="org799c8f5">Caso bidimensional</h5>
<div class="outline-text-5" id="text-org799c8f5">
<p>
Sea \((X, Y\)) un vector aleatorio discreto definido sobre un espacio de
probabilidad \((\Omega, A, P)\) con función de probabilidad conjunta
\(p_{X,Y}(x, y)\). Los números \(p_{X,Y}(x, y), (x, y) \in X(\Omega)
\times Y(\Omega) = \{(X(\omega), Y(\omega)) : \omega \in \Omega\}\), se
pueden representar en la forma de una matriz con las siguientes
propiedades
</p>


\begin{equation}
p_{X,Y}(x, y) \geq 0,\text{ y }
\displaystyle\sum_{x \in X(\Omega)}\displaystyle\sum_{y \in Y(\Omega)}p_{X,Y}(x, y) = 1
\end{equation}

<p>
Fijando \(x \in X(\Omega)\) y sumando las probabilidades que aparecen en
la fila \(x\) de la matriz \(p_{X,Y}(x, y)\) se obtiene
</p>


\begin{equation}\displaystyle\sum_{y \in Y(\Omega)} p_{X,Y}(x, y) = \displaystyle\sum_{y \in Y(\Omega)} \mathbb{P}(X = x, Y = y) = \mathbb{P}(X = x) = p_X(x)\end{equation}

<p>
Fijando \(y \in Y (\Omega)\) y sumando las probabilidades que aparecen
en la columna y de la matriz
</p>


\begin{equation}\displaystyle\sum_{x \in X(\Omega)} p_{X,Y}(x, y) = \displaystyle\sum_{x \in X(\Omega)} \mathbb{P}(X = x, Y = y) = \mathbb{P}(Y = y) = p_Y(y)\end{equation}

<p>
En otras palabras, sumando las probabilidades por filas obtenemos la
función de probabilidad marginal de la variable aleatoria \(X\) y
sumando las probabilidades por columnas obtenemos la función de
probabilidad marginal de la variable aleatoria \(Y\) . El adjetivo
<i>marginal</i> que reciben las funciones de probabilidad \(p_X(x)\) y
\(p_Y(y)\) refiere a la apariencia externa que adoptan (10) y (11) en
una tabla de doble entrada.
</p>
</div>
</div>
<div id="outline-container-org487057f" class="outline-5">
<h5 id="org487057f">Ejemplo 1.5</h5>
<div class="outline-text-5" id="text-org487057f">
<p>
En una urna hay 6 bolas rojas, 5 azules y 4 verdes. Se extraen
dos. Sean \(X\) la cantidad de bolas rojas extraídas e \(Y\) la cantidad
de azules.
</p>

<p>
Existen \(\binom{15}{2} = 105\) resultados posibles. La cantidad de
resultados con \(x\) rojas, \(y\) azules y \(2 − (x + y)\) verdes es
</p>

<p>
\[\binom{6}{x}\binom{5}{y}\binom{4}{2-(x+y)}\]
</p>

<p>
Usando esa fórmula y poniendo \(q = 1 / 105\) obtenemos
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x &setminus; y</th>
<th scope="col" class="org-left">0</th>
<th scope="col" class="org-left">1</th>
<th scope="col" class="org-right">2</th>
<th scope="col" class="org-left">p<sub>X</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-left">6q</td>
<td class="org-left">20q</td>
<td class="org-right">10q</td>
<td class="org-left">36q</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-left">24q</td>
<td class="org-left">30q</td>
<td class="org-right">0</td>
<td class="org-left">54q</td>
</tr>

<tr>
<td class="org-right">2</td>
<td class="org-left">15q</td>
<td class="org-left">0</td>
<td class="org-right">0</td>
<td class="org-left">15q</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-right">p<sub>Y</sub></td>
<td class="org-left">45q</td>
<td class="org-left">50q</td>
<td class="org-right">10q</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
Figura 2: Distribución conjunta de \((X, Y)\). En el margen derecho de
la tabla se encuentra la distribución marginal de \(X\) y en el margen
inferior, la marginal de \(Y\).
</p>
</div>
<div id="outline-container-org6eab8dc" class="outline-6">
<h6 id="org6eab8dc">Caso general</h6>
<div class="outline-text-6" id="text-org6eab8dc">
<p>
Para cada \(i = 1, \dots , n\), la función de probabilidad marginal de
\(X_i, p_{X_i}(x_i)\), se puede obtener fijando la variable \(x_i\) y
sumando la función de probabilidad conjunta \(p_X(x)\) respecto de las
demás variables
</p>

<p>
\[p_{X_i}(x_i) = \displaystyle\sum_{x_{\{i\}^c}}  p_X(x)\]
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd902c03" class="outline-4">
<h4 id="orgd902c03">Marginales continuas</h4>
<div class="outline-text-4" id="text-orgd902c03">
<p>
Sea \((X, Y)\) un vector aleatorio continuo con función densidad
conjunta \(f_{X,Y}(x, y)\). Las funciones de distribución marginales de
las variables individuales \(X\) e \(Y\) se obtienen de la distribución
conjunta haciendo lo siguiente
</p>


\begin{equation}F_X(x) = \mathbb{P}(X \leq x) = \displaystyle\lim_{y \rightarrow \infty} F_{X,Y}(x, y) = \int_{-\infty}^x \left(\int_{-\infty}^{\infty} f_{X,Y}(s,y) dy \right) ds\end{equation}


\begin{equation}F_Y(y) = \mathbb{P}(Y \leq y) = \displaystyle\lim_{x \rightarrow \infty} F_{X,Y}(x, y) = \int_{-\infty}^y \left(\int_{-\infty}^{\infty} f_{X,Y}(x,t) dx \right) dt\end{equation}

<p>
Aplicando en (12) y en (13) el Teorema Fundamental del Cálculo
Integral se obtiene que las funciones de distribución marginales
F<sub>X</sub>(x) y F<sub>Y</sub>(y) son derivables (salvo quizás en un conjunto
despreciable de puntos) y vale que
</p>


\begin{equation}f_X(x) = \frac{d}{dx} F_X(x) = \displaystyle\int_{-\infty}^{\infty}f (x,y)dy\end{equation}


\begin{equation}f_Y(y) = \frac{d}{dy} F_Y(y) = \displaystyle\int_{-\infty}^{\infty}f (x,y)dx\end{equation}

<p>
En consecuencia, las variables aleatorias \(X\) e \(Y\) son
individualmente (absolutamente) continuas con densidades <i>marginales</i>
\(f_X(x)\) y \(f_Y(y)\), respectivamente.
</p>
</div>
<div id="outline-container-org2d6b52e" class="outline-5">
<h5 id="org2d6b52e">Ejemplo 1.6 (Distribución uniforme)</h5>
<div class="outline-text-5" id="text-org2d6b52e">
<p>
Sea \(\Lambda \subset \Re^2\) una región del plano acotada, que para
simplificar supondremos convexa, y sea \((X, Y)\) un vector aleatorio
uniformemente distribuido sobre \(\Lambda\). La densidad marginal de \(X\)
en la abscisa \(x\) es igual al cociente entre el ancho de \(\Lambda\) en
\(x\) y el área de \(\Lambda\).
</p>
</div>
</div>
<div id="outline-container-org227e782" class="outline-5">
<h5 id="org227e782">Ejemplo 1.7 (Dardos)</h5>
<div class="outline-text-5" id="text-org227e782">
<p>
Consideramos un juego de dardos de blanco circular \(\Lambda\) de radio
1 centrado en el origen del plano: \(\Lambda = \{(x, y) \in \Re^2: x^2+
y^2 \leq 1\}\). Un tirador lanza un dardo al azar sobre \(\Lambda\) y se
clava en un punto de coordenadas \((X, Y)\). El punto \((X, Y)\) está
uniformemente distribuido sobre \(\Lambda\). Debido a que el área de
\(\Lambda\) es igual a \(\pi\), la densidad conjunta de \(X\) e \(Y\) es
</p>

<p>
\[f_{X,Y}(x, y) = \frac{1}{\pi} \textbf{1}\{x^2 + y^2 \leq 1\}\]
</p>

<p>
Figura 3: Para cada \(x \in [−1, 1]\) se observa que el ancho del círculo
en \(x\) es \(2\sqrt{1 − x^2}\).
</p>

<p>
Si se observa la Figura 3 es claro que la densidad marginal de \(X\) es
</p>

<p>
\[f_X(x) = \frac{2\sqrt{1 − x^2}}{\pi}\textbf{1}\{x \in [−1, 1]\}\]
</p>

<p>
y por razones de simetría la densidad marginal de Y debe ser \[f_Y (y)
= \frac{2\sqrt{1 − y^2}}{\pi}\textbf{1}\{y \in [−1, 1]\}\]
</p>
</div>
<div id="outline-container-org35441ff" class="outline-6">
<h6 id="org35441ff">Caso general</h6>
<div class="outline-text-6" id="text-org35441ff">
<p>
Para cada \(i = 1, \dots , n\), la densidad marginal de \(X_i, f_{X_i}
(x_i)\), se puede obtener fijando la variable \(x_i\) e integrando la
densidad conjunta \(f_X(x)\) respecto de las demás variables \[f_{X_i}
(x_i) = \int_{\Re^{n-1}}  f_X(x)dx_{\{i\}^c}\]
</p>
</div>
</div>
</div>
<div id="outline-container-org7b685a7" class="outline-5">
<h5 id="org7b685a7">Nota Bene: Conjuntas y marginales</h5>
<div class="outline-text-5" id="text-org7b685a7">
<p>
A veces, es necesario conocer la distribución de una sub-colección de
variables aleatorias. En el caso bidimensional este problema no se
manifiesta porque se reduce al cálculo de las marginales. Para cada
subconjunto de índices \(\Lambda \subset \{1, 2, \dots , n\}\) la
función de distribución conjunta de las variables \(X_i: i \in \Lambda,
F_{\Lambda(x_{\Lambda})}\), se obtiene fijando los valores de las
coordenadas \(x_i : i \in \Lambda\) y haciendo \(x_j \rightarrow \infty
\forall j \in \Lambda\).
</p>

<p>
En el caso discreto, la función de probabilidad conjunta de las
variables \(X_i: i \in \Lambda, p_{\Lambda(x_{\Lambda})}\), se obtiene
fijando la variables \(x_i: i \in \Lambda\) y sumando la función de
probabilidad conjunta \(p(x)\) respecto de las demás variables
</p>

<p>
\[p_{\Lambda(x_{\Lambda})} = \displaystyle\sum_{x_{\Lambda^c}}
p_X(x)\]
</p>

<p>
En el caso continuo, la densidad conjunta de las variables
\(X_{\Lambda}, f_{\Lambda(x_{\Lambda})}\), se obtiene fijando los
valores de las variables \(x_i: i \in \Lambda\) e integrando la densidad
conjunta \(f(x)\) respecto de las demás variables
</p>

<p>
\[f_{\Lambda} (x_{\Lambda}) = \int_{\Re^{n-m}} f_X(x) dx_{\Lambda^c}\]
</p>

<p>
donde \(m\) es la cantidad de índices contenidos en el conjunto
\(\Lambda\).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga4ad628" class="outline-3">
<h3 id="orga4ad628">Independencia</h3>
<div class="outline-text-3" id="text-orga4ad628">
<p>
Las variables \(X_1 , \dots , X_n\) son independientes si para cualquier
colección de conjuntos (medibles) \(A_1, \dots , A_n \subset \Re\), los
eventos \(\{X_1 \in A_1 \}, \dots , \{X_n \in A_n\}\) son
independientes.
</p>

<p>
Tomando conjuntos de la forma \(A_i = (−\infty, x_i]\) se deduce que la
independencia de \(X_ 1, \dots , X_n\) implica
</p>

\begin{equation}F_X(x) = P\left(\bigcap_{i=1}^n \{X_i < \leq x_i \} \right) =
\prod_{i=1}^n \mathbb{P}(X_i \leq x_i) = \prod_{i=1}^n F_{X_i} (x_i)\end{equation}

<p>
Dicho en palabras, la independencia de las variables implica que su
función de distribución conjunta se factoriza como el producto de
todas las marginales.
</p>

<p>
Recíprocamente, se puede demostrar que si para cada \(x = (x_1, \dots ,
x_n) \in \Re^n\) se verifica la ecuación (16), las variables aleatorias
\(X_1, \dots , X_n\) son independientes. (La demostración es técnica y
no viene al caso). Esta equivalencia reduce al mínimo las condiciones
que permiten caracterizar la independencia de variables aleatorias y
motivan la siguiente definición más simple.
</p>
</div>
<div id="outline-container-org7e8c5c7" class="outline-5">
<h5 id="org7e8c5c7">Definición 1.8 (Independencia de una cantidad finita de variables aleatorias)</h5>
<div class="outline-text-5" id="text-org7e8c5c7">
<p>
Diremos que las variables aleatorias \(X_1, \dots , X_n\) son
independientes si la ecuación (16) se verifica en todo \(x = (x_1,
\dots , x_n) \in \Re^n\).
</p>
</div>
</div>
<div id="outline-container-orgc9b100f" class="outline-5">
<h5 id="orgc9b100f">Definición 1.9 (Independencia)</h5>
<div class="outline-text-5" id="text-orgc9b100f">
<p>
Dada una familia de variables aleatorias \((X_i: i \in I)\) definidas sobre un
mismo espacio de probabilidad \((\Omega, A, P)\), diremos que sus variables son
(conjuntamente) independientes si para cualquier subconjunto finito de índices
\(J \subset I\) las variables \(X_i, i \in J\) son independientes.
</p>
</div>
</div>

<div id="outline-container-org7af88c8" class="outline-5">
<h5 id="org7af88c8">Nota Bene</h5>
<div class="outline-text-5" id="text-org7af88c8">
<p>
La independencia de las variables aleatorias \(X_1, \dots , X_n\) es equivalente a
la factorización de la distribución conjunta como producto de sus distribuciones
marginales.
</p>

<p>
Más aún, esta propiedad se manifiesta a nivel de la función de probabilidad,
\(p_X(x)\) o de la densidad conjunta, \(f_X (x)\), del vector aleatorio \(X = (X_1,
\dots , X_n)\), según sea el caso. Para ser más precisos, \(X_1, \dots , X_n\) son
independientes si y solo si
</p>

<p>
\[p_X(x) = \prod_{i=1}^n p_{X_i} (x_i) \text{ en el caso discreto},\]
</p>

<p>
\[f_X(x) = \prod_{i=1}^n f_{X_i} (x_i) \text{ en el caso continuo}.\]
</p>
</div>
</div>
<div id="outline-container-org016be07" class="outline-5">
<h5 id="org016be07">Ejemplo 1.10 (Números al azar)</h5>
<div class="outline-text-5" id="text-org016be07">
<p>
Se elige al azar un número \(U\) del intervalo \([0, 1)\). Sea \(U =
0.X_1X_2X_3\cdots\) el desarrollo decimal de \(U\). Mostraremos que los dígitos de
\(U\) son independientes entre sí y que cada uno de ellos se distribuye
uniformemente sobre el conjunto \(\{0, 1, \dots , 9\}\).  El problema se reduce a
mostrar que para cada \(n \geq 2\) las variables aleatorias \(X_1, X_2, \dots ,
X_n\) son independientes entre sí y que para cada \(k \geq 1\) y todo \(x_k \in \{0,
1, \dots , 9\}, \mathbb{P}(X_k = x_k) = 1 / 10\).
</p>

<p>
Primero observamos que para cada \(n \geq 1\) y para todo \((x_1, \dots , x_n) \in
\{0, 1, \dots , 9\}^n\) vale que \[\bigcap_{i=1}^n \{X_i = x_i\} \iff U \in
\left[ \displaystyle\sum_{i=1}^n \frac{x_i}{10^i}, \displaystyle\sum_{i=1}^n
\frac{x_i}{10^i} + \frac{1}{10^n} \right)\] En consecuencia,
</p>


\begin{equation}P\left(\bigcap_{i=1}^n \{X_i = x_i\} \right) = \frac{1}{10^n}\end{equation}

<p>
Para calcular las marginales de los dígitos observamos que para cada \(x_k \in
\{0, 1, \dots , 9\}\) vale que
</p>

<p>
\[\{X_k = x_k\} = \bigcup_(x_1, \dots, x_{k−1}) \in \{0, 1, \dots, 9\}^{k−1}
\left[ \left(\bigcap_{i=1}^{k-1} \{X_i = x_i\} \cap \{X_k = x_k\} \right)
\right]\]
</p>

<p>
De acuerdo con (17) cada uno de los \(10^{k−1}\) eventos que aparecen en la unión
del lado derecho de la igualdad tiene probabilidad \(1 / 10^k\) y como son
disjuntos dos a dos obtenemos que
</p>


\begin{equation}\mathbb{P}(X_k = x_k) = 10^{k−1} \frac{1}{10^k} = \frac{1}{10}\end{equation}

<p>
De (17) y (18) se deduce que para todo \((x_1 , \dots , x_n) \in \{0, 1, \dots ,
9\}^n\) vale que
</p>

<p>
\[P\left(\bigcap_{i=1}^{n} \{X_i = x_i\} \right) = \prod_{i=1}^n \mathbb{P}(X_i
= x_i)\]
</p>

<p>
Por lo tanto, las variables aleatorias \(X_1, X2, \dots , X_n\) son independientes
entre sí y cada una de ellas se distribuye uniformemente sobre el conjunto \(\{0,
1, \dots , 9\}\).
</p>
</div>
</div>
<div id="outline-container-org30c2bc3" class="outline-4">
<h4 id="org30c2bc3">Caso bidimensional discreto</h4>
<div class="outline-text-4" id="text-org30c2bc3">
<p>
Sea \((X, Y)\) un vector aleatorio discreto con función de probabilidad
conjunta \(p_{X,Y} (x, y)\) y marginales \(p_X(x)\) y \(p_Y(y)\). Las
variables \(X, Y\) son independientes si para cada pareja de valores \(x
\in X(\Omega), y \in Y (\Omega)\) vale que
</p>
\begin{equation}p_{X,Y}(x, y) = p_X(x) p_Y(y)\end{equation}
<p>
En otras palabras, la matriz \(p_{X,Y}(x, y)\) es la tabla de
multiplicar de las marginales \(p_X(x)\) y \(p_Y(y)\).
</p>
</div>
<div id="outline-container-org5f834e3" class="outline-5">
<h5 id="org5f834e3">Ejemplo 1.11</h5>
<div class="outline-text-5" id="text-org5f834e3">
<p>
Se arrojan dos dados equilibrados y se observan las variables
aleatorias \(X\) e \(Y\) definidas por \(X\) = <i>el resultado del primer
dado</i> e \(Y\) = <i>el mayor de los dos resultados</i>.
</p>

<p>
El espacio de muestral asociado al experimento se puede representar en
la forma \(\Omega = \{1, 2, \dots , 6\}^2\) , cada punto \((i, j) \in
\Omega\) indica que el resultado del primer dado es \(i\) y el resultado
del segundo es \(j\). Para reﬂejar que arrojamos dos dados equilibrados,
todos los puntos de \(\Omega\) serán equiprobables, i.e., para cada
\((i, j) \in \Omega\) se tiene \(\mathbb{P}(i, j) = 1 / 36\). Formalmente las
variables aleatorias \(X\) e \(Y\) están definidas por
</p>


\begin{equation}X(i,j) := i, Y(i,j) := \max\{i, j\}\end{equation}
</div>
</div>

<div id="outline-container-org919b33b" class="outline-5">
<h5 id="org919b33b">Distribución conjunta y distribuciones marginales de X e Y</h5>
<div class="outline-text-5" id="text-org919b33b">
<p>
En primer lugar vamos a representar el espacio muestral \(\Omega\) en la forma de
una matriz para poder observar más claramente los resultados posibles
</p>

\begin{Bmatrix}
(1, 1) & (1, 2) & (1, 3) & (1, 4) & (1, 5) & (1, 6)\\
(2, 1) & (2, 2) & (2, 3) & (2, 4) & (2, 5) & (2, 6)\\
(3, 1) & (3, 2) & (3, 3) & (3, 4) & (3, 5) & (3, 6)\\
(4, 1) & (4, 2) & (4, 3) & (4, 4) & (4, 5) & (4, 6)\\
(5, 1) & (5, 2) & (5, 3) & (5, 4) & (5, 5) & (5, 6)\\
(6, 1) & (6, 2) & (6, 3) & (6, 4) & (6, 5) & (6, 6)
\end{Bmatrix}

<p>
Figura 4: Resultados posibles del experimento aleatorio que consiste en arrojar
dos dados.
</p>

<p>
Debido a que \(Y \geq X\), tenemos que \(p_{X,Y}(x, y) = 0\) para todo \(1 \leq y < x
\leq 6\). En los otros casos, i.e., \(1 \leq x \leq y \leq 6\), para calcular el
valor de \(p_{X,Y}(x, y)\) hay que contar la cantidad de elementos de la fila \(x\),
de la matriz representada en la Figura 4, que contengan alguna coordenada igual
a \(y\). Multiplicando por \(q = \frac{1}{36}\) la cantidad encontrada se obtiene
\(p_{X,Y}(x, y)\).
</p>

<p>
En la figura 5 representamos la distribución conjunta \(p_{X,Y}(x, y)\) y las
distribuciones marginales \(p_X\) y \(p_Y\).
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x &setminus; y</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">2</th>
<th scope="col" class="org-right">3</th>
<th scope="col" class="org-right">4</th>
<th scope="col" class="org-left">5</th>
<th scope="col" class="org-left">6</th>
<th scope="col" class="org-left">p<sub>X</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">q</td>
<td class="org-right">q</td>
<td class="org-right">q</td>
<td class="org-right">q</td>
<td class="org-left">q</td>
<td class="org-left">q</td>
<td class="org-left">6q</td>
</tr>

<tr>
<td class="org-right">2</td>
<td class="org-right">0</td>
<td class="org-right">2q</td>
<td class="org-right">q</td>
<td class="org-right">q</td>
<td class="org-left">q</td>
<td class="org-left">q</td>
<td class="org-left">6q</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">3q</td>
<td class="org-right">q</td>
<td class="org-left">q</td>
<td class="org-left">q</td>
<td class="org-left">6q</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">4</td>
<td class="org-left">q</td>
<td class="org-left">q</td>
<td class="org-left">6q</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-left">5q</td>
<td class="org-left">q</td>
<td class="org-left">6q</td>
</tr>

<tr>
<td class="org-right">6</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-left">0</td>
<td class="org-left">6q</td>
<td class="org-left">6q</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-right">p<sub>Y</sub></td>
<td class="org-right">q</td>
<td class="org-right">3q</td>
<td class="org-right">5q</td>
<td class="org-right">7q</td>
<td class="org-left">9q</td>
<td class="org-left">11q</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
Figura 5: Distribución conjunta de \((X, Y)\). En el margen derecho se encuentra
la distribución marginal de \(X\) y en el margen inferior, la marginal de
\(Y\). Para abreviar hemos puesto \(q = \frac{1}{36}\).
</p>

<p>
De acuerdo con los resultados expuestos en la tabla que aparece en la Figura 5,
las distribuciones marginales son
</p>

<p>
\[p_X(x) = \frac{1}{6} , p_Y(y) = \frac{2y-1}{36}\]
</p>

<p>
Debido a que no se trata de una tabla de multiplicar las variables \(X\) e \(Y\) no
son independientes. Lo que, por otra parte, constituye una obviedad.
</p>
</div>
</div>
<div id="outline-container-org65de6bc" class="outline-5">
<h5 id="org65de6bc">Criterio para detectar dependencia</h5>
<div class="outline-text-5" id="text-org65de6bc">
<p>
Cuando en la tabla de la distribución conjunta de dos variables hay un
0 ubicado en la intersección de una fila y una columna de sumas
positivas, las variables no pueden ser independientes. (Las variables
del Ejemplo 1.5 no son independientes.)
</p>
</div>
</div>
</div>
<div id="outline-container-orgff83ffc" class="outline-4">
<h4 id="orgff83ffc">Caso bidimensional continuo</h4>
<div class="outline-text-4" id="text-orgff83ffc">
<p>
Sean \(X\) e \(Y\) variables aleatorias con densidad conjunta \(f_{X,Y} (x,
y)\) y marginales \(f_X(x)\) y \(f_Y(y)\). Las variables aleatorias \(X\) e
\(Y\) son independientes si y solo si
</p>


\begin{equation}f_{X,Y}(x, y) = f_X(x) f_Y(y)\end{equation}

<p>
En otras palabras, \(X\) e \(Y\) son independientes si y solo si su
densidad conjunta se factoriza como el producto de las marginales.
</p>
</div>
<div id="outline-container-orge6941b1" class="outline-5">
<h5 id="orge6941b1">Criterios para detectar (in)dependencia</h5>
<div class="outline-text-5" id="text-orge6941b1">
<ol class="org-ol">
<li>La independencia de \(X\) e \(Y\) equivale a la existencia de dos funciones
\(f_1(x)\) y \(f_2(y)\) tales que \(f_{X,Y}(x, y) = f_1(x) f_2(y)\). Por lo tanto,
para verificar independencia basta comprobar que la densidad conjunta se
puede factorizar como alguna función de \(x\) por alguna función de \(y\), siendo
innecesario verificar que se trata de las densidades marginales. (Ejercicio)</li>
<li>La factorización (21) implica que, si \(X\) e \(Y\) son independientes, el
recinto del plano \[Sop \left(f_{X,Y}\right) := \left\{(x, y) \in \Re^2:
   f_{X,Y}(x, y) > 0\right\}\] llamado el soporte de la densidad conjunta
\(f_{X,Y}\), debe coincidir con el producto cartesiano de los soportes de sus
densidades marginales: \[Sop(f_X) \times Sop(f_Y) = \{x \in \Re : f_X(x) > 0
   \} \times \{y \in \Re : f_Y(y) > 0\}\] Por ejemplo, si el soporte de la
densidad conjunta es conexo y no es un rectángulo las variables \(X\) e \(Y\) no
pueden ser independientes. (Ver el Ejemplo 1.7.)</li>
</ol>
</div>
</div>
<div id="outline-container-org8eecf50" class="outline-5">
<h5 id="org8eecf50">Ejemplo 1.12</h5>
<div class="outline-text-5" id="text-org8eecf50">
<p>
Sean \(X\) e \(Y\) variables aleatorias independientes con distribución uniforme
sobre el intervalo \((0, L)\). Una vara de longitud \(L\) metros se quiebra en dos
puntos cuyas distancias a una de sus puntas son \(X\) e \(Y\) metros. Calcular la
probabilidad de que las tres piezas se puedan usar para construir un triángulo.
</p>

<p>
Primero designamos mediante \(L_1, L_2 \text{ y } L_3\) a las longitudes de las
tres piezas. Las tres piezas se pueden usar para construir un triángulo si y
solamente si se satisfacen las desigualdades triangulares
</p>

\begin{equation}
L_1 + L_2 > L_3 , L_1 + L_3 > L_2 \text{ y } L_2 + L_3 > L_1
\end{equation}

<p>
Vamos a distinguir dos casos: el caso en que \(X \leq Y\) y el caso en que \(Y <
X\). En el primer caso, \(X \leq Y\) , tenemos que \(L_1 = X, L_2 = Y − X\) y \(L_3 =
L − Y\) y las desigualdades triangulares (22) son equivalentes a las siguientes
</p>

\begin{equation}Y > L/2, X + L/2 > Y y L/2 > X\end{equation}

<p>
En el segundo caso, \(Y < X\), tenemos que \(L_1 = Y , L_2 = X − Y\) y \(L_3= L − X\)
y las desigualdades triangulares (22) son equivalentes a las siguientes
</p>


\begin{equation}X > L/2, Y > X − L/2 \text{ y } L/2 > Y\end{equation}

<p>
Por lo tanto, las tres piezas se pueden usar para construir un triángulo si y
solamente si \((X, Y) \in B\), donde
</p>

\begin{align*}
B = & \{(x, y) \in (0, L) \times (0, L) : 0 < x < L/2, L/2 < y < x + L/2\} \cup \\
& \{ (x, y) \in (0, L) \times (0, L) : L/2 < x < L, x − L/2 < y < L/2\}
\end{align*}

<p>
Figura 6: La región sombreada representa al conjunto \(B\) que es la unión de dos
triángulos disjuntos cada uno de área \(L^2/8\).  La hipótesis de que \(X\) e \(Y\)
son independientes con distribución uniforme sobre el intervalo \((0, L)\)
significa que \((X, Y) \sim \mathcal{U}(\Lambda)\), donde \(\Lambda\) es el cuadrado
de lado \((0, L)\)
</p>

<p>
\[f_{X,Y}(x, y) = f_X(x) f_Y(y) = \left(\frac{1}{L} \textbf{1}\{0 < x < L\}
\right) \left(\frac{1}{L} \textbf{1}\{0 < y < L\} \right) = \frac{1}{L^2}
\textbf{1}\{(x, y) \in \Lambda\}\]
</p>

<p>
De (6) se deduce que
</p>


\begin{equation}\mathbb{P}((X, Y) \in B) = \frac{|B|}{|\Lambda|} = \frac{(2 / 8)L^2}{L^2} = \frac{1}{4}\end{equation}
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb246ff5" class="outline-2">
<h2 id="orgb246ff5">Bibliografía consultada</h2>
<div class="outline-text-2" id="text-orgb246ff5">
<p>
Para redactar estas notas se consultaron los siguientes libros:
</p>
<ol class="org-ol">
<li>Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to
Probability. M.I.T. Lecture Notes. (2000)</li>
<li>Feller, W.: An introduction to Probability Theory and Its
Applications. Vol. 1. John Wiley &amp; Sons, New York. (1968)</li>
<li>Feller, W.: An introduction to Probability Theory and Its
Applications. Vol. 2. John Wiley &amp; Sons, New York. (1971)</li>
<li>Ross, S.: Introduction to Probability Models. Academic Press, San
Diego. (2007)</li>
</ol>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Ver la Figura 1.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
Last update: 2019-11-08 15:45
</div>
</body>
</html>
