<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-03-17 Sun 22:52 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Espacios de Probabilidad</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/res/org.css"/>

<script type="text/javascript" src="/style/org-info.js">
/**
 *
 * @source: /style/org-info.js
 *
 * @licstart  The following is the entire license notice for the
 *  JavaScript code in /style/org-info.js.
 *
 * Copyright (C) 2012-2018 Free Software Foundation, Inc.
 *
 *
 * The JavaScript code in this tag is free software: you can
 * redistribute it and/or modify it under the terms of the GNU
 * General Public License (GNU GPL) as published by the Free Software
 * Foundation, either version 3 of the License, or (at your option)
 * any later version.  The code is distributed WITHOUT ANY WARRANTY;
 * without even the implied warranty of MERCHANTABILITY or FITNESS
 * FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.
 *
 * As additional permission under GNU GPL version 3 section 7, you
 * may distribute non-source (e.g., minimized or compacted) forms of
 * that code without the copy of the GNU GPL normally required by
 * section 4, provided you include this license notice and a URL
 * through which recipients can access the Corresponding Source.
 *
 * @licend  The above is the entire license notice
 * for the JavaScript code in /style/org-info.js.
 *
 */
</script>

<script type="text/javascript">

/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/

<!--/*--><![CDATA[/*><!--*/
org_html_manager.set("TOC_DEPTH", "2");
org_html_manager.set("LINK_HOME", "0");
org_html_manager.set("LINK_UP", "0");
org_html_manager.set("LOCAL_TOC", "0");
org_html_manager.set("VIEW_BUTTONS", "0");
org_html_manager.set("MOUSE_HINT", "underline");
org_html_manager.set("FIXED_TOC", "0");
org_html_manager.set("TOC", "1");
org_html_manager.set("VIEW", "showall");
org_html_manager.setup();  // activate after the parameters are set
/*]]>*///-->
</script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "left",
        displayIndent: "0em",

        "HTML-CSS": { scale: %SCALE,
                        linebreaks: { automatic: "%LINEBREAKS" },
                        webFont: "%FONT"
                       },
        SVG: {scale: %SCALE,
              linebreaks: { automatic: "%LINEBREAKS" },
              font: "%FONT"},
        NativeMML: {scale: %SCALE},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "%MULTLINEWIDTH",
               TagSide: "right",
               TagIndent: "%TAGINDENT"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Espacios de Probabilidad</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org67e0d03">Teoría general</a>
<ul>
<li><a href="#org7186efc">Los axiomas de Kolmogorov</a>
<ul>
<li>
<ul>
<li><a href="#org6ea32b5">Definición 1.1</a></li>
<li><a href="#org0e9c8e8">Definición 1.2</a></li>
<li><a href="#org245c6f0">Definición 1.3</a></li>
<li><a href="#org997d48d">Nota Bene (Consistencia)</a></li>
<li><a href="#org0662a1f">Construcción de espacios de probabilidad finitos</a></li>
<li><a href="#orgd0b7fb0">Ejemplo 1.4 (Lanzar una moneda equilibrada)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org2e09000">Relación con los datos experimentales</a>
<ul>
<li>
<ul>
<li><a href="#orgdb740eb">Ejemplo 1.5 (Dos monedas)</a></li>
<li><a href="#org5c68050">Deducción empírica de los axiomas I, II, III.</a></li>
<li><a href="#org1cc6ff0">Nota Bene 1</a></li>
<li><a href="#org772b351">Ejemplo 1.6.</a></li>
<li><a href="#orge6ab101">Nota Bene 2</a></li>
<li><a href="#org0ccd14f">Nota Bene 3</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgaa42b98">Corolarios inmediatos de los axiomas</a>
<ul>
<li>
<ul>
<li><a href="#org3a7cf43">Teorema de aditividad</a></li>
<li><a href="#org2cb0f82">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1a5061f">Sobre el axioma de continuidad</a>
<ul>
<li>
<ul>
<li><a href="#orgc59200c">Nota Bene 1</a></li>
<li><a href="#orgdc245b3">Nota Bene 2</a></li>
<li><a href="#orgc40bf24">Ejemplo 1.7</a></li>
<li><a href="#orgf496613">Teorema 1.8</a></li>
<li><a href="#org4fae471">Demostración</a></li>
<li><a href="#org38618c8">Ejemplo 1.9 (Números aleatorios)</a></li>
<li><a href="#org8ad0539">Ejemplo 1.10 (Ternario de Cantor)</a></li>
<li><a href="#org13c20f6">Teorema 1.11 (&sigma;-aditividad)</a></li>
<li><a href="#orgd083574">Demostración</a></li>
<li><a href="#org27fd2e1">Corolario 1.12 (Teorema de cubrimiento)</a></li>
<li><a href="#orge9517d2">Demostración</a></li>
<li><a href="#orgfd85b27">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org83ed43a">&sigma;-álgebras y teorema de extensión</a>
<ul>
<li>
<ul>
<li><a href="#org548751b">Nota Bene</a></li>
<li><a href="#orgc723320">Lema 1.13 (&sigma;-álgebra generada)</a></li>
<li><a href="#org056d42d">Teorema 1.14 (Extensión)</a></li>
<li><a href="#org4d4e4f5">Esbozo de la demostración</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org374e805">Simulación de experimentos aleatorios con espacio muestral finito</a>
<ul>
<li><a href="#orge210423">Números aleatorios</a>
<ul>
<li>
<ul>
<li><a href="#org945e6b2">Cómo usar los números aleatorios</a></li>
<li><a href="#org02afec7">Nota Bene</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge062b75">Simulación de experimentos aleatorios</a>
<ul>
<li>
<ul>
<li><a href="#org55f77a9">Nota Bene</a></li>
<li><a href="#orgc10d824">Ejemplo 2.1 (Lanzar un dado equilibrado)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgeb26ab2">Estimación de probabilidades</a>
<ul>
<li>
<ul>
<li><a href="#org877f71e">Ejemplo 2.2</a></li>
<li><a href="#org00d6426">Nota Bene</a></li>
<li><a href="#orgc00ca41">Ejemplo 2.3 (Paradoja de De Mere)</a></li>
<li><a href="#orgc38f052">Conclusión.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org15e4c31">Elementos de Análisis Combinatorio</a>
<ul>
<li><a href="#orga132051">Regla del Producto</a>
<ul>
<li>
<ul>
<li><a href="#orgf63af4d">Demostración</a></li>
<li><a href="#org21eb5b5">Teorema 3.1 (Regla del producto)</a></li>
<li><a href="#org49b5dc0">Demostración</a></li>
<li><a href="#orgccee81f">Nota Bene</a></li>
<li><a href="#org1ffd84b">Ejemplo 3.2 (Ubicar r bolas en n urnas)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge87e54b">Muestras ordenadas</a>
<ul>
<li>
<ul>
<li><a href="#orgdcdf3aa">Teorema 3.3</a></li>
<li><a href="#orge37afd7">Ejemplo 3.4</a></li>
<li><a href="#org17e6b0a">Ejemplo 3.5</a></li>
<li><a href="#orgde1d9a4">Corolario 3.6</a></li>
<li><a href="#orgff68baf">Observación 3.7</a></li>
<li><a href="#org398c0fd">Nota Bene sobre muestreo aleatorio</a></li>
<li><a href="#org2f1001d"><span class="todo TODO">TODO</span> Ejemplos</a></li>
<li><a href="#org2eb3279">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbf59df9">Subpoblaciones</a>
<ul>
<li>
<ul>
<li><a href="#org7339520">Teorema 3.8.</a></li>
<li><a href="#orgdf85e94">Ejemplo 3.9.</a></li>
<li><a href="#orgc58f581">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org42e0ee8">Particiones</a>
<ul>
<li>
<ul>
<li><a href="#orgf4b0649">Teorema 3.10. Sean r}</a></li>
<li><a href="#orgabcaec6">Demostración</a></li>
<li><a href="#org050b840">Ejemplo 3.11</a></li>
<li><a href="#org19c6ef7">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgca7f6db">Distribución Hipergeométrica</a>
<ul>
<li><a href="#org583e4c7">Control de calidad.</a>
<ul>
<li><a href="#org6e16ccf">Ejemplo 3.12.</a></li>
<li><a href="#org22c2e6e">Ejemplo 3.13.</a></li>
<li><a href="#org4d48f46">Ejemplo 3.14.</a></li>
</ul>
</li>
<li><a href="#orgca5ccd9">Estimación por captura y recaptura.</a>
<ul>
<li><a href="#org6ac3259">Ejemplo 3.15</a></li>
<li><a href="#orgadb8a03">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org53a9db5">Mecánica Estadística</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#orga02d72e">Ejemplo 4.1.</a></li>
<li><a href="#org733aa6a">Ejemplo 4.2.</a></li>
<li><a href="#org2fd0df9">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org013a0c0">Algunas distribuciones relacionadas con la estadística de Maxwell-Boltzmann</a>
<ul>
<li><a href="#org0daf81a">Cantidad de partículas por celda: la distribución binomial</a>
<ul>
<li><a href="#orgb718dd6">Demostración</a></li>
</ul>
</li>
<li><a href="#orgff028a8">Forma límite: la distribución de Poisson</a>
<ul>
<li><a href="#orgafc6955">Demostración</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb341e40">Algunas distribuciones relacionadas con la estadística de Bose-Einstein</a>
<ul>
<li><a href="#orga4bb6d6">Cantidad de partículas por celda</a>
<ul>
<li><a href="#org51ea020">Demostración</a></li>
</ul>
</li>
<li><a href="#org47b4783">Forma límite: la distribución de Geométrica</a>
<ul>
<li><a href="#org10f5789">Demostración</a></li>
<li><a href="#org788a3ff">Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org960da15">Tiempos de espera</a></li>
</ul>
</li>
<li><a href="#orged46e0a">Bibliografía consultada</a></li>
</ul>
</div>
</div>
<div id="outline-container-org67e0d03" class="outline-2">
<h2 id="org67e0d03">Teoría general</h2>
<div class="outline-text-2" id="text-org67e0d03">
</div>
<div id="outline-container-org7186efc" class="outline-3">
<h3 id="org7186efc">Los axiomas de Kolmogorov</h3>
<div class="outline-text-3" id="text-org7186efc">
<p>
Sean \(\Omega\) un conjunto no vacío cuyos elementos \(\omega\) serán
llamados <b>eventos elementales</b> y \(\mathcal{A}\) una familia de
subconjuntos de \(\Omega\) que serán llamados <b>eventos</b>.
</p>
</div>
<div id="outline-container-org6ea32b5" class="outline-5">
<h5 id="org6ea32b5">Definición 1.1</h5>
<div class="outline-text-5" id="text-org6ea32b5">
<p>
\(\mathcal{A}\) es un álgebra de eventos si contiene a \(\Omega\) y es
cerrada por complementos y uniones finitas<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>
</div>
</div>
<div id="outline-container-org0e9c8e8" class="outline-5">
<h5 id="org0e9c8e8">Definición 1.2</h5>
<div class="outline-text-5" id="text-org0e9c8e8">
<p>
Una medida de probabilidad P sobre \((\Omega, \mathcal{A})\) es una
función \(P: \mathcal{A} \rightarrow \Re\) que satisface los axiomas
siguientes:
</p>
<ol class="org-ol">
<li>Para cada \(A \in \mathcal{A}, \mathbb{P}(A) \geq 0\),</li>
<li>\(\mathbb{P}(\Omega) = 1\).</li>
<li>Aditividad. Si los eventos \(A\) y \(B\) no tienen elementos en común,
entonces \[\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\]</li>
<li>Axioma de continuidad. Para cada sucesión decreciente de eventos</li>
</ol>
\begin{equation}
A_1 \supset A_2 \supset \cdots \supset A_n \supset \cdots
\end{equation}
<p>
tal que \[\bigcap_{i=1}^{\infty} A_n = \emptyset\]
vale que \[\lim_{n \rightarrow \infty} \mathbb{P}(A_n) = 0\]
</p>
</div>
</div>
<div id="outline-container-org245c6f0" class="outline-5">
<h5 id="org245c6f0">Definición 1.3</h5>
<div class="outline-text-5" id="text-org245c6f0">
<p>
Un espacio de probabilidad es una terna \((\Omega, \mathcal{A},
\mathbb{P})\) formada por un conjunto no vacío \(\Omega\), llamado el
espacio muestral; un álgebra \(\mathcal{A}\) de subconjuntos de
\(\Omega\); llamados los <b>eventos aleatorios</b>; y una medida de
probabilidad \(\mathbb{P}\) definida sobre los eventos aleatorios.
</p>
</div>
</div>
<div id="outline-container-org997d48d" class="outline-5">
<h5 id="org997d48d">Nota Bene (Consistencia)</h5>
<div class="outline-text-5" id="text-org997d48d">
<p>
El sistema de axiomas I-IV es consistente. Esto se prueba mediante un
ejemplo. Sea \(\Omega\) un conjunto que consiste de un solo elemento y
sea \(\mathcal{A} = \{\emptyset, \Omega\}\) la familia de todos los
subconjuntos de \(\Omega\). \(\mathcal{A}\) es un álgebra y la función
\(\mathbb{P}: \mathcal{A} \rightarrow \Re\) definida por \(\mathbb{P}(\Omega) := 1\)
y \(\mathbb{P}(\emptyset) := 0\) es una medida de probabilidad.
</p>
</div>
</div>
<div id="outline-container-org0662a1f" class="outline-5">
<h5 id="org0662a1f">Construcción de espacios de probabilidad finitos</h5>
<div class="outline-text-5" id="text-org0662a1f">
<p>
Los espacios de probabilidad más simples se construyen de la siguiente
manera. Se considera un conjunto finito \(\Omega\) y una función \(p :
\Omega \rightarrow [0, 1]\) tal que \[\displaystyle\sum_{\omega \in
\Omega} p (\omega) = 1\]
La función \(p\) se llama función de probabilidad y los números
\(p(\omega)\), \(\omega \in \Omega\), se llaman las probabilidades de los
eventos elementales $&omega; &isin; \Omeg$a o simplemente las
probabilidades elementales.
El álgebra de eventos, \(\mathcal{A}\), se toma como el conjunto de
todos los subconjuntos de \(\Omega\) y para cada \(A \in \mathcal{A}\) se
define \[\mathbb{P}(A) := \displaystyle\sum_{\omega \in A} p (\omega)\] donde
la suma vacía se define como 0.
Todos los espacios de probabilidad finitos en los que A es la familia
de todos los subconjuntos de \(\Omega\) se construyen de esta manera.
</p>
</div>
</div>
<div id="outline-container-orgd0b7fb0" class="outline-5">
<h5 id="orgd0b7fb0">Ejemplo 1.4 (Lanzar una moneda equilibrada)</h5>
<div class="outline-text-5" id="text-orgd0b7fb0">
<p>
Se lanza una moneda. Los resultados posibles son cara o ceca y pueden
representarse mediante las letras H (head) y T (tail). Adoptando esa
representación el espacio muestral correspondiente es \[\Omega = \{H,
T \}\]
Decir que una moneda es equilibrada significa que la función de
probabilidad asigna igual probabilidad a los dos resultados posibles:
\[p ( H) = p ( T ) = 1/2\]
</p>
</div>
</div>
</div>
<div id="outline-container-org2e09000" class="outline-3">
<h3 id="org2e09000">Relación con los datos experimentales</h3>
<div class="outline-text-3" id="text-org2e09000">
<p>
En el mundo real de los experimentos la teoría de probabilidad se
aplica de la siguiente manera:
</p>
<ol class="org-ol">
<li>Consideramos un sistema de condiciones, \(S\), que se pueden repetir
cualquier cantidad de veces.</li>
<li>Estudiamos una familia determinada de eventos que pueden ocurrir
como resultado de realizar las condiciones \(S\). En los casos
individuales donde se realizan las condiciones \(S\), los eventos
ocurren, generalmente, de distintas maneras. En el conjunto
\(\Omega\) incluimos, a priori, todos los resultados que podrían
obtenerse al realizar las condiciones \(S\).</li>
<li>Si al realizar las condiciones S el resultado pertenece al conjunto
\(A\) (definido de alguna manera), diremos que ocurre el evento \(A\).</li>
</ol>
</div>
<div id="outline-container-orgdb740eb" class="outline-5">
<h5 id="orgdb740eb">Ejemplo 1.5 (Dos monedas)</h5>
<div class="outline-text-5" id="text-orgdb740eb">
<p>
Las condiciones \(S\) consisten en lanzar una moneda dos veces.  El
conjunto de los eventos mencionados en (2) resultan del hecho de que
en cada lanzamiento puede obtenerse una cara (H) o una ceca (T). Hay
cuatro resultados posibles (los eventos elementales), a saber: \(HH, HT
, TH, TT\). Si el evento \(A\) se define por la ocurrencia de una
repetición, entonces \(A\) consistirá en que suceda el primero o el
cuarto de los cuatro eventos elementales. Esto es, \(A = \{HH, TT
\}\). De la misma manera todo evento puede considerarse como un
conjunto de eventos elementales.
</p>
<ol class="org-ol">
<li>Bajo ciertas condiciones se puede suponer que, dado el sistema de
condiciones \(S\), un evento \(A\) que a veces ocurre y a veces no,
tiene asignado un número real \(\mathbb{P}(A)\) que tiene las siguientes
características:
<ul class="org-ul">
<li>Se puede estar prácticamente seguro de que si el sistema de
condiciones \(S\) se repite una gran cantidad de veces, \(n\),
entonces si \(n(A)\) es la cantidad de veces que ocurre el evento
\(A\), la proporción \(n(A)/n\) diferirá muy poco de \(\mathbb{P}(A)\).</li>
<li>Si \(\mathbb{P}(A)\) es muy pequeña, se puede estar prácticamente seguro de
que cuando se realicen las condiciones \(S\) solo una vez, el
evento \(A\) no ocurrirá.</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org5c68050" class="outline-5">
<h5 id="org5c68050">Deducción empírica de los axiomas I, II, III.</h5>
<div class="outline-text-5" id="text-org5c68050">
<p>
En general, se puede suponer que la familia \(A\) de los eventos
observados A, B, C, &hellip;$ que tienen probabilidades asignadas,
constituye un álgebra de eventos. Está claro que \(0 \leq n(A)/n \leq
1\) de modo que el axioma \(I\) es bastante natural. Para el evento
\(\Omega, n(\Omega)\) siempre es igual a n de modo que es natural
definir \(\mathbb{P}(\Omega) = 1\) (Axioma II). Si finalmente, \(A\) y \(B\) son
incompatibles (i.e., no tienen elementos en común), entonces \(n(A \cup
B) = n(A) + n(B)\) y de aquí resulta que \[\frac{n ( A \cup B ){ n} =
\frac{n ( A ){n} + \frac{n ( B ){n}\] Por lo tanto, es apropiado
postular que \(\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\) (Axioma III).
</p>
</div>
</div>
<div id="outline-container-org1cc6ff0" class="outline-5">
<h5 id="org1cc6ff0">Nota Bene 1</h5>
<div class="outline-text-5" id="text-org1cc6ff0">
<p>
La afirmación de que un evento \(A\) ocurre en las condiciones \(S\) con
una determinada probabilidad \(\mathbb{P}(A)\) equivale a decir que en una serie
suficientemente larga de experimentos (es decir, de realizaciones del
sistema de condiciones \(S\)), las frecuencias relativas \[\hat{p}_k (A)
:= \frac{n_k(A){n_k}\]
de ocurrencia del evento \(A\) (donde \(n_k\) es la cantidad de
experimentos realizados en la k-ésima serie y \(n_k(A)\) la cantidad de
ellos en los que ocurre \(A\)) son aproximadamente idénticas unas a
otras y están próximas a \(\mathbb{P}(A)\).
</p>
</div>
</div>
<div id="outline-container-org772b351" class="outline-5">
<h5 id="org772b351">Ejemplo 1.6.</h5>
<div class="outline-text-5" id="text-org772b351">
<p>
Las condiciones \(S\) consisten en lanzar una moneda (posiblemente cargada).
Podemos poner \(\Omega = \{H, T\}\) y \(A = \{\emptyset, \{H\, \{T\,
\Omega\}\), y las posibles medidas de probabilidad \(P : A \rightarrow
[0, 1]\) están dadas por \[\mathbb{P}(\emptyset) = 0, \mathbb{P}(H) = p, \mathbb{P}(T) = 1 − p,
\mathbb{P}(\Omega) = 1\], donde p es un número real fijo perteneciente al
intervalo [0, 1].
Si en 10 series, de 1000 lanzamientos cada una, se obtienen las
siguientes frecuencias relativas de ocurrencia del evento A = \{H\}
\[0.753; 0.757; 0.756; 0.750; 0.746; 0.758; 0.751; 0.748; 0.749;
0.746\], parece razonable asignarle a p el valor 0.75.
</p>
</div>
</div>
<div id="outline-container-orge6ab101" class="outline-5">
<h5 id="orge6ab101">Nota Bene 2</h5>
<div class="outline-text-5" id="text-orge6ab101">
<p>
Si cada una de dos afirmaciones diferentes es prácticamente segura,
entonces podemos decir que simultáneamente son ambas seguras, aunque
el grado de seguridad haya disminuido un poco. Si, en cambio, el
número de tales afirmaciones es muy grande, de la seguridad práctica
de cada una, no podemos deducir nada sobre la validez simultánea de
todos ellas. En consecuencia, del principio enunciado en (a) no se
deduce que en una cantidad muy grande de series de n experimentos cada
una, en cada uno de ellos la proporción \(n(A)/n\) diferirá sólo un poco
de \(\mathbb{P}(A)\).
En los casos más típicos de la teoría de probabilidades, la situación
es tal que en una larga serie de pruebas es posible obtener uno de los
dos valores extremos para la frecuencia \[\frac{n(A){n} = \frac{n}{n}
= 1 \text{ y } \frac{n(A){n} = \frac{0}{n} = 0\] Así, cualquiera sea el
número de ensayos \(n\), es imposible asegurar con absoluta certeza que
tendremos, por ejemplo, la desigualdad \[\left|\frac{n(A){n} -
\mathbb{P}(A)\right| < \frac{1}{10}\]
Por ejemplo, si el evento \(A\) es sacar un seis tirando un dado
equilibrado, entonces en \(n\) tiradas del dado la probabilidad de
obtener un seis en todas ellas es \((1 / 6)^n > 0\); en otras palabras,
con probabilidad \((1 / 6)^n\) tendremos una frecuencia relativa igual a
uno de sacar un seis en todas las tiradas ; y con probabilidad \((5 /
6)^n\) no saldrá ningún seis, es decir, la frecuencia relativa de sacar
seis será igual a cero.
</p>
</div>
</div>
<div id="outline-container-org0ccd14f" class="outline-5">
<h5 id="org0ccd14f">Nota Bene 3</h5>
<div class="outline-text-5" id="text-org0ccd14f">
<p>
De acuerdo con nuestros axiomas a un evento imposible (un conjunto
vacío) le corresponde la probabilidad \(\mathbb{P}(\emptyset) = 0\), pero la
recíproca no es cierta: \(\mathbb{P}(A) = 0\) no implica la imposibilidad de
\(A\). Cuando \(\mathbb{P}(A) = 0\), del principio (b) todo lo que podemos asegurar
es que cuando se realicen las condiciones \(S\) una sola vez, el evento
\(A\) será prácticamente imposible.
Sin embargo, esto no asegura de ningún modo que en una sucesión
suficientemente grande de experimentos el evento \(A\) no ocurrirá. Por
otra parte, del principio (a) solamente se puede deducir que cuando
\(\mathbb{P}(A) = 0\) y \(n\) es muy grande, la proporción \(n(A)/n\) debe ser muy
pequeña (por ejemplo, \(1/n\)).
</p>
</div>
</div>
</div>
<div id="outline-container-orgaa42b98" class="outline-3">
<h3 id="orgaa42b98">Corolarios inmediatos de los axiomas</h3>
<div class="outline-text-3" id="text-orgaa42b98">
<p>
De \(A \cup A^c = \Omega\) y los axiomas II y III se deduce que \[\mathbb{P}(A^c)
= 1 − \mathbb{P}(A)\]
En particular, debido a que \(\Omega^c = \emptyset\), tenemos que
\(\mathbb{P}(\emptyset) = 0\).
</p>
</div>
<div id="outline-container-org3a7cf43" class="outline-5">
<h5 id="org3a7cf43">Teorema de aditividad</h5>
<div class="outline-text-5" id="text-org3a7cf43">
<p>
Si los eventos \(A_1, A_2, \dots , A_n\) son disjuntos dos a dos,
entonces del axioma III se deduce la fórmula \[P\left(\bigcup_{i =
1}^n A_i \right) = \displaystyle\sum_{i = 1}^n \mathbb{P}(A_i)\]
</p>
</div>
</div>
<div id="outline-container-org2cb0f82" class="outline-5">
<h5 id="org2cb0f82">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org2cb0f82">
<ol class="org-ol">
<li>Sean \(A\) y \(B\) dos eventos. Mostrar que
<ul class="org-ul">
<li>Si \(A \subseteq B\), entonces \(\mathbb{P}(A) \leq \mathbb{P}(B)\). Más precisamente:
\(\mathbb{P}(B) = \mathbb{P}(A) + \mathbb{P}(B \setminus A)\). Sugerencia. Expresar el evento
\(B\) como la unión disjunta de los eventos \(A\) y \(B \setminus A\) y
usar el axioma III.</li>
<li>La probabilidad de que ocurra al menos uno de los eventos \(A\) o
\(B\) es \[\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) − \mathbb{P}(A \cap B ) \]
Sugerencia. La unión \(A \cup B\) de dos eventos puede expresarse
como la unión de dos eventos disjuntos: \(A \cup (B \ (A \cap
     B))\).</li>
</ul></li>
<li>Mostrar que para eventos A, B y C vale que \[\mathbb{P}(A \cup B \cup C) =
   \mathbb{P}(A) + \mathbb{P}(B) + \mathbb{P}(C) − \mathbb{P}(A \cap B) − \mathbb{P}(A \cap C) − \mathbb{P}(B \cap C) + \mathbb{P}(A
   \cap B \cap C)\]</li>
<li>Mostrar que para eventos \(A_1, A_2, \dots , A_n\) vale que \[P\left(
   \bigcup_{i=1}^n A_i \right) = \displaystyle\sum_i \mathbb{P}(A_i) −
   \displaystyle\sum_{i<j} \mathbb{P}(A_i \cap A_j) + \displaystyle\sum_{i<j<k}
   \mathbb{P}(A_i \cap A_j \cap A_k) − \cdots +(−1)^n \mathbb{P}(A_1 \cap A_2 \cap
   \cdots \cap A_n)\]</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org1a5061f" class="outline-3">
<h3 id="org1a5061f">Sobre el axioma de continuidad</h3>
<div class="outline-text-3" id="text-org1a5061f">
</div>
<div id="outline-container-orgc59200c" class="outline-5">
<h5 id="orgc59200c">Nota Bene 1</h5>
<div class="outline-text-5" id="text-orgc59200c">
<p>
Si la familia de eventos A es finita el axioma de continuidad IV se
deduce de los axiomas I-III. En tal caso, en la sucesión (1) solo hay
una cantidad finita de eventos diferentes. Si \(A_k\) es el menor de
ellos, entonces todos los conjuntos \(A_{k + m} , m \geq 1\) coinciden
con \(A_k\) . Tenemos que \(A_k = A_{k + m} = \cap_{n = 1}^{\infty} A_n =
\emptyset\) y \(\lim_{n \rightarrow \infty} \mathbb{P}(A_n) = \mathbb{P}(\emptyset) =
0\). Por lo tanto, todos los ejemplos de espacios de probabilidad
finitos satisfacen los axiomas I-IV.
</p>
</div>
</div>
<div id="outline-container-orgdc245b3" class="outline-5">
<h5 id="orgdc245b3">Nota Bene 2</h5>
<div class="outline-text-5" id="text-orgdc245b3">
<p>
Se puede probar que para espacios muestrales infinitos, el axioma de
continuidad IV es independiente de los axiomas I-III. Este axioma es
esencial solamente para espacios de probabilidad infinitos y es casi
imposible elucidar su significado empírico en la forma en que lo
hicimos con los axiomas I-III.
</p>
</div>
</div>
<div id="outline-container-orgc40bf24" class="outline-5">
<h5 id="orgc40bf24">Ejemplo 1.7</h5>
<div class="outline-text-5" id="text-orgc40bf24">
<p>
Sean \(\Omega = Q \cap [0, 1] = \{r_1, r_2, r_3, \dots \}\) y
\(\mathcal{A}_0\) la familia de los subconjuntos de \(\Omega\) de la forma
\([a, b], [a, b), (a, b]\) o \((a, b)\). La familia, \(A\) de todas las
uniones finitas de conjuntos disjuntos de \(\mathcal{A}_0\) es un
álgebra de eventos. La medida de probabilidad definida por \[\mathbb{P}(A) := b
− a, si A \in \mathcal{A}_0,\] \[\mathbb{P}(A) := \displaystyle\sum_{i=1}^k
\mathbb{P}(A_i) \text{ si } A = \bigcup_{i=1}^k A_i , \text{ para } A_i \in
\mathcal{A}_0 \text{ y } A_i \cap A_j = \emptyset\], satisface los
axiomas I-III pero no satisface el axioma de continuidad.
En efecto, para cada \(r \in \Omega, \{r\} \in \mathcal{A}\) y \(\mathbb{P}(\{r\)
= 0\). Los eventos \(A_n := \Omega \setminus \{r_1, \dots , r_n\}, n
\in N\), son decrecientes y \(\bigcap_{n=1}^\infty A_n = \emptyset\), sin
embargo \(\lim_{n \rightarrow \infty} \mathbb{P}(A_n ) = 1\), debido a que \(\mathbb{P}(A_n) =
1\) para todo \(n \geq 1\).
</p>
</div>
</div>
<div id="outline-container-orgf496613" class="outline-5">
<h5 id="orgf496613">Teorema 1.8</h5>
<div class="outline-text-5" id="text-orgf496613">
<ol class="org-ol">
<li>Si \(A_1 \supset A_2 \supset \cdots\) y \(A = \bigcap_{n=1}^\infty A_n\)
, entonces \(\mathbb{P}(A) = \lim_{n \rightarrow \infty} \mathbb{P}(A_n)\).</li>
<li>Si \(A_1 \subset A_2 \subset \cdots\) y \(A = \bigcup_{n=1}^\infty A_n\),
entonces \(\mathbb{P}(A) = \lim_{n \rightarrow \infty} \mathbb{P}(A_n)\).</li>
</ol>
</div>
</div>
<div id="outline-container-org4fae471" class="outline-5">
<h5 id="org4fae471">Demostración</h5>
<div class="outline-text-5" id="text-org4fae471">
<ol class="org-ol">
<li>Considerar la sucesión \(Bn = An \setminus A\). Observar que \(B_1
   \supset B_2 \supset \cdots\) y \(\bigcap_{n=1}^{\infty} B_n =
   \emptyset\). Por el axioma de continuidad se obtiene \(\lim_{n
   \rightarrow \infty} \mathbb{P}(B_n) = 0\). Como \(\mathbb{P}(B_n) = \mathbb{P}(A_n) − \mathbb{P}(A)\) se
deduce que \[\lim_{n \rightarrow \infty} \mathbb{P}(A_n) = \mathbb{P}(A)\]</li>
<li>Considerar la sucesión \(B_n = A_n^c\). Observar que \(B_1 \supset B_2
   \supset \cdots\) y \(\bigcap_{n=1}^{\infty} B_n = A^c\). Por el inciso
1 se obtiene \[\lim_{n \rightarrow \infty} \mathbb{P}(B_n) = \mathbb{P}(A^c) = 1 −
   \mathbb{P}(A)\]. Como \(\mathbb{P}(B_n) = 1 − \mathbb{P}(A_n)\) se deduce que \(\lim_{n
   \rightarrow \infty} \mathbb{P}(A_n) = \mathbb{P}(A)\).</li>
</ol>
</div>
</div>
<div id="outline-container-org38618c8" class="outline-5">
<h5 id="org38618c8">Ejemplo 1.9 (Números aleatorios)</h5>
<div class="outline-text-5" id="text-org38618c8">
<p>
Teóricamente, los números aleatorios son realizaciones independientes
del experimento conceptual que consiste en <i>"elegir al azar"</i> un
número \(U\) del intervalo \((0, 1]\). Aquí la expresión <i>"elegir al
azar"</i> significa que el número \(U\) tiene la distribución uniforme
sobre el intervalo \((0, 1]\), i.e., la probabilidad del evento \(U \in
(a, b]\) es igual a \(b − a\), para cualquier pareja de números reales
\(a\) y \(b\) tales que \(0 < a < b \leq 1\).
</p>
</div>
</div>
<div id="outline-container-org8ad0539" class="outline-5">
<h5 id="org8ad0539">Ejemplo 1.10 (Ternario de Cantor)</h5>
<div class="outline-text-5" id="text-org8ad0539">
<p>
Se elije al azar un número \(U\) del intervalo \((0, 1]\), ¿cuál es la
probabilidad de que el 1 no aparezca en el desarrollo en base 3 de
\(U\)?
Consideramos la representación en base 3 del número U: \[U =
\displaystyle\sum_{k \geq 1} \frac{a_k(U){3^k}\] donde \(a_k(U) \in
\{0, 1, 2\, k \geq 1\).
Lo que queremos calcular es la probabilidad del evento \(A = \{a_k(U)
\neq 1, \forall k \geq 1\}\). Primero observamos que \[A = \bigcap_{i =
1}^{\infty} A_n\] donde \(A_n = \{a_k(U) \neq 1, \forall 1 \leq k \leq
n\}\) y notamos que \(A_1 \supset A_2 \supset \cdots\). Usando el inciso
(a) del Teorema 1.8 tenemos que \(\mathbb{P}(A) = \lim_{n \rightarrow \infty}
\mathbb{P}(A_n)\). El problema se reduce a calcular la sucesión de
probabilidades \(\mathbb{P}(A_n)\) y su límite.
Geométricamente el evento \(A_1\) se obtiene eliminando el segmento \((1
/ 3, 2 / 3)\) del intervalo \((0, 1]\): \[A_1 = (0, 1 / 3] \cup [2 / 3,
1]\]
Para obtener \(A_2\) eliminamos los tercios centrales de los dos
intervalos que componen \(A_1\): \[A_2 = (0, 1 / 9] \cup [2 / 9, 3 / 9]
\cup [6 / 9, 7 / 9] \cup [8 / 9, 1]\]
Continuando de este modo obtenemos una caracterización geométrica de
los eventos \(A_n : A_n\) es la unión disjunta de \(2^n\) intervalos, cada
uno de longitud \(3^{−n}\). En consecuencia, \mathbb{P}(A<sub>n</sub>) = 2<sup>n</sup> \frac{1}{3^n}
= \left(\frac{2}{3}\right)<sup>2</sup> $ Por lo tanto, \(\mathbb{P}(A) =
\lim_{n\rightarrow\infty} (2 / 3) n = 0\).
</p>
</div>
</div>
<div id="outline-container-org13c20f6" class="outline-5">
<h5 id="org13c20f6">Teorema 1.11 (&sigma;-aditividad)</h5>
<div class="outline-text-5" id="text-org13c20f6">
<p>
Si \(A_1, A_2, \dots\) , es una sucesión de eventos disjuntos dos a dos
(i.e., \(A_i \cap A_j = \emptyset\) para todos los pares \(i, j\) tales
que \(i \neq j\)) y \(\bigcup_{n=1}^{\infty} A_n \in \mathcal{A}\),
entonces
</p>
\begin{equation}
P \left( \bigcup_{n=1}^{\infty} An \right) = \displaystyle\sum_{n=1}^{\infty} \mathbb{P}(An)
\end{equation}
</div>
</div>
<div id="outline-container-orgd083574" class="outline-5">
<h5 id="orgd083574">Demostración</h5>
<div class="outline-text-5" id="text-orgd083574">
<p>
La sucesión de eventos \(Rn := \bigcup_{m>n} Am , n \geq 1\), es decreciente y tal que
\(\bigcap_{n=1}^{\infty} Rn = \emptyset\). Por el axioma IV tenemos que
</p>
\begin{equation}\lim_{n \rightarrow \infty} \mathbb{P}(Rn) = 0\end{equation}
<p>
y por el teorema de aditividad tenemos que
</p>
\begin{equation} 
P \left( \bigcup{n=1}^{\infty} An \right) = \displaystyle\sum_{k=1}^n \mathbb{P}(Ak) + \mathbb{P}(Rn)
\end{equation}
<p>
De <a href="#org2ca75fe">1</a> y <a href="#orgd275165">1</a> se obtiene <a href="#org24a1ff1">1</a>.
</p>
</div>
</div>
<div id="outline-container-org27fd2e1" class="outline-5">
<h5 id="org27fd2e1">Corolario 1.12 (Teorema de cubrimiento)</h5>
<div class="outline-text-5" id="text-org27fd2e1">
<p>
Si \(B, A_1, A_2, \dots\) es una sucesión de eventos tal que \(A =
\bigcup_{n=1}^{\infty} An \in \mathcal{A}\) y \(B \subset A\), entonces
\[\mathbb{P}(B) \leq \displaystyle\sum_{n=1}^{\infty} \mathbb{P}(An)\]
</p>
</div>
</div>
<div id="outline-container-orge9517d2" class="outline-5">
<h5 id="orge9517d2">Demostración</h5>
<div class="outline-text-5" id="text-orge9517d2">
<p>
Una cuenta. Descomponemos B en una unión disjunta de eventos \[ B = B
\cap \left( \bigcup_{n=1}^{\infty} A_n \right) =
\bigcup_{n=1}^{\infty} \left( B \cap \left( A_n \setminus
\bigcup_{k=1}^{n-1(A_n \cap A_k) \right) \right)\] y aplicamos el
teorema de $&sigma;$-aditividad \[\mathbb{P}(B) = \displaystyle\sum_{n=1}^{
\infty} P \left( B \cap \left( An \setminus \bigcup_{k=1}^{n−1} (An
\cap Ak) \right)\right) \leq \sum_{n=1}^{\infty} \mathbb{P}(An)\]
</p>
</div>
</div>
<div id="outline-container-orgfd85b27" class="outline-5">
<h5 id="orgfd85b27">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-orgfd85b27">
<ol class="org-ol">
<li>Sean \(\Omega\) un conjunto no vacío y \(\mathcal{A}\) un álgebra de
eventos. Sea \(P : \mathcal{A} \rightarrow \Re\) una función tal que
<ol class="org-ol">
<li>Para cada \(A \in \mathcal{A}, \mathbb{P}(A) \geq 0\),</li>
<li>\(\mathbb{P}(\Omega) = 1\).</li>
<li>Si los eventos \(A\) y \(B\) no tienen elementos en común, entonces
\(\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\).</li>
<li>Si \((A_n)_{n \geq 1}\) es una sucesión de eventos disjuntos dos a
dos y \(\bigcup_{n=1}^{\infty}A_n \in \mathcal{A}\), entonces \[
      P\left(\bigcup_{n=1}^{\infty} An \right) = \sum_{n=1}^{\infty}
      \mathbb{P}(An)\]</li>
</ol></li>
</ol>
<p>
Mostrar que bajo esas condiciones la función \(P\) satisface el axioma
de continuidad.
</p>
</div>
</div>
</div>
<div id="outline-container-org83ed43a" class="outline-3">
<h3 id="org83ed43a">&sigma;-álgebras y teorema de extensión</h3>
<div class="outline-text-3" id="text-org83ed43a">
<p>
El álgebra \(\mathcal{A}\) se llama una $&sigma;$-álgebra, si toda unión
numerable \(\bigcup_{n=1}^{\infty} An\) de conjuntos \(A_1, A_2, \cdots \in
\mathcal{A}\), disjuntos dos a dos, también pertenece a \(\mathcal{A}\).
De la identidad \[\bigcup_{n=1}^{\infty} An = \bigcup_{n=1}^{\infty}
\left( An \setminus \bigcup_{k=1}^{n−1(An \cap Ak)\right)\] se deduce
que la $&sigma;$-álgebra también contiene todas las uniones numerables
de conjuntos \(A_1, A_2, \cdots \in \mathcal{A}\). De la identidad
\[\bigcap{n=1}^{\infty} An = \Omega \setminus \bigcup{n=1}^{\infty}
A_n^c\] lo mismo puede decirse de las intersecciones.
</p>
</div>
<div id="outline-container-org548751b" class="outline-5">
<h5 id="org548751b">Nota Bene</h5>
<div class="outline-text-5" id="text-org548751b">
<p>
Solamente cuando disponemos de una medida de probabilidad, \(P\),
definida sobre una $&sigma;$-álgebra, \(\mathcal{A}\), obtenemos libertad
de acción total, sin peligro de que ocurran eventos que no tienen
probabilidad.
</p>
</div>
</div>
<div id="outline-container-orgc723320" class="outline-5">
<h5 id="orgc723320">Lema 1.13 (&sigma;-álgebra generada)</h5>
<div class="outline-text-5" id="text-orgc723320">
<p>
Dada un álgebra \(\mathcal{A}\) existe la menor $&sigma;\(-álgebra,
\sigma(\mathcal{A})\), que la contiene, llamada la $&sigma;$-álgebra
generada por \(\mathcal{A}\).
</p>
</div>
</div>
<div id="outline-container-org056d42d" class="outline-5">
<h5 id="org056d42d">Teorema 1.14 (Extensión)</h5>
<div class="outline-text-5" id="text-org056d42d">
<p>
Dada una función de conjuntos, \(P\), no negativa y $&sigma;$-aditiva
definida sobre un álgebra \(\mathcal{A}\) se la puede extender a todos
los conjuntos de la $&sigma;$-álgebra generada por \(\mathcal{A},
\sigma(\mathcal{A})\), sin perder ninguna de sus propiedades (no
negatividad y $&sigma;$-aditividad) y esta extensión puede hacerse de
una sola manera.
</p>
</div>
</div>
<div id="outline-container-org4d4e4f5" class="outline-5">
<h5 id="org4d4e4f5">Esbozo de la demostración</h5>
<div class="outline-text-5" id="text-org4d4e4f5">
<p>
Para cada \(A \subset \Omega\) definimos \[P^*(A) := \inf_{A \subset
\cup_n An} \displaystyle\sum_n \mathbb{P}(An)\] donde el ínfimo se toma
respecto a todos los cubrimientos del conjunto \(A\) por colecciones
finitas o numerables de conjuntos \(An\) pertenecientes a
\(\mathcal{A}\). De acuerdo con el Teorema de cubrimiento \(P^*(A)\)
coincide con \(\mathbb{P}(A)\) para todo conjunto \(A \in \mathcal{A}\).  La
función \(P^*\) es no negativa y $&sigma;$-aditiva sobre
\(\sigma(\mathcal{A})\). La unicidad de la extensión se deduce de la
propiedad minimal de \(\sigma(\mathcal{A})\).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org374e805" class="outline-2">
<h2 id="org374e805">Simulación de experimentos aleatorios con espacio muestral finito</h2>
<div class="outline-text-2" id="text-org374e805">
</div>
<div id="outline-container-orge210423" class="outline-3">
<h3 id="orge210423">Números aleatorios</h3>
<div class="outline-text-3" id="text-orge210423">
<p>
Toda computadora tiene instalado un algoritmo para simular números
aleatorios que se pueden obtener mediante una instrucción del tipo
<i>"random"</i>. En el software Octave, por ejemplo, la sentencia rand
simula un número aleatorio y <i>rand(1, n)</i> simula un vector de \(n\)
números aleatorios. En algunas calculadoras (llamadas científicas) la
instrucción Rand permite simular números aleatorios de tres
dígitos. En algunos libros de texto se pueden encontrar tablas de
números aleatorios (p. ej., Meyer, P. L.: Introductory Probability and
Statistical Applications. Addison-Wesley, Massachusetts. (1972))
</p>
</div>
<div id="outline-container-org945e6b2" class="outline-5">
<h5 id="org945e6b2">Cómo usar los números aleatorios</h5>
<div class="outline-text-5" id="text-org945e6b2">
<p>
La idea principal se puede presentar mediante un ejemplo muy
simple. Queremos construir un mecanismo aleatorio para simular el
lanzamiento de una moneda cargada con probabilidad p de obtener de
obtener \("cara"\). Llamemos \(X\) al resultado del lanzamiento: \(X \in
\{0, 1\}\) con la convención de que \("cara" = 1\) y \("ceca" = 0\).  Para
construir \(X\) usamos un número aleatorio \(U\), uniformemente
distribuido sobre el intervalo \([0, 1]\) y definimos
</p>
\begin{equation}X := \textbf{1} \{1 − p < U \leq 1\}\end{equation}
<p>
Es fácil ver X satisface las condiciones requeridas. En efecto, \[\mathbb{P}(X
= 1) = \mathbb{P}(1 − p < U \leq 1) = 1 − (1 − p) = p\]
La ventaja de la construcción es que se puede implementar casi
inmediatamente en una computadora. Por ejemplo, si \(p = 1 / 2\), una
rutina en Octave para simular \(X\) es la siguiente
Rutina para simular el lanzamiento de una moneda equilibrada
</p>
<pre class="example">
U = rand;
if U &gt; 1/2
  X = 1;
else
  X = 0;
end
X
</pre>
</div>
</div>
<div id="outline-container-org02afec7" class="outline-5">
<h5 id="org02afec7">Nota Bene</h5>
<div class="outline-text-5" id="text-org02afec7">
<p>
El ejemplo anterior es el prototipo para construir y simular
experimentos aleatorios. Con la misma idea podemos construir
experimentos aleatorios tan complejos como queramos.
</p>
</div>
</div>
</div>
<div id="outline-container-orge062b75" class="outline-3">
<h3 id="orge062b75">Simulación de experimentos aleatorios</h3>
<div class="outline-text-3" id="text-orge062b75">
<p>
Supongamos que \(\Omega = \{\omega_1, \omega_2, \dots , \omega_m\}\)
representa el espacio muestral correspondiente a un experimento
aleatorio y que cada evento elemental \(\omega_k \in \Omega\) tiene
asignada la probabilidad \(p(\omega_k) = p_k\).
Usando un número aleatorio, U, uniformemente distribuido sobre el
intervalo \((0, 1]\), podemos construir un mecanismo aleatorio, \(X\),
para simular los resultados del experimento aleatorio
considerado. Definimos
</p>
\begin{equation}
X = \displaystyle\sum_{k=1}^m k \textbf{1} \{L_{k−1} < U \leq L_k\}
\end{equation}
<p>
donde \[L_0 := 0 \text{ y } L_k := \displaystyle\sum_{i=1}^k p_i, (1
\leq k \leq m)\] e identificamos cada evento elemental \(\omega_k \in
\Omega\) con su correspondiente subíndice \(k\).
En efecto, de la definición (6) se deduce que para cada \(k = 1, \dots
, m\) vale que \[\mathbb{P}(X = k) = \mathbb{P}(L_{k−1} < U \leq L_k) = L_k − L_{k−1} =
p_k\]
</p>
</div>
<div id="outline-container-org55f77a9" class="outline-5">
<h5 id="org55f77a9">Nota Bene</h5>
<div class="outline-text-5" id="text-org55f77a9">
<p>
El mecanismo aleatorio definido en (6) se puede construir
\("gráficamente"\) de la siguiente manera:
</p>
<ol class="org-ol">
<li>Partir el intervalo \((0, 1]\) en m subintervalos sucesivos \(I_1,
   \dots , I_m\) de longitudes \(p_1, \dots , p_m\) , respectivamente.</li>
<li>Sortear un número aleatorio, \(U\), y observar en qué intervalo de la
partición cae.</li>
<li>Si \(U\) cae en el intervalo \(I_k\), producir el resultado \(\omega_k\).</li>
</ol>
</div>
</div>
<div id="outline-container-orgc10d824" class="outline-5">
<h5 id="orgc10d824">Ejemplo 2.1 (Lanzar un dado equilibrado)</h5>
<div class="outline-text-5" id="text-orgc10d824">
<p>
Se quiere simular el lanzamiento de un dado equilibrado. El espacio
muestral es \(\Omega = \{1, 2, 3, 4, 5, 6\}\) y la función de
probabilidades es \(p(k) = 1/6, k = 1, \dots , 6\). El mecanismo
aleatorio \(X = X(U)\), definido en (6), se construye de la siguiente
manera:
</p>
<ol class="org-ol">
<li>Partir el intervalo \((0, 1]\) en 6 intervalos sucesivos de longitud
\(1 / 6: I_1 = (0, 1 / 6], I_2 = (1 / 6, 2 / 6], I_3 = (2 / 6, 3 /
   6], I_4 = (3 / 6, 4 / 6], I_5 = (4 / 6, 5 / 6]\) e \(I_6 = (5 / 6, 6 /
   6]\).</li>
<li>Sortear un número aleatorio \(U\).</li>
<li>Si \(U \in I_k, X = k\).</li>
</ol>
<p>
En pocas palabras,
</p>
\begin{equation}
X = \displaystyle\sum_{k=1}^6 k \textbf{1}\left\{\frac{k−1}{6} < U \leq \frac{k}{6}\right\}
\end{equation}
<p>
Por ejemplo, si sorteamos un número aleatorio, \(U\) y se obtiene que \(U
= 0.62346\), entonces el valor simulado del dado es \(X = 4\). Una rutina
en Octave para simular \(X\) es la siguiente
Rutina para simular el lanzamiento de un dado
</p>
<pre class="example">
U = rand;
k = 0;
do
  k++;
until((k - 1) / 6 &lt; U &amp; U &lt;= k / 6)
X = k
</pre>
</div>
</div>
</div>
<div id="outline-container-orgeb26ab2" class="outline-3">
<h3 id="orgeb26ab2">Estimación de probabilidades</h3>
<div class="outline-text-3" id="text-orgeb26ab2">
<p>
Formalmente, un experimento aleatorio se describe mediante un espacio
de probabilidad \((\Omega, \mathcal{A}, \mathbb{P})\). Todas las
preguntas asociadas con el experimento pueden reformularse en términos
de este espacio. En la práctica, decir que un evento A ocurre con una
determinada probabilidad \(\mathbb{P}(A) = p\) equivale a decir que en una serie
suficientemente grande de experimentos las frecuencias relativas de
ocurrencia del evento \(A\) \[\hat{p}_k (A) = \frac{n_k(A){n_k}\]
(donde \(n_k\) es la cantidad de ensayos realizados en la k-ésima serie
y \(n_k(A)\) es la cantidad en los que ocurre \(A\)) son aproximadamente
idénticas unas a otras y están próximas a \(p\). Las series de
experimentos se pueden simular en una computadora utilizando un
generador de números aleatorios.
</p>
</div>
<div id="outline-container-org877f71e" class="outline-5">
<h5 id="org877f71e">Ejemplo 2.2</h5>
<div class="outline-text-5" id="text-org877f71e">
<p>
El experimento consiste en lanzar 5 monedas equilibradas y registrar
la cantidad N de caras observadas. El conjunto de todos los resultados
posibles es \(\Omega = \{0, 1, 2, 3, 4, 5\}\).  El problema consiste en
asignarle probabilidades a los eventos elementales.  La solución
experimental del problema se obtiene realizando una serie
suficientemente grande de experimentos y asignando a cada evento
elemental su frecuencia relativa.  Sobre la base de una rutina similar
a la que presentamos en la sección 2.1 para simular el resultado del
lanzamiento de una moneda equilibrada se pueden simular \(n = 10000\)
realizaciones del experimento que consiste en lanzar 5 monedas
equilibradas. Veamos co mo hacerlo. Usamos la construcción (5) para
simular el lanzamiento de 5 monedas equilibradas \(X_1, X2, X3, X4,
X5\). La cantidad de caras observadas es la suma de las \(X_i: N = X_1+
X2+ X3+ X4+ X5\).
Repitiendo la simulación 10000 veces (o genéricamente n veces),
obtenemos una tabla que contiene la cantidad de veces que fué simulado
cada valor de la variable \(N\). Supongamos que obtuvimos la siguiente
tabla:
</p>
<table id="orgc08bcae" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">valor simulado</th>
<th scope="col" class="org-right">0</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">2</th>
<th scope="col" class="org-right">3</th>
<th scope="col" class="org-right">4</th>
<th scope="col" class="org-right">5</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">cantidad de veces</td>
<td class="org-right">308</td>
<td class="org-right">1581</td>
<td class="org-right">3121</td>
<td class="org-right">3120</td>
<td class="org-right">1564</td>
<td class="org-right">306</td>
</tr>
</tbody>
</table>
<p>
En tal caso diremos que se obtuvieron las siguientes estimaciones
\[\mathbb{P}(N = 0) \approx 0.0308, \mathbb{P}(N = 1) \approx 0.1581, \mathbb{P}(N = 2) \approx
0.3121\] \[\mathbb{P}(N = 3) \approx 0.3120, \mathbb{P}(N = 4) \approx 0.1564, \mathbb{P}(N = 5)
\approx 0.0306\]
Para finalizar este ejemplo, presentamos un programa en Octave que
simula diez mil veces el lanzamiento de cinco monedas equilibradas,
contando en cada una la cantidad de caras observadas y que al final
provee una tabla como la representada en (8)
</p>
<pre class="example">
n = 10000;
N = zeros(1,n);
for i = 1:n
  U = rand(1,5);
  X = [ U &lt;= (1/2)];
  N(i) = sum(X);
end
for j=1:6
  T(j) = sum([N == j-1]);
end
T
</pre>
</div>
</div>
<div id="outline-container-org00d6426" class="outline-5">
<h5 id="org00d6426">Nota Bene</h5>
<div class="outline-text-5" id="text-org00d6426">
<p>
Usando las herramientas que proporciona el análisis combinatorio (ver
sección 3) se puede demostrar que para cada \(k \in \{0, 1, 2, 3, 4,
5\}\) vale que \[\mathbb{P}(N = k) = \binom{5}{k} \frac{1}{32}\]
En otros términos, \[\mathbb{P}(N = 0) = 0.03125, \mathbb{P}(N = 1) = 0.15625, \mathbb{P}(N = 2)
= 0.31250\] \[\mathbb{P}(N = 3) = 0.31250, \mathbb{P}(N = 4) = 0.15625, \mathbb{P}(N = 5) =
0.03125\]
</p>
</div>
</div>
<div id="outline-container-orgc00ca41" class="outline-5">
<h5 id="orgc00ca41">Ejemplo 2.3 (Paradoja de De Mere)</h5>
<div class="outline-text-5" id="text-orgc00ca41">
<p>
¿Cuál de las siguientes apuestas es más conveniente?
</p>
<ul class="org-ul">
<li>Obtener al menos un as en 4 tiros de un dado.</li>
<li>Obtener al menos un doble as en 24 tiros de dos dados.</li>
<li>La construcción (7) permite simular 4 tiros de un dado usando 4
números aleatorios independientes \(U1, U2, U3, U4\). La cantidad de
ases obtenidos en los 4 tiros es la suma \(S =
   \displaystyle\sum_{i=1}^4 \textbf{1}\{0 < U_i \leq 1 / 6\}\). El
evento \(A_1 =\) <i>"obtener al menos un as en 4 tiros de un dado"</i>
equivale al evento \(S \geq 1\). Si repetimos la simulación 10000
veces podemos obtener una estimación (puntual) de la probabilidad
del evento \(A_1\) calculando su frecuencia relativa. La siguiente
rutina (en Octave) provee una estimación de la probabilidad del
evento \(A_1\) basada en la repetición de 10000 simulaciones del
experimento que consiste en tirar 4 veces un dado.</li>
</ul>
<p>
Rutina 1
</p>
<pre class="example">
n = 10000;
A_1 = zeros(1,n);
for i = 1:n
  U = rand(1,4);
  S = sum(U &lt;= 1/6);
  if S &gt;= 1
    A_1(i) = 1;
  else
    A_1(i) = 0;
  end
end
hpA_1 = sum(A_1)/n
</pre>
<p>
Ejecutando 10 veces la Rutina 1 se obtuvieron los siguientes
resultados para la frecuencia relativa del evento \(A_1\) \[0.5179 0.5292
0.5227 0.5168 0.5204 0.5072 0.5141 0.5177 0.5127 0.5244\] Notar que
los resultados obtenidos se parecen entre sí e indican que la
probabilidad de obtener al menos un as en 4 tiros de un dado es mayor
que 0.5.
</p>
<ol class="org-ol">
<li>La construcción (7) permite simular 24 tiros de dos dados usando 48
números aleatorios independientes \(U_1, U_2, \dots , U_{47},
   U_{48}\).</li>
</ol>
<p>
La cantidad de veces que se obtiene un doble as en los 24 tiros de dos
dados es la suma \(S = \displaystyle\sum_{i=1}^24 \textbf{1} \{0 <
U_{2i−1} \leq 1 / 6, 0 < U_{2i} \leq 1 / 6\}\). El evento \(A_2 =\)
<i>"obtener al menos un doble as en 24 tiros de dos dados"</i> equivale al
evento \(S \geq 1\).
Si repetimos la simulación 10000 veces podemos obtener una estimación
(puntual) de la probabilidad del evento \(A_2\) calculando su frecuencia
relativa.
La siguiente rutina (en Octave) provee una estimación de la
probabilidad del evento \(A_2\) basada en la repetición de 10000
simulaciones del expe rimento que consiste en tirar 24 veces dos
dados.
Rutina 2
</p>
<pre class="example">
n = 10000;
A_2 = zeros(1,n);
for i = 1:n
  U = rand(2,24);
  V = (U &lt;= 1/6);
  S = sum(V(1,:).*V(2,:));
  if S &gt;= 1
    A_2(i) = 1;
  else
    A_2(i) = 0;
  end
end
hpA_2 = sum(A_2)/n
</pre>
<p>
Ejecutando 10 veces la Rutina 2 se obtuvieron los siguientes
resultados para la frecuencia relativa del evento \(A_2\) \[0.4829 0.4938
0.4874 0.4949 0.4939 0.4873 0.4882 0.4909 0.4926 0.4880\] Notar que
los resultados obtenidos se parecen entre sí e indican que la
probabilidad de obtener al menos un doble as en 24 tiros de dos dados
es menor que 0.5.
</p>
</div>
</div>
<div id="outline-container-orgc38f052" class="outline-5">
<h5 id="orgc38f052">Conclusión.</h5>
<div class="outline-text-5" id="text-orgc38f052">
<p>
Los resultados experimentales obtenidos indican que es mejor apostar a
que se obtiene al menos un as en 4 tiros de un dado que apostar a que
se obtiene al menos un doble as en 24 tiros de un dado.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org15e4c31" class="outline-2">
<h2 id="org15e4c31">Elementos de Análisis Combinatorio</h2>
<div class="outline-text-2" id="text-org15e4c31">
<p>
Cuando se estudian juegos de azar, procedimientos muestrales,
problemas de or den y ocupación, se trata por lo general con espacios
muestrales finitos \(\Omega\) en los que a todos los eventos elementales
se les atribuye igual probabilidad. Para calcular la probabilidad de
un evento \(A\) tenemos que dividir la cantidad de eventos elementales
contenidos en \(A\) (llamados casos favorables) entre la cantidad de
total de eventos elementales contenidos en \(\Omega\) (llamados casos
posibles). Estos cálculos se facilitan por el uso sistemático de unas
pocas reglas.
</p>
</div>
<div id="outline-container-orga132051" class="outline-3">
<h3 id="orga132051">Regla del Producto</h3>
<div class="outline-text-3" id="text-orga132051">
<p>
Sean \(A\) y \(B\) dos conjuntos cualesquiera. El producto cartesiano de
\(A\) y \(B\) se define por \(A \times B = \(a, b) : a \in A\) y $b &isin;
B\}. Si \(A\) y \(B\) son finitos, entonces \(|A \times B| = |A| · |B|\).
</p>
</div>
<div id="outline-container-orgf63af4d" class="outline-5">
<h5 id="orgf63af4d">Demostración</h5>
<div class="outline-text-5" id="text-orgf63af4d">
<p>
Supongamos que \(A = \{a_1, a_2, \dots , a_m\}\) y \(B = \{b_1, b_2, \dots ,
b_n\}\). Basta observar el cuadro siguiente
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">b<sub>1</sub></td>
<td class="org-left">b<sub>2</sub></td>
<td class="org-left">&hellip;</td>
<td class="org-left">b<sub>n</sub></td>
</tr>

<tr>
<td class="org-left">a<sub>1</sub></td>
<td class="org-left">(a<sub>1</sub>, b<sub>1</sub>)</td>
<td class="org-left">(a<sub>1</sub>, b<sub>2</sub>)</td>
<td class="org-left">&hellip;</td>
<td class="org-left">(a<sub>1</sub>, b<sub>n</sub>)</td>
</tr>

<tr>
<td class="org-left">a<sub>2</sub></td>
<td class="org-left">(a<sub>2</sub>, b<sub>1</sub>)</td>
<td class="org-left">(a<sub>2</sub>, b<sub>2</sub>)</td>
<td class="org-left">&hellip;</td>
<td class="org-left">(a<sub>2</sub>, b<sub>n</sub>)</td>
</tr>

<tr>
<td class="org-left">\vdots</td>
<td class="org-left">\vdots</td>
<td class="org-left">\vdots</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">\vdots</td>
</tr>

<tr>
<td class="org-left">a<sub>m</sub></td>
<td class="org-left">(a<sub>m</sub>, b<sub>1</sub>)</td>
<td class="org-left">(a<sub>m</sub>, b<sub>2</sub>)</td>
<td class="org-left">&hellip;</td>
<td class="org-left">(a<sub>m</sub>, b<sub>n</sub>)</td>
</tr>
</tbody>
</table>
<p>
Cuadro 1: Esquema rectangular del tipo tabla de multiplicar con \(m\)
filas y \(n\) columnas: en la intersección de fila \(i\) y la columna \(j\)
se encuentra el par \((a_i, b_j)\). Cada par aparece una y sólo una vez.
En palabras, con \(m\) elementos \(a_1, \dots , a_m\) y \(n\) elementos
\(b_1, \dots , b_n\) es posible formar \(m · n\) pares \((a_i, b_j)\) que
contienen un elemento de cada grupo.
</p>
</div>
</div>
<div id="outline-container-org21eb5b5" class="outline-5">
<h5 id="org21eb5b5">Teorema 3.1 (Regla del producto)</h5>
<div class="outline-text-5" id="text-org21eb5b5">
<p>
Sean A<sub>1</sub>, A<sub>2</sub>, &hellip; , An, n conjuntos cualesquiera. El producto
cartesiano de los \(n\) conjuntos \(A_1, A_2, \dots , An\) se define por \[A_1
\times A_2 \times \cdots \times An = \(x_1, x_2, \dots , x_n ) : x_i \in
A_i, 1 \leq i \leq n\}\]
Si los conjuntos \(A_1 , A_2 , \dots, An\) son finitos, entonces \[|A_1
\times A_2 \times \cdots \times An | = \prod_{i=1}^n |A_i|\]
</p>
</div>
</div>
<div id="outline-container-org49b5dc0" class="outline-5">
<h5 id="org49b5dc0">Demostración</h5>
<div class="outline-text-5" id="text-org49b5dc0">
<p>
Si \(n = 2\) ya lo demostramos. Si \(n = 3\), tomamos los pares \((x_1, x_2)\)
como elementos de un nuevo tipo. Hay \(|A_1| · |A_2|\) elementos de ese
tipo y \(|A_3|\) elementos \(x_3\). Cada terna \((x_1 , x_2 , x_3)\) es un
par formado por un elemento \((x_1 , x_2)\) y un elemento \(x_3\) ; por lo
tanto, la cantidad de ternas es \(|A_1| · |A_2| ·|A_3|\). Etcétera.
</p>
</div>
</div>
<div id="outline-container-orgccee81f" class="outline-5">
<h5 id="orgccee81f">Nota Bene</h5>
<div class="outline-text-5" id="text-orgccee81f">
<p>
Muchas aplicaciones se basan en la siguiente reformulación de la regla
del producto: \(r\) decisiones sucesivas con exactamente \(n_k\)
elecciones posibles en el k-ésimo paso pueden producir un total de
\(n_1· n_2 \cdots n_r\) resultados diferentes.
</p>
</div>
</div>
<div id="outline-container-org1ffd84b" class="outline-5">
<h5 id="org1ffd84b">Ejemplo 3.2 (Ubicar r bolas en n urnas)</h5>
<div class="outline-text-5" id="text-org1ffd84b">
<p>
Los resultados posibles del experimento se pueden representar mediante
el conjunto \[\Omega = \{1, 2, \dots , n\}^r = \(x_1, x_2, \dots ,
xr) : x_i \in \{1, 2, \dots , n\}, 1 \leq i \leq r\},\] donde \(x_i =
j\) representa el resultado <i>"la bola i se ubicó en la urna j"</i>. Cada
bola puede ubicarse en una de las \(n\) urnas posibles. Con \(r\) bolas
tenemos \(r\) elecciones sucesivas con exactamente \(n\) elecciones
posibles en cada paso. En consecuencia, \(r\) bolas pueden ubicarse en
\(n\) urnas de \(n_r\) formas distintas.
Usamos el lenguaje figurado de bolas y urnas, pero el mismo espacio
muestral admite muchas interpretaciones distintas. Para ilustrar el
asunto listaremos una cantidad de situciones en las cuales aunque el
contenido intuitivo varía son todas abstractamente equivalentes al
esquema de ubicar \(r\) bolas en \(n\) urnas, en el sentido de que los
resultados difieren solamente en su descripción verbal.
</p>
<ol class="org-ol">
<li>Nacimientos. Las configuraciones posibles de los nacimientos de r
personas corresponde a los diferentes arreglos de r bolas en n =
365 urnas (suponiendo que el año tiene 365 días).</li>
<li>Accidentes. Clasificar r accidentes de acuerdo con el día de la
semana en que ocurrieron es equivalente a poner r bolas en n = 7
urnas.</li>
<li>Muestreo. Un grupo de personas se clasifica de acuerdo con,
digamos, edad o profesión. Las clases juegan el rol de las urnas y
las personas el de las bolas.</li>
<li>Dados. Los posibles resultados de una tirada de r dados corresponde
a poner r bolas en n = 6 urnas. Si en lugar de dados se lanzan
monedas tenemos solamente n = 2 urnas.</li>
<li>Dígitos aleatorios. Los posibles or denamientos de una sucesión de
r dígitos corresponden a las distribuciones de r bolas (= lugares)
en diez urnas llamadas \(0, 1, \dots , 9\).</li>
<li>Coleccionando figuritas . Los diferentes tipos de figuritas
representan las urnas, las figuritas coleccionadas representan las
bolas.</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orge87e54b" class="outline-3">
<h3 id="orge87e54b">Muestras ordenadas</h3>
<div class="outline-text-3" id="text-orge87e54b">
<p>
Se considera una <i>"población"</i> de \(n\) elementos \(a1, a2, \dots ,
a_n\). Cualquier secuencia ordenada \(a_{j1}, a_{j2}, \dots , a_{jk}\) de
k símbolos se llama una muestra ordenad a de tamaño k tomada de la
población. (Intuitivamente los elementos se pueden elegir uno por
uno). Hay dos procedimientos posibles.
</p>
<ol class="org-ol">
<li>Muestreo con reposición. Cada elección se hace entre toda la
población, por lo que cada elemento se puede elegir más de una
vez. Cada uno de los k elementos se puede elegir en n formas: la
cantidad de muestras posibles es, por lo tanto, \(n_k\), lo que
resulta de la regla del producto con \(n_1 = n_2 = \cdots = n_k =
   n\).</li>
<li>Muestreo sin reposición. Una vez elegido, el elemento se quita de
la población, de modo que las muestras son arreglos sin
repeticiones. El volumen de la muestra k no puede exceder el tamaño
de la población total n. Tenemos n elecciones posibles para el
primer elemento, pero sólo \(n−1\) para el segundo, \(n−2\) para el
tercero, etcétera. Usando la regla del producto se obtiene un total
de</li>
</ol>
<p>
\begin{equation(n)<sub>k</sub> := n(n − 1)(n −2) &ctdot; (n − k + 1)\end{equation}
elecciones posibles.
</p>
</div>
<div id="outline-container-orgdcdf3aa" class="outline-5">
<h5 id="orgdcdf3aa">Teorema 3.3</h5>
<div class="outline-text-5" id="text-orgdcdf3aa">
<p>
Para una población de \(n\) elementos y un tamaño de muestra prefijado
\(k\), existen \(n^k\) diferentes muestras con reposición y \((n)_k\)
muestras sin reposición.
</p>
</div>
</div>
<div id="outline-container-orge37afd7" class="outline-5">
<h5 id="orge37afd7">Ejemplo 3.4</h5>
<div class="outline-text-5" id="text-orge37afd7">
<p>
Consideramos una urna con 8 bolas numeradas \(1, 2, \dots , 8\)
</p>
<ol class="org-ol">
<li>Extracción con rep os ición. Extraemos 3 bolas con reposición:
después de extraer una bola, anotamos su número y la ponemos de
nuevo en la urna. El espacio muestral \(\Omega_1\) correspondiente a
este experimento consiste de todas las secuencias de longitud 3 que
pueden formarse con los símbolos \(1, 2, \dots 8\). De acuerdo con el
Teorema 3.3, \(\Omega_1\) tiene \(8^3 = 512\) elementos. Bajo la
hipótesis de que todos los elementos tienen la misma probabilidad,
la probabilidad de observar la secuencia \((3, 7, 1)\) es \(1 / 512\).</li>
<li>Extracción de una colección ordenada sin reposición. Extraemos 3
bolas sin reposición: cada bola elegida no se vuelve a poner en la
urna. Anotamos los números de las bolas en el orden en que fueron
extraídas de la urna. El espacio muestral \(\Omega_2\)
correspondiente a este experimento es el conjunto de todas las
secuencias de longitud 3 que pueden formarse con los símbolos \(1, 2
   \dots , 8\) donde cada símbolo puede aparecer a los sumo una vez. De
acuerdo con el Teorema 3.3, \(\Omega_2\) tiene \((8)_3 = 8 · 7 · 6 =
   336\) elementos. Bajo la hipótesis que todos los elementos tienen la
misma probabilidad, la probabilidad de observar la secuencia \((3,
   7, 1)\) (en ese orden) es \(1 / 336\).</li>
</ol>
</div>
</div>
<div id="outline-container-org17e6b0a" class="outline-5">
<h5 id="org17e6b0a">Ejemplo 3.5</h5>
<div class="outline-text-5" id="text-org17e6b0a">
<p>
Una urna contiene 6 bolas rojas y 4 bolas negras. Se extraen 2 bolas
con reposición. Para fijar ideas supongamos que las bolas están
numeradas de la siguiente manera: las primeras 6 son las rojas y las
últimas 4 son las negras. El espacio muestral asociado es \(\Omega =
\{1, \dots , 10\}^2\) y su cantidad de elementos \(|\Omega| = 10^2\).
</p>
<ol class="org-ol">
<li>¿Cuál es la probabilidad de que las dos sean rojas? Sea R el evento
<i>"las dos son rojas"</i>, \(R = \{1, \dots , 6\}^2\) y \(|R| = 6^2\). Por
lo tanto, \(\mathbb{P}(R) = 6^2 / 10^2 = 0.36\).</li>
<li>¿Cuál es la probabilidad de que las dos sean del mismo co lor? Sea
N el evento <i>"las dos son negras"</i>, \(N = \{7, \dots , 10\}^2\) y
$|N| = 4<sup>2</sup>, entonces \(\mathbb{P}(N) = 4^2 / 10^2 = 0.16\). Por lo tanto, \(\mathbb{P}(R
   \cup N) = \mathbb{P}(R) + \mathbb{P}(N) = 0.52\).</li>
<li>¿Cuál es la probabilidad de que al menos una de las dos sea roja?
El evento <i>"al menos una de las dos es roja"</i> es el complemento de
<i>"las dos son negras"</i>. Por lo tanto, \(\mathbb{P}(N^c) = 1−\mathbb{P}(N) = 0.84\).</li>
</ol>
<p>
Si se consideran extracciones sin reposición, deben reemplazarse las
cantidades \(10^2 , 6^2\) y \(4^2\) por las correspondientes \((10)_2 ,
(6)_2\) y \((4)_2\).
Caso especial k = n. 
En muestreo sin reposición una muestra de tamaño \(n\) incluye a toda la
población y representa una permutación de sus elementos. En
consecuencia, \(n\) elementos \(a1, a2, \dots , an\) se pueden ordenar de
\((n)_n = n ·(n −1) \cdots 2 ·1\) formas distintas. Usualmente el número
\((n)_n\) se denota \(n!\) y se llama el factorial de \(n\).
</p>
</div>
</div>
<div id="outline-container-orgde1d9a4" class="outline-5">
<h5 id="orgde1d9a4">Corolario 3.6</h5>
<div class="outline-text-5" id="text-orgde1d9a4">
<p>
La cantidad de formas distintas en que se pueden ordenar \(n\) elementos
es
</p>
\begin{equation}n! = 1 · 2 \cdots n\end{equation}
</div>
</div>
<div id="outline-container-orgff68baf" class="outline-5">
<h5 id="orgff68baf">Observación 3.7</h5>
<div class="outline-text-5" id="text-orgff68baf">
<p>
Las muestras ordenadas de tamaño \(k\), sin reposición, de una población
de \(n\) elementos, se llaman variaciones de \(n\) elementos tomados de a
\(k\). Su número total \((n)_k\) se puede calcular del siguiente modo
</p>
<p>
\begin{equation(n)<sub>k</sub> = \frac{n!}(n-k)!}\end{equation}
</p>
</div>
</div>
<div id="outline-container-org398c0fd" class="outline-5">
<h5 id="org398c0fd">Nota Bene sobre muestreo aleatorio</h5>
<div class="outline-text-5" id="text-org398c0fd">
<p>
Cuando hablemos de <i>"muestras aleatorias de tamaño k"</i>, el adjetivo
aleatorio indica que todas las muestras posibles tienen la misma
probabilidad, a saber: \(1/n^k\) en muestreo con reposición y \(1 /
(n)_k\) en muestreo sin reposición. En ambos casos, \(n\) es el tamaño de
la población de la que se extraen las muestras.  Si \(n\) es grande y
\(k\) es relativamente pequeño, el cociente \((n)_k/n^k\) está cerca de la
unidad. En otras palabras, para grandes poblaciones y muestras
relativamente pequeñas, las dos formas de muestrear son prácticamente
equivalentes.
</p>
</div>
</div>
<div id="outline-container-org2f1001d" class="outline-5">
<h5 id="org2f1001d"><span class="todo TODO">TODO</span> Ejemplos</h5>
<div class="outline-text-5" id="text-org2f1001d">
<p>
Consideramos muestras aleatorias de volumen k (con reposición) tomadas
de una población de n elementos a1 , &hellip; , an . Nos interesa el
evento que en una muestra no se repita ningún el
emento. En total existen n
k
muestras diferentes, de las cuales (n)
k
satisfacen la condición
19
estipulada. Por lo tanto, la probabilidad de ninguna repetición en nuestra muestra es}
p =}
(n)
k
n
k
=
n ( n −{1) &ctdot; ( n − k + 1)
n
k
(12)
Las interpretaciones concretas de la fórmula (12) revelan aspectos sorprendentes.
Muestras aleatorias de números. La población consiste de los diez dígitos 0, 1, &hellip; , 9.
Toda sucesión de cinco dígitos representa una muestra de tamaño k = 5, y supondremos que
cada uno de esos arreglos tiene probabilidad 10
−{5}
. La probabilidad de que 5 dígitos aleatorios}
sean todos distintos es p = (10)}
5
10
−{5}
= 0.3024.
Bolas y urnas. Si n bolas se ubican aleatoriamente en n urnas, la probabilidad de que cada}
urna esté ocupada es
p =}
n{!}
n
n
.
Interpretaciones:
(a) Para n = 7, p = 0.00612&hellip;. Esto significa que si en una ciudad ocurren 7 acci
dente s por}
semana, entonces (suponiendo que todas las ubicaciones posibles son igualmente prob
ables) prácticamente todas las semanas contienen días con dos o más accidentes, y en
promedio solo una semana de 164 mostrará una distribución uniforme de un accidente
por día.
(b) Para n = 6 la probabilidad p es igual a 0.01543&#x2026; Esto muestra lo extremadamente
improbable que en seis tiradas de un dado perfecto aparezcan todas las caras.
Cumpleaños. Los cumpleaños de k personas constituyen una muestra de tamaño k de la}
población formada por todos los días del año.
De acuerdo con la ecuación (12) la probabilidad, p}
k
, de que todos los k cumpleaños sean
diferentes es
p
k
=
(365)
k
365
k
=
</p>

<p>
1 −}
1
365

1 −}
2
365

&ctdot;
</p>

<p>
1 −}
k −{1
365

.
Una fórmula aparentemente abominable. Si k = 23 tenemos p
k
&lt; 1}/{2. En palabras, para 23 
personas la probabilidad que al menos dos personas tengan un cumpleaños común excede 1 / 2}.
Aproximaciones numéricas de p
k
. Si k es chico, tomando logaritmos y usando que para x
pequeño y positivo log(1 −x) &sim; −x, se obtiene
log p
k
&sim; −
1 + 2 + &ctdot; + (k −} 1)
365
= −}
k ( k − 1)}
730
.
20
</p>
</div>
</div>
<div id="outline-container-org2eb3279" class="outline-5">
<h5 id="org2eb3279">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org2eb3279">
<ol class="org-ol">
<li>Hallar la probabilidad p}</li>
</ol>
<p>
k
de que en una muestra de k dígitos aleatorios no haya dos iguales.
Estimar el valor numérico de p
10
usando la fórmula de Stirling (1730): n! &sim; e 
−n
n
n{+}
1
2
\sqrt{}
2 &pi; .
</p>
<ol class="org-ol">
<li>Considerar los primeros 10000 decimales del número &pi;}. Hay 2000 grupos de cinco dígitos.</li>
</ol>
<p>
Contar la cantidad de grupos en los que los 5 dígitos son diferentes e indicar la frecuencia
relativa del evento considerado. Comparar el resultado obtenido con la probabilidad de que
en una muestra de 5 dígitos aleatorios no haya dos iguales.
</p>
</div>
</div>
</div>
<div id="outline-container-orgbf59df9" class="outline-3">
<h3 id="orgbf59df9">Subpoblaciones</h3>
<div class="outline-text-3" id="text-orgbf59df9">
<p>
En lo que sigue, utilizaremos el término población de tamaño n para designar una colección 
de n elementos sin considerar su orden. Dos poblaciones se consideran diferentes si una de
ellas contiene algún elemento que no está contenido en la otra.
Uno de los problemas más importantes del cálculo combinatorio es determinar la cantidad C}
n, k
de subpoblaciones distintas de tamaño k que tiene una población de tamaño n.
Cuando n y k son pequeños, el problema se puede resolver por enumeración directa. Por
ejemplo, hay seis formas distintas elegir dos letras entre cuatro letras A, B, C, D, a saber:
AB, AC , AD, BC, BD, CD. Así, C
4, 2
= 6. Cuando la cantidad de elementos de la colección
es grande la enumeración directa es impracticable. El problema general se resuelve razonando
de la siguiente manera: consideramos una subpoblación de tamaño k de una población de n
elementos. Cada numeración arbitraria de los elementos de la subpoblación la convierte en
una muestra ordenada de tamaño k. Todas las muestras ordenadas de tamaño k se pueden
obtener de esta forma. Debido a que k elementos se pueden ordenar de k! formas diferentes,
resulta que k! veces la cantidad de subpoblaciones de tamaño k coincide con la cantidad de
muestras ordenadas de dicho tamaño. En otros términos, C}
n, k
· k{! = (n ) 
k
. Por lo tanto,
C
n, k
=
(n)
k
k{!}
=
n{!}
k{!(n −}k)!}
. (13)
Los números definidos en (13) se llaman coeficientes binomiales o números combinatorios y}
la notación clásica para ellos es

n
k

.
</p>
</div>
<div id="outline-container-org7339520" class="outline-5">
<h5 id="org7339520">Teorema 3.8.</h5>
<div class="outline-text-5" id="text-org7339520">
<p>
Una población de n elementos tiene}
</p>

<p>
n
k

=
n{!}
k{!(n −}k)!}
(14)
diferentes subpoblaciones de tamaño k &le; n}.
</p>
</div>
</div>
<div id="outline-container-orgdf85e94" class="outline-5">
<h5 id="orgdf85e94">Ejemplo 3.9.</h5>
<div class="outline-text-5" id="text-orgdf85e94">
<p>
Consideramos una urna con 8 bolas numeradas 1, 2, &hellip; , 8. Extraemos 3 bolas}
simultáneamente, de modo que el orden es irrelevante. El espacio muestral &Omega;
3
correspondiente
a este experimento consiste de todos los subconjuntos de tamaño 3 del conjunto \1, 2, &hellip; , 8{\}.
Por el Teorema 3.8 &Omega;
3
tiene

8
3

= 56 elementos. Bajo la hipótesis de que todos los elementos
tienen la misma probabilidad, la probabilidad de seleccionar \3, 7, 1{\} es 1 / 56.
21
Dada una población de tamaño n podemos elegir una subpoblación de tamaño k de

n
k

maneras distintas. Ahora bien, elegir los k elementos que vamos a quitar de una población es
lo mismo que elegir los n − k elementos que vamos a dejar dentro. Por lo tanto, es cl aro que
para cada k &le; n debe valer
</p>

<p>
n
k

=
</p>

<p>
n
n −}k

. (15)
La ecuación (15) se deduce inmediatamente de la identidad (14). El lado izquierdo de la
ecuación (15) no está definido para k = 0, pero el lado derecho si l o está. Para que la ecuación
(15) sea valida para todo entero k tal que 0 &le; k &le; n, se definen}
</p>

<p>
n
0

:= 1, 0! := 1, y (n)
0
:= 1.
Triángulo de Pascal. Las ecuaciones en diferencias}
</p>

<p>
n
k

=
</p>

<p>
n −{1
k

</p>
<ul class="org-ul">
<li></li>
</ul>

<p>
n −{1
k −{1

, (16)
junto con el conocimiento de los datos de borde
</p>

<p>
n
0

=
</p>

<p>
n
n

= 1, (17)
determinan completamente los números c ombinatorios

n
k

, 0 &le; k &le; n, n = 0, 1, &hellip; . Usando
dichas relaciones se construye el famoso /"triángulo de Pascal'', que muestra todos los números
combinatorios en la forma de un triángulo
1
1 1
1 2 1
1 3 3 1
1 4 6 4 1
1 5 10 10 5 1
1 6 15 20 15 6 1
dots &hellip; &hellip; &hellip; &hellip; &hellip;
La n-ésima fila de este triángulo contiene los coeficientes

n
0

,

n
1

, &hellip; ,

n
n

. Las condiciones de
borde (17) indican que el primero y el último de esos números son 1. Los números restantes
se determinan por la ecuación en diferencias (16). Vale decir, para cada 0 &lt; k &lt; n, el k-ésimo
coeficiente de la n-ésima fila del /"triángulo de Pascal"/se obtiene sumando los dos coeficientes
inmediatamente superiores a izquierda y derecha. Por ejemplo,

5
2

= 4 + 6 = 10.
Control de calidad. Una planta de ensamblaje recibe una partida de 50 piezas de precisión}
que incluye 4 defectuosas. La división de control de calidad elige 10 piezas al azar para
controlarlas y rechaza la partida si encuentra 1 o más defectuosas. ¿Cuál es la probabilidad
de que la partida pase la inspección? Hay

50
10

formas de elegir la muestra para controlar y

46
10

de elegir todas las piezas sin defectos. Por lo tanto, la probabilidad es
</p>

<p>
46
10

50
10

−{1}
=
46!
10!36!
10!40!
50!
=
40 ·}39 ·}38 · 37
50 ·}49 ·}48 · 47
= 0, 3968. &#x2026;
22
Usando cálculos casi idénticos una compañía puede decidir sobre qué cantidad de piezas
defectuosas admite en una partida y diseñar un programa de control con una probabilidad
dada de éxito.
</p>
</div>
</div>
<div id="outline-container-orgc58f581" class="outline-5">
<h5 id="orgc58f581">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-orgc58f581">
<ol class="org-ol">
<li>Considerar el siguiente juego: el jugador I tira 4 veces una moneda honesta y el jugador}</li>
</ol>
<p>
II lo hace 3 veces. Calcular la la probabilidad de que el jugador I obtenga más caras que el
jugador II.
</p>
</div>
</div>
</div>
<div id="outline-container-org42e0ee8" class="outline-3">
<h3 id="org42e0ee8">Particiones</h3>
<div class="outline-text-3" id="text-org42e0ee8">
</div>
<div id="outline-container-orgf4b0649" class="outline-5">
<h5 id="orgf4b0649">Teorema 3.10. Sean r}</h5>
<div class="outline-text-5" id="text-orgf4b0649">
<p>
1
, &hellip; , r
k
enteros tales que
r
1
</p>
<ul class="org-ul">
<li>r</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>&ctdot; + r</li>
</ul>
<p>
k
= n, r}
i
&ge; 0. (18)
El número de formas en que una población de n elementos se puede dividir en k partes
ordenadas (particionarse en k subpoblaciones) tales que la primera contenga r
1
elementos, la
segunda r
2
, etc, es
n{!}
r
1
!r
2
! \cdotsr}
k
!
. (19)
Los números (19) se llaman coeficientes multinomiales.
</p>
</div>
</div>
<div id="outline-container-orgabcaec6" class="outline-5">
<h5 id="orgabcaec6">Demostración</h5>
<div class="outline-text-5" id="text-orgabcaec6">
<p>
Un uso repetido de (14) muestra que el número (19) se puede r eescribir en}
la forma
</p>

<p>
n
r
1

n −}r
1
r
2

n −}r
1
− r
2
r
3

&ctdot;
</p>

<p>
n −}r
1
− &ctdot; − r
k{−{2
r
k{−{1

(20)
Por otro lado, para efectuar la partición deseada, tenemos primero que seleccionar r
1
elementos
de los n; de los restantes n − r}
1
elementos seleccionamos un segundo grupo de tamaño r
2
,
etc. Después de formar el grupo (k − 1) quedan n − r}
1
− r
2
− &ctdot; − r
k{−{1
= r
k
elementos, y
esos forman el último grupo. Concluimos que (20) representa el número de formas en que se
puede realizar la partición.
</p>
</div>
</div>
<div id="outline-container-org050b840" class="outline-5">
<h5 id="org050b840">Ejemplo 3.11</h5>
<div class="outline-text-5" id="text-org050b840">
<p>
(Accidentes). En una semana ocurrieron 7 accidentes. Cuál es la probabilidad}
de que en dos días de esa semana hayan ocurrido dos accidentes cada día y de que en otros
tres días hayan ocurrido un accidente cada día?
Primero particionamos los 7 días en 3 subpoblaciones: dos días con dos accidentes en cada
uno, tres días con un accidente en cada uno y dos días sin accidentes.. Esa partición en tres
grupos de tamaños 2, 3, 2 se puede hacer de 7! / (2!3!2!) formas distintas y por cada una de
ellas hay 7! / (2!2!1!1!1!0!0!) = 7! / (2!2!) formas diferentes de ubicar los 7 accidentes en los 7
días. Por lo tanto, el valor de la probabilidad requerido es igual a
7!
2!3!2!
&times;
7!
2!2!
1
7
7
= 0.3212&hellip;
23
</p>
</div>
</div>
<div id="outline-container-org19c6ef7" class="outline-5">
<h5 id="org19c6ef7">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org19c6ef7">
<ol class="org-ol">
<li>¿Cuántas palabras distintas pueden formarse permutando las letras de la palabra /"man}</li>
</ol>
<p>
zana"/y cuántas permutando las letras de la palabra /"aiaiiaiiiaiiii''}?}
</p>
<ol class="org-ol">
<li>Se ubicarán 6 bolas distinguibles en 8 urnas numeradas 1, 2, &hellip; , 8. Suponiendo que todas}</li>
</ol>
<p>
las configuraciones distintas son equiprobables calcular la probabilidad de que resulten tre s
urnas ocupadas con una bola cada una y que otra urna contenga las tres bolas restantes.
</p>
</div>
</div>
</div>
<div id="outline-container-orgca7f6db" class="outline-3">
<h3 id="orgca7f6db">Distribución Hipergeométrica</h3>
<div class="outline-text-3" id="text-orgca7f6db">
<p>
Muchos problemas combinatorios se pueden reducir a la siguiente forma. En una urna
hay n
1
bolas rojas y n
2
bolas negras. Se elige al azar un grupo de r bolas. Se quiere calcular
la probabilidad p
k
de que en el grupo elegido, haya exactamente k b olas rojas, 0 &le; k &le;}
mín(n
1
, r).
Para calcular p
k
, observamos que el grupo elegido debe contener k bolas rojas y r{−}k negras.
Las rojas pueden elegirse de

n
1
k

formas distintas y la negras de

n
2
r{−}k

formas distintas. Como
cada elección de las k bolas rojas debe combinarse con cada elección de las r − k negras, se
obtiene
p
k
=
</p>

<p>
n
1
k

n
2
r − k

n
1
</p>
<ul class="org-ul">
<li>n</li>
</ul>
<p>
2
r

−{1}
(21)
El sistema de probabilidades obtenido se llama la distribución hipergeométrica.
</p>
</div>
<div id="outline-container-org583e4c7" class="outline-4">
<h4 id="org583e4c7">Control de calidad.</h4>
<div class="outline-text-4" id="text-org583e4c7">
<p>
En control de calidad industrial, se someten a inspección lotes de n unidades. Las unidades
defectuosas juegan el rol de las bolas rojas y su cantidad n
1
es descono c ida. Se toma una
muestra de tamaño r y se determina la cantidad k de unidades defectuosas. La fórmula (21)
permite hacer inferencias sobre la c antidad desconocida n
1
; se trata de problema típico de
estimación estadística que será analizado más adelante.
</p>
</div>
<div id="outline-container-org6e16ccf" class="outline-5">
<h5 id="org6e16ccf">Ejemplo 3.12.</h5>
<div class="outline-text-5" id="text-org6e16ccf">
<p>
Una planta de ensamblaje recibe una partida de 100 piezas de precisión que}
incluye exactamente 8 defectuosas. La división control de calidad elige 10 piezas al azar para
controlarlas y rechaza l a partida si encuentra al menos 2 defectuosas. ¿Cuál es la probabilidad
de que la partida pase la inspección?
El criterio de decisión adoptado indica que la partida pasa la inspección si (y sólo si)
en la muestra no se encuentran piezas defectuosas o si se e ncu e ntra exactamente una pieza
defectuosa. Hay

100
10

formas de elegir la muestra para controlar,

92
10

8
0

formas de elegir
muestras sin piezas defectuosas y

92
9

8
1

formas de elegir muestras con exactamente una
pieza defectuosa. En consecuencia la probabilidad de que la partida pase la inspección es
</p>

<p>
92
10

8
0

100
10

−{1}
</p>
<ul class="org-ul">
<li></li>
</ul>

<p>
92
9

8
1

100
10

−{1}
&asymp; 0.818.
24
</p>
</div>
</div>
<div id="outline-container-org22c2e6e" class="outline-5">
<h5 id="org22c2e6e">Ejemplo 3.13.</h5>
<div class="outline-text-5" id="text-org22c2e6e">
<p>
Una planta de ensamblaje recibe una partida de 100 piezas de precisión que}
incluye exactamente k defectuosas. La división control de calidad elige 10 piezas al azar para
controlarlas y rechaza la partida si encuentra al menos 2 defectuosas. ¿Con ese criterio de
decisión, cómo se comporta la probabilidad p(k) de que la partida pase la inspección?.
Una partida pasará la inspección si (y sólo si) al extraer una muestra de control la cantidad
de piezas defectuosas encontradas es 0 o 1. Hay

100
10

formas de elegir la muestra para con
trolar. Para cada k = 1, &hellip; , 90 hay

100{−k}
10{−k}

k
0

formas de elegir muestras sin piezas defectos y

100{−k}
9

k
1

formas de elegir muestras con exactamente una pieza defectuosa. En consecuencia
la probabilidad p(k) de que la partida pase la inspección es
p ( k) =}
</p>

<p>
100 −k}
10

k
0

100
10

−{1}
</p>
<ul class="org-ul">
<li></li>
</ul>

<p>
100 −k}
9

k
1

100
10

−{1}
.
Una cuenta sencilla muestra que para todo k = 1, &hellip; , 90 el c ociente
p ( k ) 
p ( k{−{1)}
es menor que 1.
Esto significa que a medida que aumenta la cantidad de piezas defectuosas en la partida, la
probabilidad de aceptarla disminuye.
0 10 20 30 40 50 60
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Figura 1: Gráfico de función p(k).
¿Cuál es la máxima probabilidad de aceptar una partida de 100 que contenga más de
20 piezas defectuosas? Debido a que la función p(k) es decreciente, dicha probabilidad es
p(20) &asymp; 0.3630.
</p>
</div>
</div>
<div id="outline-container-org4d48f46" class="outline-5">
<h5 id="org4d48f46">Ejemplo 3.14.</h5>
<div class="outline-text-5" id="text-org4d48f46">
<p>
Una planta de ensamblaje recibe un lote de n = 100 piezas de precisión, de}
las cuales una cantidad desconocida n
1
son defectuosas. Para controlar el lote se elige una
muestra (sin reposición) de r = 10 piezas. Examinadas estas, resultan k = 2 defectuosas.
¿Qué se puede decir sobre la cantidad de piezas defectuosas en el lote?
25
\hypertarget{pf1a}
Sabemos que de 10 piezas examinadas 2 son defectuosas y 8 no lo son. Por lo tanto,
2 &le; n}
1
&le; 92. Esto es todo lo que podemos decir con absoluta certeza. Podría suponerse que}
el lote contiene 92 piezas defectuosas. Partiendo de esa hipótesis, llegamos a la conclusión de
que ha ocurrido un evento de probabilidad
</p>

<p>
8
8

92
2

100
10

−{1}
= O(10
−{10}
).
En el otro extremo, podría suponerse que el lote contiene exactamente 2 piezas defectuosas,
en ese caso llegamos a la conclusión de que ha ocurrido un evento de probabilidad
</p>

<p>
98
8

2
2

100
10

−{1}
=
1
110
.
Las consideraciones anteriores conducen a buscar el valor de n
1
que maximice la probabilidad
p ( n
1
) :=
</p>

<p>
100 −n}
1
8

n
1
2

100
10

−{1}
,
puesto que para ese valor de n
1
nuestra observación tendría la mayor probabilidad de ocur
rir. Para encontrar ese valor consideramos el cociente
p ( n
1
)
p ( n
1
−{1)
. Simplificando los factoriales,
obtenemos
p ( n
1
)
p ( n
1
− 1)
=
n
1
(93 −n}
1
)
(n
1
− 2)(101 −n
1
)
&gt; 1}
\iff n
1
(93 −n}
1
) &gt; (n
1
− 2)(101 −n
1
)
\iff n
1
&lt; 20.2 \iff n
1
&le; 20.
Esto significa que cuando n
1
crece la sucesión p(n
1
) primero crece y después decrece; alcanza
su máximo cuando n
1
= 20. Suponiendo que n
1
= 20, la probabilidad de que en una muestra
de 10 piezas extraídas de un lote de 100 se observen 2 defectuosas es:
p(20) =}
</p>

<p>
80
8

20
2

100
10

−{1}
&asymp; 0.318.
Aunque el verdadero valor de n
1
puede ser mayor o menor que 20, si se supone que n
1
= 20 se
obtiene un resultado consistente con el sentido común que indicaría que los eventos observables
deben tener /"alta probabilidad''.
</p>
</div>
</div>
</div>
<div id="outline-container-orgca5ccd9" class="outline-4">
<h4 id="orgca5ccd9">Estimación por captura y recaptura.</h4>
<div class="outline-text-4" id="text-orgca5ccd9">
<p>
Para estimar la cantidad n de peces en un lago se puede realizar el siguiente procedimiento.
En el primer paso se capturan n
1
peces, que luego de marcarlos se los deja en libertad. En el
segundo paso se capturan r peces y se determina la cantidad k de peces marcados. La fórmula
(21) permite hacer inferencias sobre la cantidad desconocida n.
</p>
</div>
<div id="outline-container-org6ac3259" class="outline-5">
<h5 id="org6ac3259">Ejemplo 3.15</h5>
<div class="outline-text-5" id="text-org6ac3259">
<p>
(Exp erime ntos de captura y recaptura). Se capturan 1000 peces en un lago,}
se marcan con manchas rojas y se los deja en libertad. Después de un tiempo se hace una
nueva captura de 1000 peces, y se encuentra que 100 tienen manchas rojas. ¿Qué conclusiones
pueden hacerse sobre la cantidad de peces en el lago?
26
\hypertarget{pf1b}
0 20 40 60 80 100
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Figura 2: Gráfico de función p(n
1
). Observar que arg máx\{p(n
1
) : 2 &le; n}
1
&le; 92\} = 20.
Suponemos que las dos capturas pueden considerarse como muestras aleatorias de la
población total de peces en el lago. También vamos a suponer que la cantidad de peces
en el lago no cambió entre las dos capturas.
Generalizamos el problema admitiendo tamaños muestrales arbitrarios. Sean
n = el número (desconocido) de peces en el lago.
n
1
= el número de peces en la primera captura. Estos peces juegan el rol de las bolas
rojas.
r = el número de peces en la segunda captura.
k = el número de peces rojos en la segunda captura.
p
k
(n) = la probabilidad de que la segunda captura contenga exactamente k peces rojos.
Con este planteo la probabilidad p
k
(n) se obtiene poniendo n
2
= n − n}
1
en la fórmula (21):
p
k
(n) =
</p>

<p>
n
1
k

n −}n
1
r − k

n
r

−{1}
. (22)
En la práctica n
1
, r, y k pueden observarse, pero n es desconocido.
Notar que n es un número fijo que no depende del azar. Resultaría insensato preguntar
por la probabilidad que n sea mayor que, digamos, 6000.
Sabemos que fueron capturados n
1
</p>
<ul class="org-ul">
<li>r −}k peces diferentes, y por lo tanto n &ge; n}</li>
</ul>
<p>
1
</p>
<ul class="org-ul">
<li>r −}k}.</li>
</ul>
<p>
Esto es todo lo que podemos decir con absoluta certeza. En nuestro ejemplo tenemos n
1
=
r = 1000 y k = 100, y podría suponerse que el lago contiene solamente 1900 peces. Sin}
27
\hypertarget{pf1c}
embargo, partiendo de esa hipótesis, llegamos a la conclusión de que ha ocurrido un evento
de probabilidad fantásticamente pequeña. En efecto, si se supone que hay un total de 1900
peces, la fórmula (22) muestra que la probabilidad de que las dos muestras de tamaño 1000
agoten toda la población es ,
</p>

<p>
1000
100

900
900

1900
1000

−{1}
=
(1000!)
2
100!1900!
La fórmula de Stirling muestra que esta probabilidad es del orden de magnitud de 10
−{430}
, y en
esta situación el sentido común indica rechazar la hipótesis como irrazonable. Un razonamiento
similar nos induce a rechazar la hipótesis de que n es muy grande, digamos, un millón.
Las consideraciones anteriores nos conducen a buscar el valor de n que maximice la prob
abilidad p
k
(n), puesto que para ese n nuestra observación tendría la mayor probabilidad de
ocurrir. Para cualquier conjunto de observaciones n
1
, r, k, el valor de n que maximiza la prob
abilidad p
k
(n) se denota por ˆn
_{mv}
y se llama el estimador de máxima verosimilitud de n. Para
encontrar ˆn
_{mv}
consideramos la proporción
p
k
(n)
p
k
(n −} 1)
=
(n −}n}
1
)(n −}r)
(n −}n}
1
− r + k ) n}
&gt; 1}
\iff (n − n
1
)(n −}r) &gt; (n − n}
1
− r + k ) n}
\iff n
2
− nn}
1
− nr + n}
1
r &gt; n
2
− nn}
1
− nr + nk}
\iff n &lt;}
n
1
r
k
.
Esto significa que cuando n crece la sucesión p
k
(n) primero crece y después decrece; alcanza
su máximo cuando n es el mayor entero menor que
n
1
r
k
, así que ˆn
_{mv}
es aproximadamente
igual a
n
1
r
k
. En nuestro ejemplo particular el estimador de máxima verosimilitud del número
de peces en el lago es ˆn
_{mv}
= 10000.
El verdadero valor de n puede ser mayor o menor, y podemos preguntar por los límites
entre los que resulta razonable esperar que se encuentre n. Para esto testeamos la hipótesis
que n sea menos que 8500. Sustituimos en (22) n = 8500, n}
1
= r = 1000, y calculamos la
probabilidad que la segunda muestra contenga 100 o menos peces rojos. Esta probabilidad es
p = p
0
</p>
<ul class="org-ul">
<li>p</li>
</ul>
<p>
1
</p>
<ul class="org-ul">
<li>&ctdot; + p</li>
</ul>
<p>
100
. Usando una computadora encontramos que p &asymp; 0.04. Similarmente,
si n = 12.000, la probabilidad que la segunda muestra contenga 100 o más peces rojos esta
cerca de 0.03. Esos resultados justificarían la apuesta de que el verdadero número n de peces
se encuentra en algún lugar entre 8500 y 12.000.
</p>
</div>
</div>
<div id="outline-container-orgadb8a03" class="outline-5">
<h5 id="orgadb8a03">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-orgadb8a03">
<ol class="org-ol">
<li>Un estudiante de ecología va a una laguna y captura 60 escarabajos de agua, marca cada}</li>
</ol>
<p>
uno con un punto de pintura y los deja en libertad. A los pocos días vuelve y captura otra
muestra de 50, encontrando 12 escarabajos marcados. ¿Cuál sería su mejor apuesta sobre el
tamaño de la población de escarabajos de agua en la laguna?
28
\hypertarget{pf1d}
</p>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org53a9db5" class="outline-2">
<h2 id="org53a9db5">Mecánica Estadística</h2>
<div class="outline-text-2" id="text-org53a9db5">
<p>
El espacio se divide en una gran cantidad, n , de pequeñas regiones
llamadas celdas. Se considera un sistema mecánico compuesto por r
partículas que se distribuyen al azar entre las n celdas. ¿Cuál es la
distribución de las partículas en las celdas? La respuesta depende de
lo que se considere un evento elemental.
</p>
<ol class="org-ol">
<li>Estadística de Maxwell-Boltzmann. Suponemos que todas las partículas son distintas y</li>
</ol>
<p>
que todas las ubicaciones de las partículas son igualmente posibles. Un evento elemental
está determinado por la r-upla (x
1
, x
2
, &hellip; , x
r
), donde x
i
es el número de la celda en la
que cayó la partícula i. Puesto que cada x
i
puede tomar n valores distintos, el número
de tales r-uplas es n
r
. La probabilidad de un evento elemental es 1{/n}
r
.
</p>
<ol class="org-ol">
<li>Estadística de Bose-Einstein. Las partículas son indistinguibles. De nuevo, todas las</li>
</ol>
<p>
ubicaciones son igualmente posibles. Un evento elemental está determinado por la n-upla
(r
1
, &hellip; , r
n
), donde r
1
</p>
<ul class="org-ul">
<li>&ctdot;}+ r</li>
</ul>
<p>
n
= r y r
i
es la cantidad de partículas en la i-ésima cel
da,
1 &le; i &le; n}. La cantidad de tales n-uplas se puede calcular del siguiente modo: a cada
n{- upla (r
1
, r
2
, &hellip; , r
n
) la identificamos con una sucesión de unos y ceros s
1
, &hellip; , s
r{+}n{−{1
con unos en las posiciones numeradas r
1
</p>
<ul class="org-ul">
<li>1, r}</li>
</ul>
<p>
1
</p>
<ul class="org-ul">
<li>r</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>2, &hellip; , r}</li>
</ul>
<p>
1
</p>
<ul class="org-ul">
<li>r</li>
</ul>
<p>
2
</p>
<ul class="org-ul">
<li>&ctdot;}+ r</li>
</ul>
<p>
n{−{1
</p>
<ul class="org-ul">
<li>n −} 1</li>
</ul>
<p>
(hay n − 1 de ellas) y ceros en las restantes posiciones. La cantidad de tales sucesiones
es igual al número de combinaciones de r + n −} 1 cosas tomadas de a n −} 1 por vez. La
probabilidad de un evento elemental es 1 / 

r{+}n{−{1
n{−{1

.
</p>
<ol class="org-ol">
<li>Estadística de Fermi-Dirac. En este caso r &lt; n y cada celda contiene a lo sumo una</li>
</ol>
<p>
partícula. La cantidad de eventos elementales es

n
r

. La probabilidad de un evento
elemental es 1 / 

n
r

.
</p>
</div>
<div id="outline-container-orga02d72e" class="outline-5">
<h5 id="orga02d72e">Ejemplo 4.1.</h5>
<div class="outline-text-5" id="text-orga02d72e">
<p>
Se distribuyen 5 partículas en 10 celdas numeradas 1, 2, &hellip; , 10. Calcular, para}
cada una de las tres estadísticas, la probabilidad de que las celdas 8, 9 y 10 no tengan partículas
y que la celdas 6 y 7 tengan exactamente una partícula cada una.
</p>
<ol class="org-ol">
<li>Maxwell-Boltzmann}. Las bolas son distinguibles y todas las configuraciones diferentes</li>
</ol>
<p>
son equiprobables. La probabilidad de cada configuración (x
1
, &hellip; , x
5
) &isin; \1, &hellip; , 10{\}
5
,
donde x
i
indica la celda en que se encuentra la partícula i, es 1 / 10
5
.
¿De qué forma podemos obtener las configuraciones deseadas? Primero elegimos (en
orden) las 2 bolas que van a ocupar la celdas 6 y 7 (hay 5 &times; 4 formas diferentes de
hacerlo) y luego elegimos entre las celdas 1, 2, 3, 4, 5 las ubicaciones de las 3 bolas
restantes (hay 5
3
formas diferentes de hacerlo). Por lo tanto, su cantidad es 5 &times; 4 &times; 5
3
y la probabilidad de observarlas es
p =}
5 &times;}4 &times;}5
3
10
5
=
1
5 &times;}2
3
=
1
40
= 0.025.
</p>
<ol class="org-ol">
<li>Bose-Einstein}. Las partículas son indistinguibles y todas las configuraciones distintas</li>
</ol>
<p>
son equiprobables. La probabilidad de cada configuración (r
1
, &hellip; , r
10
), donde r
1
</p>
<ul class="org-ul">
<li>&ctdot;}+</li>
</ul>
<p>
r
10
= 5 y r
i
es la cantidad de partículas en la i-ésima celda, es 1 / 

14
9

.
Las configuraciones deseadas son de la forma (r
1
, &hellip; , r
5
, 1, 1, 0, 0, 0), donde r
1
+{&ctdot;}+r
5
=
3, su cantidad es igual a la cantidad de configuraciones distintas que pueden formarse
29
\hypertarget{pf1e}
usando 3 ceros y 4 unos. Por lo tanto, su cantidad es

7
3

y la probabilidad de observarlas
es
p =}
</p>

<p>
7
3

14
9

−{1}
=
35
2002
&asymp; 0.0174&#x2026;.}
</p>
<ol class="org-ol">
<li>Fermi-Dirac. Las partículas son indistinguibles, ninguna celda puede contener más de</li>
</ol>
<p>
una partícula y todas las configuraciones distintas son equiprobables. La probabilidad
de cada configuración es 1 / 

10
5

.
Las configuraciones deseadas se obtienen eligiendo tres de las las cinco celdas 1, 2, 3,
4, 5 para ubicar las tres partículas que no están en las celdas 6 y 7. Por lo tanto, su
cantidad es

5
3

y la probabilidad de observarlas es
</p>

<p>
5
3

10
5

−{1}
=
10
252
&asymp; 0.0396&#x2026;.}
</p>
</div>
</div>
<div id="outline-container-org733aa6a" class="outline-5">
<h5 id="org733aa6a">Ejemplo 4.2.</h5>
<div class="outline-text-5" id="text-org733aa6a">
<p>
Calcular para cada una de las tres estadísticas mencionadas, la probabilidad}
de que una celda determinada (p.ej., la número 1) no contenga partícula.
En cada uno de los tres casos la cantidad de eventos elementales favorables es igual a
la cantidad de ubicaciones de las partículas en n − 1 celdas. Por lo tanto, designando por
p
MB
, p
BE
, p
F D
las probabilidades del evento especificado para cada una de las estadísticas
(siguiendo el orden de exposición), tenemos que
p
MB
=
(n −} 1)
r
n
r
=
</p>

<p>
1 −}
1
n

r
,
p
BE
=
</p>

<p>
r + n − 2
n −{2

r + n − 1
n −{1

−{1}
=
n −{1
N + n −{1
,
p
F D
=
</p>

<p>
n −{1
r

n
r

−{1}
= 1 −}
r
n
.
Si r/n = &lambda; y n &rarr; &infin;}, entonces
p
MB
= e
− &lambda; 
, p
BE
=
1
1 + &lambda;}
, p
F D
= 1 − &lambda;.}
Si &lambda; es pequeño, esas probabilidades coinciden hasta O( &lambda; 
2
). El número &lambda; carac teriza la <i>"densidad promedio"</i> de las partículas.
</p>
</div>
</div>
<div id="outline-container-org2fd0df9" class="outline-5">
<h5 id="org2fd0df9">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org2fd0df9">
<ol class="org-ol">
<li>Utilizando la estadística de Maxwell-Boltzmann construir un mecanismo aleatorio para}</li>
</ol>
<p>
estimar el número e.
30
\hypertarget{pf1f}
</p>
</div>
</div>
<div id="outline-container-org013a0c0" class="outline-3">
<h3 id="org013a0c0">Algunas distribuciones relacionadas con la estadística de Maxwell-Boltzmann</h3>
<div class="outline-text-3" id="text-org013a0c0">
<p>
Se distribuyen r partículas en n celdas y cada una de las n
r
configuraciones tiene probabilidad n
−r
.
</p>
</div>
<div id="outline-container-org0daf81a" class="outline-4">
<h4 id="org0daf81a">Cantidad de partículas por celda: la distribución binomial</h4>
<div class="outline-text-4" id="text-org0daf81a">
<p>
Cantidad de partículas en una celda específica. Para calcular la probabilidad, p}
MB
(k),
de que una celda específica contenga exactamente k partículas (k = 0, 1, &hellip; , r) notamos que
las k partículas pueden elegirse de

r
k

formas, y las restantes r −}k partículas pueden ubicarse
en las restantes n − 1 celdas de (n − 1)
r{−}k
formas. Resulta que
p
MB
(k) =
</p>

<p>
r
k

(n −} 1)
r{−}k
1
n
r
Dicho en palabras, en la estadística de Maxwe
ll-Bol tzmann la probabilidad de que una
celda dada contenga exactamente k partículas está dada por la distribución Binomial (r,}
1
n
)
definida por
p ( k) :=}
</p>

<p>
r
k

1
n

k
</p>

<p>
1 −}
1
n

r{−}k
, 0 &le; k &le; r. (23)
Cantidad de partículas más probable en una celda específica. La cantidad más}
probable de partículas en una celda específica es el entero &nu; tal que
(r − n + 1)
n
&lt; &nu; &le;}
(r + 1)
n
. (24)
Para ser más precisos:
p
MB
(0) &lt; p}
MB
(1) &lt; &ctdot; &lt; p}
MB
(&nu; − 1) &le; p}
MB
( &nu; ) &gt; p}
MB
(&nu; + 1) &gt; &ctdot; &gt; p}
MB
(r).
</p>
</div>
<div id="outline-container-orgb718dd6" class="outline-5">
<h5 id="orgb718dd6">Demostración</h5>
<div class="outline-text-5" id="text-orgb718dd6">
<p>
(Ejercicio.)
</p>
</div>
</div>
</div>
<div id="outline-container-orgff028a8" class="outline-4">
<h4 id="orgff028a8">Forma límite: la distribución de Poisson</h4>
<div class="outline-text-4" id="text-orgff028a8">
<p>
Forma límite. Si n &rarr; &infin; y r &rarr; &infin; de modo que la cantidad promedio &lambda; = r/n de partículas}
por celda se mantiene constante, entonces
p
MB
(k) &rarr; e}
− &lambda; 
&lambda;
k
k{!}
.
Dicho en palabras, la forma límite de la estadí stica de Maxwell-Boltzmann es la distribución 
de Poisson de media &lambda; definida por
p ( k) := e
− &lambda; 
&lambda;
k
k{!}
, k = 0, 1, 2, &hellip; (25)
31
</p>
</div>
<div id="outline-container-orgafc6955" class="outline-5">
<h5 id="orgafc6955">Demostración</h5>
<div class="outline-text-5" id="text-orgafc6955">
<p>
Primero observamos que:}
</p>

<p>
r
k

1
n

k
</p>

<p>
1 −}
1
n

r{−}k
=
r{!}
k{!(r − k)!}
</p>

<p>
1
n

k
</p>

<p>
1 −}
1
n

r{−}k
=
1
k{!}
</p>

<p>
1
n

k
</p>

<p>
n −{1
n

−k
r{!}
(r − k)!
</p>

<p>
1 −}
1
n

r
=
1
k{!}
1
(n −} 1)
k
r{!}
(r − k)!
</p>

<p>
1 −}
1
n

r
. (26)
Reemplazando en (26) r = &lambda; n obtenemos:
</p>

<p>
&lambda; n
k

1
n

k
</p>

<p>
1 −}
1
n

&lambda; n{−}k
=
1
k{!}
1
(n −} 1)
k
(&lambda; n)!
(&lambda; n − k)!
</p>

<p>
1 −}
1
n

&lambda; n
=

1 −}
1
n

n

&lambda;
1
k{!}
1
(n −} 1)
k
(&lambda; n)!
(&lambda; n − k)!
&sim; e
− &lambda; 
1
k{!}
</p>

<p>
1
(n −} 1)
k
(&lambda; n)!
(&lambda; n −}k)!

. (27)
Para estimar el último factor del lado derecho de (27) utilizamos la fórmula de Stirling n! &sim;}
\sqrt{}
2{&pi; n}
n{+}
1
2
e
−n
</p>
<pre class="example">


</pre>
<p>
1
(n −} 1)
k
(&lambda; n)!
(&lambda; n −}k)!
&sim;
1
(n −} 1)
k
\sqrt{}
2{&pi; (&lambda; n)
&lambda; n{+}
1
2
e
−{&lambda; n}
\sqrt{}
2{&pi; (&lambda; n − k)
(&lambda; n{−}k)+
1
2
e
−(&lambda; n} −{k ) 
=
1
(n −} 1)
k
(&lambda; n)
&lambda; n{+}
1
2
e
−k
(&lambda; n − k)
(&lambda; n{−}k)+
1
2
=
</p>

<p>
&lambda; n −}k
n −{1

k
</p>

<p>
&lambda; n
&lambda; n −}k

&lambda; n{+}
1
2
e
−k
&sim; &lambda;}
k
e
−k
"
</p>

<p>
1 −}
k
&lambda; n

&lambda; n{+}
1
2
\#
−{1}
&sim; &lambda;}
k
. (28)
De (26), (27) y (28) resulta que
</p>

<p>
r
k

1
n

k
</p>

<p>
1 −}
1
n

r{−}k
&sim; e
− &lambda; 
&lambda;
k
k{!}
. (29)
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb341e40" class="outline-3">
<h3 id="orgb341e40">Algunas distribuciones relacionadas con la estadística de Bose-Einstein</h3>
<div class="outline-text-3" id="text-orgb341e40">
<p>
Se distribuyen r partículas indistinguibles en n celdas y cada una de las

r{+}n{−{1
n{−{1

configu
raciones tiene probabilidad 1 / 

r{+}n{−{1
n{−{1

.
32
</p>
</div>
<div id="outline-container-orga4bb6d6" class="outline-4">
<h4 id="orga4bb6d6">Cantidad de partículas por celda</h4>
<div class="outline-text-4" id="text-orga4bb6d6">
<p>
Cantidad de partículas en una celda específica. Para calcular la probabilidad, p}
BE
(k),
de que una celda específica contenga exactamente k partículas (k = 0, 1, &hellip; , r) fijamos k de
los r ceros y 1 de los n − 1 unos para r
epresentar que hay k partículas en la urna específica.
La cantidad de configuraciones distintas que pueden formarse con los restantes r − k ceros y
n −{2 unos es

r{−}k{+}n{−{2
n{−{2

. Resulta que
p
BE
(k) =
</p>

<p>
r − k + n −{2
n −{2

r + n − 1
n −{1

−{1}
. (30)
Cantidad de partículas más probable en una celda específica. Cuando n &gt; 2 la}
cantidad más probable de partículas en una celda específica es 0 o más precisamente p
BE
(0) &gt;}
p
BE
(1) &gt; &ctdot;} .
</p>
</div>
<div id="outline-container-org51ea020" class="outline-5">
<h5 id="org51ea020">Demostración</h5>
<div class="outline-text-5" id="text-org51ea020">
<p>
(Ejercicio.)
</p>
</div>
</div>
</div>
<div id="outline-container-org47b4783" class="outline-4">
<h4 id="org47b4783">Forma límite: la distribución de Geométrica</h4>
<div class="outline-text-4" id="text-org47b4783">
<p>
Forma límite. Si n &rarr; &infin; y r &rarr; &infin; de modo que la cantidad promedio &lambda; = r/n de partículas}
por celda se mantiene constante, entonces
p
BE
(k) &rarr;}
&lambda;
k
(1 + &lambda;)
{k+1}
.
Dicho en palabras, la forma límite de la estadística de Bose-Einstein es la distribución ge- 
ométrica de parámetro
1
1+ &lambda; 
definida por
p ( k) :=}
</p>

<p>
1 −}
1
1 + &lambda;}

k
1
1 + &lambda;}
, k = 0, 1, 2, &hellip;
</p>
</div>
<div id="outline-container-org10f5789" class="outline-5">
<h5 id="org10f5789">Demostración</h5>
<div class="outline-text-5" id="text-org10f5789">
<p>
Primero observamos que:}
</p>

<p>
r − k + n −{2
n −{2

r + n − 1
n −{1

−{1}
=
(r − k + n −} 2)!
(n −} 2)!(r − k)!
(n −} 1)!r!
(r + n − 1)!
=
(n −} 1)!
(n −} 2)!
r{!}
(r − k)!
(r − k + n −} 2)!
(r + n − 1)!
. (31)
Reemplazando en el lado derecho de (31) r = &lambda; n obtenemos:
(n −} 1)!
(n −} 2)!
(&lambda; n)!
(&lambda; n − k)!
(&lambda; n −}k + n − 2)!
(&lambda; n + n −} 1)!
(32)
33
Para estimar los factores que intervienen en (32) utilizamos la fórmula de Stirling n! &sim;}
\sqrt{}
2{&pi; n}
n{+}
1
2
e
−n
</p>
<pre class="example">


</pre>
<p>
(n −} 1)
n{−{1+
1
2
e
−{n{+1
(n −} 2)
n{−{2+
1
2
e
−{n{+2
&sim; (n − 2)e}
−{1}
"
</p>

<p>
1 −}
1
n −{1

n{−{1
\#
−{1}
&sim; n − 2 &sim; n, (33)}
(&lambda; n)
&lambda; n{+}
1
2
e
−{&lambda; n}
(&lambda; n − k)
&lambda; n{−}k{+}
1
2
e
−{&lambda; n{+}k}
&sim; (&lambda; n − k ) 
k
e
−k
"
</p>

<p>
1 −}
k
&lambda; n

&lambda; n
\#
−{1}
&sim; (&lambda; n − k ) 
k
&sim; &lambda;}
k
n
k
, (34)
(&lambda; n − k + n − 2)
&lambda; n{−}k{<del>}n{−{2</del>
1
2
e
−{&lambda; n{+}k}−{n{+2
(&lambda; n + n −} 1)
&lambda; n{<del>}n{−{1</del>
1
2
e
−{&lambda; n}−{n{+1
&sim; (&lambda; n − k + n −{2)
−k−{1}
e
{k+1}
&times;
</p>

<p>
1 −}
k + 1}
&lambda; n + n −{1

&lambda; n{+}n{−{1
&sim; (&lambda; n − k + n −{2)
−k−{1}
&sim;
1
(1 + &lambda;)
{k+1}
n
{k+1}
. (35)
De (31), (32), (33), (34) y (35) resulta que
</p>

<p>
r − k + n −{2
n − 2

r + n − 1
n −{1

−{1}
&sim;
&lambda;
k
(1 + &lambda;)
k
. (36)
</p>
</div>
</div>
<div id="outline-container-org788a3ff" class="outline-5">
<h5 id="org788a3ff">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org788a3ff">
<ol class="org-ol">
<li>Considerando la estadística de Maxwell-Boltzmann para la distribución aleatoria de r}</li>
</ol>
<p>
partículas en n celdas demostrar que la cantidad de de partículas más probable en una celda
determinada es la parte entera de
r{+1}
n
.
</p>
<ol class="org-ol">
<li>Considerando la estadística de Bose-Einstein para la distribución aleatoria de r partículas}</li>
</ol>
<p>
(indistinguibles) en n &gt; 2 celdas demostrar que la cantidad de de partículas más probable en
una celda determinada es 0.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org960da15" class="outline-3">
<h3 id="org960da15">Tiempos de espera</h3>
<div class="outline-text-3" id="text-org960da15">
<p>
Consideramos una vez más el experimento conceptual de ubicar aleatoriamente partículas
(distinguibles) en n celdas. Solo que ahora no fijamos la cantidad r de partículas y ubicamos
las partículas una por una hasta que ocurra alguna situación prescrita. Analizaremos dos
situaciones:
(i) Ubicar partículas hasta que alguna se ubique en una celda ocupada previamente.
(ii) Fijada una celda, ubicar partículas hasta que alguna ocupe la celda.
34
Situación (i). Usamos símbolos de la forma (j}
1
, j
2
, &hellip; , j
r
) para indicar que la primera, la
segunda,&#x2026; y la r-ésima partícula están ubicadas en las celdas j
1
, j
2
, &hellip; , j
r
y que el proceso
culmina en el paso r. Esto significa que las j
i
son enteros entre 1 y n; que las j
1
, j
2
, &hellip; , j
r{−{1
son todas diferentes y que j
r
es igual a una de ellas. Toda configuración de ese tipo representa
un punto muestral. Los posibles valores de r son 2, 3, &hellip; , n + 1.
Para un r fijo el conjunto de todos los puntos muestrales (j
1
, j
2
, &hellip; , j
r
) representa el
evento que el proceso termina en el r-ésimo paso. Los números j
1
, j
2
, &hellip; , j
r{−{1
pueden elegirse
de (n)
r{−{1
formas diferentes; j
r
podemos elegir uno de los r − 1 números j
1
, j
2
, &hellip; , j
r{−{1
. Por
lo tanto la probabilidad de que el proceso termine en el r-ésimo paso es
p
r
=
(n)
r{−{1
(r − 1)
n
r
. (37)
Situación (ii). Usamos símbolos de la forma (j}
1
, j
2
, &hellip; , j
r
) para indicar que la primera, la
segunda,&#x2026; y la r-ésima partícula están ubicadas en las celdas j
1
, j
2
, &hellip; , j
r
y que el proceso
culmina en el paso r. Las r-uplas (j
1
, j
2
, &hellip; , j
r
) están sujetas a la condición de que los números
j
1
, j
2
, &hellip; , j
r{−{1
son diferentes de un número prescrito a &le; n, y j
r
= a.
Para un r fijo el conjunto de todos los puntos muestrales (j
1
, j
2
, &hellip; , j
r
) representa el
evento que el proceso termina en el r-ésimo paso. Los números j
1
, j
2
, &hellip; , j
r{−{1
pueden elegirse
de (n −} 1)
r{−{1
formas diferentes; j
r
debe ser a. Por lo tanto la probabilidad de que el proceso
termine en el r-ésimo paso es
p
r
=
(n −} 1)
r{−{1
n
r
. (38)
</p>
</div>
</div>
</div>
<div id="outline-container-orged46e0a" class="outline-2">
<h2 id="orged46e0a">Bibliografía consultada</h2>
<div class="outline-text-2" id="text-orged46e0a">
<p>
Para redactar estas notas se consultaron los siguientes libros:
</p>
<ol class="org-ol">
<li>Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to
Probability. M.I.T. Lecture Notes. (2000)</li>
<li>Brémaud, P.: An Introduction to Probabilistic Modeling. Springer,
New York. (1997)</li>
<li>Durrett, R. Elementary Probability for Applications. Cambridge
University Press, New York. (2009)</li>
<li>Feller, W.: An introduction to Probability Theory and Its
Applications. Vol. 1. John Wiley &amp; Sons, New York. (1957)</li>
<li>Ferrari, P.: Passeios aleatórios e redes eletricas. Instituto de
Matemática Pura e Aplicada. Rio de Janeiro. (1987)</li>
<li>Grinstead, C. M. &amp; Snell, J. L. Introduction to
Probability. American Mathematical Society. (1997)</li>
<li>Kolmogorov, A. N.: Foundations of the Theory of
Probability. Chelsea Publishing Co., New York. (1956)</li>
<li>Kolmogorov, A. N.: The Theory of Probability. Mathematics. Its
Content, Methods, and Meaning. Vol 2. The M.I.T. Press,
Massachusetts. (1963) pp. 229-264.</li>
<li>Meester, R.: A Natural Introduction to Probability
Theory. Birkhauser, Berlin. (2008)</li>
<li>Meyer, P. L.: Introductory Probability and Statistical
Applications. Addison-Wesley, Massachusetts. (1972)</li>
<li>Ross, S. M: Introduction to Probability and Statistics foe
Engineers and Scientists. Elsevier Academic Press, San
Diego. (2004)</li>
<li>Skorokhod, A. V.: Basic Principles and Applications of Probability
Theory. Springer-Verlag, Berlin. (2005)</li>
<li>Soong, T. T.: Fundamentals of Probability and Statistics for
Engineers. John Wiley &amp; Sons Ltd. (2004)</li>
<li>Stoyanov, J.: Counterexamples in Probability. John Wiley &amp;
Sons. (1997)</li>
</ol>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Nomenclatura y definiciones previas. Sean \(A\) y \(B\) eventos.
</p>
<ol class="org-ol">
<li>Escribiremos \(A^c := \{\omega \in \Omega : \omega \notin A\}\) para
designar al evento que no ocurre \(A\). El evento \(A^c\) se llama el
complemento de \(A\).</li>
<li>Escribiremos \(A \cup B := \{\omega \in \Omega : \omega \in A\) o $
&omega; &isin; B\}$ para designar al evento que ocurre al menos uno de
los eventos \(A\) o \(B\). El evento \(A \cup B\) se llama la unión de
\(A\) y \(B\).</li>
<li>Escribiremos \(A \cap B := \{\omega \in \Omega : \omega \in A\) y $
&omega; &isin; B\}$ para designar al evento ocurren ambos \(A\) y \(B\). El
evento \(A \cap B\) se llama la intersección de \(A\) y \(B\).</li>
</ol>
<p class="footpara">
A veces escribiremos \(A  \setminus  B\) en lugar de \(A \cap B^c\),
esto es, el evento que \(A\) ocurre, pero \(B\) no lo hace. Cuando dos
eventos \(A\) y \(B\) no tienen elementos en común, esto es \(A \cap B =
\emptyset\), diremos que \(A\) y \(B\) son disjuntos. Una colección de eventos
\(A_1, A_2, \dots\) se dice disjunta dos a dos, si A<sub>i</sub> &cap; A<sub>j</sub> =
&empty; &forall; i &ne; j$.
</p>
<ol class="org-ol">
<li>\(\Omega \in \mathcal{A}\),</li>
<li>\(A \in \mathcal{A} \implies A^c \in \mathcal{A}\),</li>
<li>\(A, B \in \mathcal{A} \implies A \cup B \in \mathcal{A}\).</li>
</ol></div></div>


</div>
</div></div>
<div id="postamble" class="status">
Last update: 2019-03-17
</div>
</body>
</html>
