<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-03-18 Mon 00:16 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Variables aleatorias</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/res/org.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "left",
        displayIndent: "0",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "%LINEBREAKS" },
                        webFont: "%FONT"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "%LINEBREAKS" },
              font: "%FONT"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "%AUTONUMBER"},
               MultLineWidth: "%MULTLINEWIDTH",
               TagSide: "right",
               TagIndent: "%TAGINDENT"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_CHTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Variables aleatorias</h1>
<div id="outline-container-org6535c3d" class="outline-2">
<h2 id="org6535c3d">Variables aleatorias</h2>
<div class="outline-text-2" id="text-org6535c3d">
<p>
Sea \((\Omega, \mathcal{A},\mathbb{P})\) un espacio de probabilidad. Una variable aleatoria sobre &Omega; es una función
X : &Omega; &rarr; \Re  tal que para todo x &isin; \Re}
\{X &le; x\} := \{&omega; &isin; &Omega; : X(&omega;) &le; x\} &isin; A, 
i.e., para to do x &isin; \Re el evento \{X &le; x\} tiene asignada probabilidad. La función de distribu
ción F}
X
</p>
<pre class="example">
R \rightarrow [0, 1] de la variable aleatoria X se define por

</pre>
<p>
F<sub>X</sub>(x) := \mathbb{P}(X &le; x).
Cálculo de probabilidades. La función de distribución resume (y contiene) toda la in
formación relevante sobre de la variable aleatoria. Para ser más precisos, para cada pareja de
números reales a &lt; b vale que
1
\mathbb{P}(a &lt; X &le; b) = F
X
(b) − F
X
(a). (1)
</p>
</div>
<div id="outline-container-orge891467" class="outline-5">
<h5 id="orge891467">Ejemplos</h5>
</div>
<div id="outline-container-org6354861" class="outline-5">
<h5 id="org6354861">Ejemplo 1.1 (Dado equilibrado).</h5>
<div class="outline-text-5" id="text-org6354861">
<p>
Sea X el resultado del lanzamiento de un dado equilibrado.
Los posibles valores de X son 1, 2, 3, 4, 5, 6. Para cada k &isin; \}1, 2, 3, 4, 5, 6{\} la probabilidad de
que X tome el valor k es 1 / 6.
</p>

<p>
Sea x &isin; \Re} . Si x &lt; 1 es evidente que \mathbb{P}(X &le; x) = 0. Si k &le; x &lt; k + 1 para algún
k &isin; \{1}, 2, 3, 4, 5{\} la probabilidad del evento \{X &le; x\} es la probabilidad de observar un valor
menor o igual que k y en consecuencia, \mathbb{P}(X &le; x) = k/}6. Finalmente, si x &ge; 6 es evidente
que \mathbb{P}(X &le; x) = 1.
</p>

<p>
x
1/6
2/6
3/6
4/6
5/6
1
1 2 30 4 5 6
Figura 1: Gráfico de la función de distribución del resultado de lanzar un dado equilibrado.
Por lo tanto, la función de distribución de X se puede expresar del siguiente modo
F<sub>X</sub>(x) =
6
X
{k=1}
1
6
1\{k &le; x\}.
1
Basta observar que \{X &le; a\} &sub; \{X &le; b\} y usar las propiedades de la probabilidad. De la igualdad
\{a &lt; X &le; b\} = \{X &le; b\}  &setminus;  \{X &le; a\} se deduce que \mathbb{P}(a &lt; X &le; b) = \mathbb{P}(X &le; b ) − \mathbb{P}(X &le; a) = F}
X
(b) − F
X
(a).
3
</p>
</div>
</div>
<div id="outline-container-orgb1b8fa2" class="outline-5">
<h5 id="orgb1b8fa2">Ejemplo 1.2 (Fiabilidad).</h5>
<div class="outline-text-5" id="text-orgb1b8fa2">
<p>
Un problema fundamental de la ingeniería es el problema de la
fiabilidad. Informalmente, la fiabilidad de un sistema se define como
su capacidad para cumplir ciertas funciones prefijadas. Esta propiedad
se conserva durante un período de tiempo hasta que ocurre una fa lla
que altera la capacidad de trabajo del sistema. Por ejemplo: rupturas
y cortocircuitos; fracturas, deformaciones y atascamientos de piezas
mecánicas; el fundido o la combustión de las componentes de un
circuito.
</p>

<p>
Debido a que las fallas pueden ocurrir como hechos casuales, podemos
considerar que el tiempo de funcionamiento, T , hasta la aparición de
la primer falla es una variable aleatoria a valores no negativos.
</p>

<p>
La fiabilidad de un sistema se caracteriza por su función intensidad de fallas &lambda; ( t). Esta 
función temporal tiene la siguiente propiedad: cuando se la multiplica por dt se obtiene la
probabilidad condicional de que el sistema sufra una falla durante el intervalo de tiempo
(t, t + dt] sabiendo que hasta el momento t funcionaba normalmente. Si se conoce la función
&lambda; ( t) se puede hallar la ley de distribución de probabilidades de T .
Para calcular la función de distribución de T estudiaremos dos eventos: A := \{T &gt; t\} (el
sistema funciona hasta el momento t) y B := \{t &lt; T &le; t + dt{\} (el sistema sufre una falla en
el intervalo de tiempo (t, t + dt]). Como B &sub; A, tenemos que \mathbb{P}(B) = \mathbb{P}(B &cap; A) y de la regla
del producto se deduce que
\mathbb{P}(B) = \mathbb{P}(B | A)\mathbb{P}(A). (2)
Si la función de distribución de T admite derivada continua, salvo términos de segundo orden
que se pueden despreciar, la probabilidad del evento B se puede expresar en la forma
\mathbb{P}(B) = \mathbb{P}(t &lt; T &le; t + dt) = F
T
(t + dt) − F
T
(t) = F}
′
T
(t)dt. (3)
La probabilidad del evento A se puede expresar en la forma
\mathbb{P}(A) = \mathbb{P}(T &gt; t) = 1 − \mathbb{P}(T &le; t) = 1 − F 
T
(t). (4)
Finalmente, la probabilidad condicional \mathbb{P}(B | A) se expresa mediante la función intensidad de
fallas &lambda;(t):
\mathbb{P}(B | A) = &lambda;(t)dt (5)
Sustituyendo las expresiones (3)-(5) en la fórmula (2) obtenemos, después de dividir ambos
miembros por dt, una ecuación diferencial de primer orden para F}
T
(t)
F
′
T
(t) = &lambda;(t)(1 − F
T
(t)). (6)
Debido a que la duración del servicio del sistema no puede ser negativa, el evento \{T &le; 0{\} es
imposible. En consecuencia, F}
T
(0) = 0. Integrando la ecuación diferencial (6) con la condición
inicial F (0) = 0, obtenemos
2
F
T
(t) = 1 − exp
</p>

<p>
−
Z
t<sub>0</sub>
&lambda; ( s ) ds

. (7)
2
F
′
T
(t) = &lambda;(t)(1 − F
T
(t)) \iff}
F
′
T
(t)
1 − F
T
(t)
= &lambda;(t) \iff}
d
dt
log(1 − F
T
(t)) = − &lambda; (t)
\iff log(1 − F}
T
(t)) = −}
Z
t<sub>0</sub>
&lambda; ( s ) ds + C \iff F
T
(t) = 1 − exp
„
−
Z
t<sub>0</sub>
&lambda; ( s ) ds + C
«
.
Usando que F}
T
(0) = 0 se deduce que C = 0.
4
</p>
</div>
</div>
<div id="outline-container-org14eff89" class="outline-5">
<h5 id="org14eff89">Nota Bene</h5>
<div class="outline-text-5" id="text-org14eff89">
<p>
El desarrollo anterior presupone que la función intensidad de fallas &lambda;(t) verifica}
las siguientes condiciones: (1) &lambda;(t) &ge; 0 para todo t &gt; 0 y (2)
R
&infin;
0
&lambda; ( t ) dt = +{&infin;}.
</p>
</div>
</div>
<div id="outline-container-orgdca0550" class="outline-5">
<h5 id="orgdca0550">Ejemplo 1.3 (Fiabilidad)</h5>
<div class="outline-text-5" id="text-orgdca0550">
<p>
Se estipula que la duración de servicio de un sistema automático}
debe ser t<sub>0</sub>
. Si durante ese período el sistema falla, se lo repara y se lo utiliza hasta que sirva
el plazo estipulado. Sea S el tiempo de funcionamiento del sistema después de la primera
reparación. Quere mos hallar la función de distribución de S}.
En primer lugar observamos que la relación entre la variable aleatoria S y el instante T}
en que ocurre la primera falla del sistema es la siguiente
S = máx(t}
0
− T, 0) =

t<sub>0</sub>
− T si T &le; t<sub>0</sub>
,
0 si T &gt; t}
0
.
Sea F}
S
(s) la función de distribución de la variable S}. Es claro que para s &lt; 0, F}
S
(s) = 0 y
que para s &ge; t}
0
, F}
S
(s) = 1. Lo que falta hacer es analizar el compor
tamiento de F}
S
sobre el
intervalo 0 &le; s &lt; t<sub>0</sub>
. Sea s &isin; [0, t}
0
)
F
S
(s) = \mathbb{P}(S &le; s) = \mathbb{P}(máx(t<sub>0</sub>
− T, 0) &le; s) = \mathbb{P}(t}
0
− T &le; s, 0 &le; s ) 
= \mathbb{P}(t<sub>0</sub>
− T &le; s) = \mathbb{P}(t}
0
− s &le; T ) = exp
</p>

<p>
−
Z
t<sub>0</sub>
−s
0
&lambda; ( t ) dt

,
donde &lambda;(t) es la función intensidad de fallas del sistema.
1
exp
/"
−
R
t<sub>0</sub>
0
&lambda; ( t ) dt
''
t<sub>0</sub>
s{0}
Figura 2: Gráfico de la función de distribución de la variable aleatoria S}.
Por lo tanto,
F
S
(s) = exp
</p>

<p>
−
Z
t<sub>0</sub>
−s
0
&lambda; ( t ) dt

1\{0 &le; s &lt; t<sub>0</sub>
\} + 1} \{s &ge; t<sub>0</sub>
\}.
</p>
</div>
</div>
<div id="outline-container-org68a3f91" class="outline-5">
<h5 id="org68a3f91">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org68a3f91">
<ol class="org-ol">
<li>Sea X una variable aleatoria con función de distribución F<sub>X</sub>(x). Mostrar que para cada</li>
</ol>
<p>
pareja de números reales a &lt; b vale que:
\mathbb{P}(a &le; X &le; b) = F
X
(b) − F
X
(a) + \mathbb{P}(X = a) (8)
\mathbb{P}(a &le; X &lt; b) = F
X
(b) − \mathbb{P}(X = b) − F
X
(a) + \mathbb{P}(X = a) (9)
\mathbb{P}(a &lt; X &lt; b) = F
X
(b) − \mathbb{P}(X = b) − F
X
(a) (10)
5
Notar que las fórmulas (8)-(10), junto con (1), muestran como calcular l a probabilidad de
que la variable aleatoria X tome valores en un intervalo de extremos a y b y contienen una
advertencia sobre la acumulación de masa positiva en alguno de los dos extremos.
</p>
</div>
</div>
<div id="outline-container-org3f84eb8" class="outline-3">
<h3 id="org3f84eb8">Propiedades de la función de distribución</h3>
<div class="outline-text-3" id="text-org3f84eb8">
</div>
<div id="outline-container-org50d228d" class="outline-5">
<h5 id="org50d228d">Lema 1.4.</h5>
<div class="outline-text-5" id="text-org50d228d">
<p>
Sea X : &Omega; &rarr; \Re  una variable aleatoria. La función de distribución de X, F<sub>X</sub>(x) =
\mathbb{P}(X &le; x), tiene las siguientes propiedades:}
(F1) es no decreciente{: si x
1
&le; x
2
, entonces F}
X
(x
1
) &le; F
X
(x
2
);
(F2) es continua a derecha{: para todo x
0
&isin; R vale que lím
x{↓}x
0
F<sub>X</sub>(x) = F}
X
(x
0
);
(F3) lim<sub>x &rarr;−&infin;</sub>
F<sub>X</sub>(x) = 0 y lim<sub>x &rarr;&infin;</sub>
F<sub>X</sub>(x) = 1.
</p>
</div>
</div>
<div id="outline-container-org3db65cf" class="outline-5">
<h5 id="org3db65cf">Demostración.</h5>
<div class="outline-text-5" id="text-org3db65cf">
<p>
La propiedad (F1) se deduce de la fórmula (1).
La propiedad (F2) es consecuencia del axioma de continuidad de la medida de probabilidad
P. Se considera una sucesión decreciente de números positivos que converge a 0, &epsilon;
1
&gt; &epsilon;
2
&gt;
dots &gt; 0, arbitraria, pero fija y se definen eventos A}
n
= \{x}
0
&lt; X &le; x
0
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n
\. Se observa que}
A<sub>1</sub>
&sup; A<sub>2</sub>
&sup;  &ctdot;  y
T<sub>n</sub>{&isin;{N
A<sub>n</sub>
= &empty;}:
0 = lim<sub>n  &rarr; &infin;</sub>
\mathbb{P}(A<sub>n</sub>
) = lim<sub>n  &rarr; &infin;</sub>
\mathbb{P}(x}
0
&lt; X &le; x
0
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n
) = lim<sub>n  &rarr; &infin;</sub>
F  ( x
0
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n
) − F (x
0
).
Por lo tanto,
F  ( x
0
) = lim<sub>n  &rarr; &infin;</sub>
F  ( x
0
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n
).
Las propiedades (F3) se demuestran de manera similar.
</p>
</div>
</div>
<div id="outline-container-org5d068d3" class="outline-5">
<h5 id="org5d068d3">Observación 1.5.</h5>
<div class="outline-text-5" id="text-org5d068d3">
<p>
Si se define
F
X
(x
−
0
) := lim<sub>x</sub>{↑}x
0
F<sub>X</sub>(x), 
entonces F}
X
(x
−
0
) = \mathbb{P}(X &lt; x}
0
). Por lo tanto, \mathbb{P}(X = x
0
) = F}
X
(x
0
) − F
X
(x
−
0
). En particular,
si F}
X
(x) es continua en x
0
, entonces \mathbb{P}(X = x
0
) = 0. Si \mathbb{P}(X = x
0
) &gt; 0, entonces F}
X
(x) es
discontinua en x
0
y su discontinuidad es un salto de altura \mathbb{P}(X = x
0
) &gt; 0.
</p>
</div>
</div>
<div id="outline-container-orgbaea1c2" class="outline-5">
<h5 id="orgbaea1c2">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-orgbaea1c2">
<ol class="org-ol">
<li>Sea \((\Omega, \mathcal{A},\mathbb{P})\) un espacio de probabilidad y X : &Omega; &rarr; \Re  una variable aleatoria con función}</li>
</ol>
<p>
de distribución F}
X
(x).
(a) Mostrar que
lim<sub>x &rarr;−&infin;</sub>
F<sub>X</sub>(x) = 0 y lim<sub>x &rarr;&infin;</sub>
F<sub>X</sub>(x) = 1.
6
(Sugerencia. Considerar sucesiones de eventos B
n
= \{X &le; −n\} y C}
n
= \{X &le; n\, n &isin; N , y
utilizar el axioma de continuidad de la medida de probabilidad P.)
(b) Mostrar que
lim<sub>x</sub>{↑}x
0
F<sub>X</sub>(x) = \mathbb{P}(X &lt; x}
0
).
(Sugerencia. Observar que si x ↑ x 
0
, entonces \{X &le; x\} ↑ \{X &lt; x
0
\} y utilizar el axioma de}
continuidad de la medida de probabilidad P.)
</p>
</div>
</div>
</div>
<div id="outline-container-org612ef8c" class="outline-3">
<h3 id="org612ef8c">Clasificación de variables aleatorias</h3>
<div class="outline-text-3" id="text-org612ef8c">
<p>
En todo lo que sigue, X designa una variable ale atoria definida sobre un espacio de
probabilidad \((\Omega, \mathcal{A},\mathbb{P})\) y F}
X
(x) := \mathbb{P}(X &le; x) su función de distribución.
</p>
</div>
<div id="outline-container-orga1b13b1" class="outline-5">
<h5 id="orga1b13b1">Nota Bene</h5>
<div class="outline-text-5" id="text-orga1b13b1">
<p>
Al observar el gráfico de una función de distribución lo primero que llama la}
atención son sus saltos y sus escalones.
´
Atomos. Diremos que a &isin; \Re es un átomo de F }
X
(x) si su peso es positivo: \mathbb{P}(X = a) =
F
X
(a) − F
X
(a{−}) &gt; 0.
El conjunto de todos los átomos de F}
X
(x): A = \{a &isin; \Re : F}
X
(a) − F
X
(a{−}) &gt; 0{\, coincide
con el conjunto de todos los puntos de discontinuidad de F}
X
(x). El peso de cada átomo
coincide con la longitud del salto dado por la función de distribución en dicho átomo. En
consecuencia, existen a lo sumo un átomo de probabilidad &gt;}
1
2
, a lo sumo dos átomos de
probabilidad &gt;}
1
3
, etcétera. Por lo tanto, es posible reordenar los átomos en una sucesión
a
1
, a
2
, &hellip; tal que \mathbb{P}(X = a
1
) &ge; \mathbb{P}(X = a
2
) &ge;  &ctdot;  . En otras palabras, existen a lo sumo}
numerables átomos.
La propiedad de &sigma;}-aditividad de la medida de probabilidad P implica que el peso total
del conjunto A no puede exceder la unidad:
P
a{\inA}
\mathbb{P}(X = a) &le; 1.
</p>
</div>
</div>
<div id="outline-container-orga6bf9f3" class="outline-5">
<h5 id="orga6bf9f3">Definición 1.6 (Variables discretas). Diremos que X es una variable aleatoria discreta si</h5>
<div class="outline-text-5" id="text-orga6bf9f3">
<p>
X
a{\inA}
\mathbb{P}(X = a) = 1.
En tal caso, la función p
X
</p>
<pre class="example">
A \rightarrow \Re definida por p

</pre>
<p>
X
(x) = \mathbb{P}(X = x) se denomina la función}
de probabilidad de X.
Escalones. Sea X una variable aleatoria discreta. Si a}
1
&lt; a
2
son dos átomos consecutivos,
entonces F}
X
(x) = F}
X
(a
1
) para todo x &isin; (a
1
, a
2
). En otras palabras, la función de distribución}
de una variable aleatoria discreta debe ser constante entre saltos consecutivos.
Si no lo fuera, deberían existir dos números x
1
&lt; x
2
contenidos en el intervalo (a
1
, a
2
)
tales que F}
X
(x
1
) &lt; F}
X
(x
2
). En tal caso,
\mathbb{P}(X &isin; A &cup; (x
1
, x
2
]) = \mathbb{P}(X &isin; A}) + \mathbb{P}(x
1
&lt; X &le; x
2
) =
X
a{\inA}
\mathbb{P}(X = a) + F
X
(x
2
) − F
X
(x
1
)
= 1 + F}
X
(x
2
) − F
X
(x
1
) &gt; 1.
lo que constituye un absurdo.
7
</p>
</div>
</div>
<div id="outline-container-org88c44d0" class="outline-5">
<h5 id="org88c44d0">Definición 1.7 (Variables continuas). Diremos que X es una variable aleatoria continua si</h5>
<div class="outline-text-5" id="text-org88c44d0">
<p>
su función de distribución es continua.
</p>
</div>
</div>
<div id="outline-container-org1028f40" class="outline-5">
<h5 id="org1028f40">Definición 1.8 (Variables mixtas). Diremos que X es una variable aleatoria mixta si no es}</h5>
<div class="outline-text-5" id="text-org1028f40">
<p>
continua ni discreta.
</p>
</div>
</div>
<div id="outline-container-org40ccac1" class="outline-5">
<h5 id="org40ccac1">Definición 1.9 (Variables absolutamente continuas). Diremos que X es absolutamente con}</h5>
<div class="outline-text-5" id="text-org40ccac1">
<p>
tinua si exi ste una función (medible) f}
X
</p>
<pre class="example">
R \rightarrow R}

</pre>
<ul class="org-ul">
<li></li>
</ul>
<p>
, llamada densidad de X, tal que cua
lesquiera sean −&infin; &le; a &lt; b &lt; &infin; vale que
\mathbb{P}(a &lt; X &le; b) =}
Z
b
a
f<sub>X</sub>(x) dx. (11)
En particular, para cada x &isin; \Re}, vale que
F<sub>X</sub>(x) = \mathbb{P}(X &le; x) =
Z
x
−&infin;
f
X
(t) dt. (12)
</p>
</div>
</div>
<div id="outline-container-orga8c0e4f" class="outline-5">
<h5 id="orga8c0e4f">Nota Bene</h5>
<div class="outline-text-5" id="text-orga8c0e4f">
<p>
Notar que de (12) se deduce que}
Z
&infin;
−&infin;
f<sub>X</sub>(x)dx = 1.
Aplicando en (12) el teorema Fundamental del Cálculo Integral, se obtiene que si X es abso
lutamente continua, F<sub>X</sub>(x) es una función continua para todo x, y su derivada es f<sub>X</sub>(x) en
todos los x donde f
X
es continua.
Como la expresión /"absolutamente continua"/es demasiado larga, se suele hablar simple
mente de /"distribuciones continuas''. Sin embargo, hay que tener en cuenta que el hecho de
que F}
X
sea una función continua, no implica que la distribución de X sea absolutamente con}
tinua: hay funciones monótonas y continuas, que sin embargo no son la primitiva de ninguna
función. (Para más detalles consultar el ejemplo sobre distribuciones tipo Cantor que está en
Feller Vol II, p.35-36).
Interpretación intuitiva de la densidad de probabilidad. Sea X una variable aleatoria}
absolutamente continua con función densidad f<sub>X</sub>(x) continua. Para cada &epsilon; &gt; 0 pequeño y
para x &isin; \Re vale que
\mathbb{P}(x − &epsilon;/}2 &lt; X &le; x + &epsilon;/}2) =}
Z
x{+}ε/{2}
x{−}&epsilon;/{2}
f
X
(t) dt &asymp; f}
X
(x)&epsilon;.
Dicho en palabras, la probabilidad de que el valor de X se encuentre en un intervalo de
longitud &epsilon; centrado en x es aproximadamente f<sub>X</sub>(x)&epsilon;}.
</p>
</div>
</div>
<div id="outline-container-org3741887" class="outline-5">
<h5 id="org3741887">Ejemplos</h5>
</div>
<div id="outline-container-orgbba2437" class="outline-5">
<h5 id="orgbba2437">Ejemplo 1.10.</h5>
<div class="outline-text-5" id="text-orgbba2437">
<p>
El resultado, X, del lanzamiento de un dado equilibrado (ver Ejemplo 1.1) 
es}
una variable aleatoria discreta. Esto resulta evidente de observar que el gráfico de la función
de distribución de X (ver Figura 1) que tiene la forma de una escalera con saltos de altura
1 / 6 en los puntos 1, 2, 3, 4, 5, 6. Dicho en otras palabras, toda la masa de la variable aleatoria
X está concentrada en el conjunto de los átomos de F
X
, A = \1, 2, 3, 4, 5, 6{\}.
8
</p>
</div>
</div>
<div id="outline-container-org84a1670" class="outline-5">
<h5 id="org84a1670">Ejemplo 1.11</h5>
<div class="outline-text-5" id="text-org84a1670">
<p>
(Números al azar). El resultado de /"sortear"/un número al azar sobre el}
intervalo (0, 1) es una variable aleatoria absolutamente continua. La probabilidad del evento
U &le; u es igual a la longitud del intervalo (−&infin;, u] &cap; (0, 1).
Notar que cuando u &le; 0 el intervalo (−&infin;, u] &cap; (0, 1) se reduce al conjunto vacío que por
definición tiene longitud 0. Por otra parte, para cualquier u &isin; (0, 1) se tiene que (−&infin;, u] &cap;}
(0, 1) = (0, u) y en consecuencia \mathbb{P}(U &le; u
) = u; mientras que si u &ge; 1, (−&infin;, u]&cap;(0, 1) = (0, 1)
de donde sigue que \mathbb{P}(U &le; u) = 1. Por lo tanto, la función de distribución de U es
F
U
(u) = u{1{\}0 &le; u &lt; 1{\} + 1\{u &ge; 1{\}.
1
1
u{0}
Figura 3: Gráfico de la función de distribución del resultado de /"sortear"/un número al azar.
Derivando, respecto de u, la función de distribución F}
U
(u) se obtiene una función densidad
para U}:
f
U
(u) = 1{\}0 &lt; u &lt; 1{\}.
</p>
</div>
</div>
<div id="outline-container-orgc145af0" class="outline-5">
<h5 id="orgc145af0">Nota Bene</h5>
<div class="outline-text-5" id="text-orgc145af0">
<p>
Sortear un número al azar sobre el intervalo (0, 1) es un caso particular de}
una familia de variables aleatorias denominadas uniformes}. Una variable aleatoria X, definida
sobre un espacio de probabilidad (&Omega;, \mathcal{A},\mathbb{P}), se denomina uniformemente distribuida sobre el}
intervalo (a, b), donde a &lt; b, si X es absolutamente continua y admite una función densidad}
de la forma
f<sub>X</sub>(x) =
1
b − a
1\{x &isin; (a, b)\}.
En tal caso escribiremos X &sim; \mathcal{U} (a, b).
Comentario. En la Sección 1.4 mostraremos que todas las variables aleatorias se pueden}
construir utilizando variables aleatorias uniformemente distribuidas sobre el intervalo (0, 1).
</p>
</div>
</div>
<div id="outline-container-org333987c" class="outline-5">
<h5 id="org333987c">Ejemplo 1.12.</h5>
<div class="outline-text-5" id="text-org333987c">
<p>
El tiempo, T , de funcionamiento hasta la aparición de la primera falla para}
un sistema con función intensidad de fallas continua &lambda;(t) (ver Ejemplo 1.2) 
es una variable
aleatoria absolutamente continua que admite una densidad de la forma
f
T
(t) = &lambda;(t) exp
</p>

<p>
−
Z
t<sub>0</sub>
&lambda; ( s ) ds

1\{t &gt; 0} \. (13) 
.
9
\hypertarget{pfa}
</p>
</div>
</div>
<div id="outline-container-orgb092afa" class="outline-5">
<h5 id="orgb092afa">Nota Bene</h5>
<div class="outline-text-5" id="text-orgb092afa">
<p>
algunos casos particulares del Ejemplo 1.12. 
El comportamiento de la}
densidad (13) depende de la forma particular de la función intensidad de fallas &lambda;(t). En lo
que sigue mostraremos algunos casos particulares.
Exponencial de intensidad &lambda;}. Se obtiene poniendo &lambda;(t) = &lambda;{1{\}t &ge; 0{\, donde &lambda; es una}
constante positiva, arbitraria pero fija.
f
T
(t) = &lambda; exp (−{&lambda; t}) 1\{t &gt; 0{\. (14)
.
Weibull de parámetros c y &alpha;}. Se obtiene p
oniendo &lambda;(t) =}
c
&alpha;

t
&alpha;

c{−{1
1\{t &ge; 0}\, donde
c &gt; 0 y &alpha; &gt; 0. En este caso, la densidad (13) adopta la forma}
f
T
(t) =
c
&alpha;
</p>

<p>
t
&alpha;

c{−{1
exp
</p>

<p>
−
</p>

<p>
t
&alpha;

c

. (15)
0 0.5 1 1.5 2 2.5 3 3.5 4
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Figura 4: Gráficos de las densidades Weibull de parámetro de escala &alpha; = 1 y parámetro de
forma: c = 1, 2, 4: en línea sólida c = 1; en línea quebrada c = 2 y en línea punteada c = 4.
Notar que la exponencial de intensidad &lambda; es un caso especial de la Weibull puesto que (14) se
obtiene de (15) poniendo c = 1 y &alpha; = &lambda;}
−{1}
.
</p>
</div>
</div>
<div id="outline-container-orgc653a5f" class="outline-5">
<h5 id="orgc653a5f">Ejemplo 1.13.</h5>
<div class="outline-text-5" id="text-orgc653a5f">
<p>
La variable aleatoria, S, considerada en el Ejemplo 1.3 es una variable aleato
ria mixta (ver Figura 2) porque no es discreta ni continua. Tiene un único átomo en s = 0 y
su peso es exp

−
R
t<sub>0</sub>
0
&lambda; ( x ) dx

.
10
\hypertarget{pfb}
</p>
</div>
</div>
</div>
<div id="outline-container-orgf6ec5e5" class="outline-3">
<h3 id="orgf6ec5e5">Cuantiles</h3>
<div class="outline-text-3" id="text-orgf6ec5e5">
</div>
<div id="outline-container-orgad95fde" class="outline-5">
<h5 id="orgad95fde">Definición 1.14.</h5>
<div class="outline-text-5" id="text-orgad95fde">
<p>
Sea &alpha; &isin; (0}, 1)}. Un cuantil}-{&alpha; de X es cualquier número x}
&alpha;
&isin; R tal que
\mathbb{P}(X &lt; x
&alpha;
) &le; &alpha; y &alpha; &le; \mathbb{P}(X &le; x}
&alpha;
). (16)
</p>
</div>
</div>
<div id="outline-container-orgc300791" class="outline-5">
<h5 id="orgc300791">Observación 1.15. Notar que las desigualdades que caracterizan a los cuantiles-{&alpha; se pueden}</h5>
<div class="outline-text-5" id="text-orgc300791">
<p>
reescribir de la siguiente manera
F
X
(x
&alpha;
) − \mathbb{P}(X = x
&alpha;
) &le; &alpha; y &alpha; &le; F}
X
(x
&alpha;
). (17)
Por lo tanto, si F<sub>X</sub>(x) es continua, x}
&alpha;
es un cuantil &alpha; si y sólo si
F
X
(x
&alpha;
) = &alpha;. (18)
Interpretación /"geométrica"/del cuantil- &alpha; . Si X es una variable aleatoria absoluta
mente continua con función de densidad f<sub>X</sub>(x) el cuantil-{&alpha; de X es la única solución de la
ecuación
Z
x
&alpha;
−&infin;
f<sub>X</sub>(x)dx = &alpha;.
Esto significa que el cuantil-{&alpha; de X es el único punto sobre el eje de las abscisas a cuya
izquierda el área bajo la función de densidad f<sub>X</sub>(x) es igual a &alpha;}.
</p>
</div>
</div>
<div id="outline-container-orgdc911ce" class="outline-5">
<h5 id="orgdc911ce">Nota Bene</h5>
<div class="outline-text-5" id="text-orgdc911ce">
<p>
Sea x &isin; \Re} . Las desigualdades (17) significan que x es u n cuantil&alpha; si y sólo si 
&alpha; &isin; [ F  ( x) − \mathbb{P}(X = x ) , F  ( x)]
</p>
</div>
</div>
<div id="outline-container-org1c89f35" class="outline-5">
<h5 id="org1c89f35">Nota Bene</h5>
<div class="outline-text-5" id="text-org1c89f35">
<p>
El cuantil-{&alpha; siempre existe. Sea &alpha; &isin; (0, 1), la existencia del cuantil &alpha; se deduce}
analizando el conjunto R}
&alpha;
X
= \{x &isin; \Re : &alpha; &le; F}
X
(x)\}.
</p>
<ol class="org-ol">
<li>R}</li>
</ol>
<p>
&alpha;
X
es no vacío porque lim<sub>x &rarr;&infin;</sub>
F<sub>X</sub>(x) = 1.
</p>
<ol class="org-ol">
<li>R}</li>
</ol>
<p>
&alpha;
X
es acotado inferiormente porque lim<sub>x &rarr;−&infin;</sub>
F<sub>X</sub>(x) = 0.
</p>
<ol class="org-ol">
<li>Si x</li>
</ol>
<p>
0
&isin; \Re
&alpha;
X
, entonces [x
0
, +{&infin;) &sub; R
&alpha;
X
porque F}
X
(x) es no decreciente.
</p>
<ol class="org-ol">
<li>ínf R}</li>
</ol>
<p>
&alpha;
X
&isin; \Re
&alpha;
X
porque existe una sucesión \{x}
n
</p>
<pre class="example">
n \in N\} \subset R}

</pre>
<p>
&alpha;
X
tal que x
n
↓ ínf R
&alpha;
X
y
F<sub>X</sub>(x) es una función continua a derecha:
&alpha; &le; lím
{n &rarr; &infin;}
F
X
(x
n
) = F}
X

lim<sub>n  &rarr; &infin;</sub>
x
n

= F}
X
(ínf R}
&alpha;
X
) .
De las propiedades anteriores se deduce que
R
&alpha;
X
= [ínf R}
&alpha;
X
, +{&infin;) = [mín R
&alpha;
X
, +{&infin;) .
Hay dos casos posibles: (a) F}
X
(mín R}
&alpha;
X
) = &alpha; o (b) F}
X
(mín R}
&alpha;
X
) &gt; &alpha;}.
(a) Si F}
X
(mín R}
&alpha;
X
) = &alpha;, entonces \mathbb{P}(X &lt; mín R}
&alpha;
X
) = &alpha; − P}(X = mín R}
&alpha;
X
) &le; &alpha;} .
11
\hypertarget{pfc}
(b) Si F}
X
(mín R}
&alpha;
X
) &gt; &alpha;, entonces
\mathbb{P}(X &lt; x) &lt; &alpha; &forall; x &lt; mín R
&alpha;
X
(19)
porque sino existe un x &lt; mín R}
&alpha;
x
tal que &alpha; &le; P}(X &lt; x) &le; F<sub>X</sub>(x) y por lo tanto,
x &isin; R
&alpha;
X
lo que constituye un absurdo.
De (19) se deduce que \mathbb{P}(X &lt; mín R}
&alpha;
X
) = lim<sub>x</sub>{↑{mín R 
&alpha;
X
F<sub>X</sub>(x) &le; &alpha;} .
En cualquiera de los dos casos
x
&alpha;
= mín \{x &isin; \Re : F}
X
(x) &ge; &alpha;\} (20)
es un cuantil- &alpha; .
</p>
</div>
</div>
<div id="outline-container-orgef810b8" class="outline-5">
<h5 id="orgef810b8">Nota Bene</h5>
<div class="outline-text-5" id="text-orgef810b8">
<p>
Si F
X
es discontinua, (18) no tiene siempre solución; y por eso es mejor tomar
(16) como definición. Si F}
X
es estrictamente creciente, los cuantiles son únicos. Pero si no,
los valores que satisfacen (18) forman un intervalo.
Cuartiles y mediana. Los cuantiles correspondientes a &alpha; = 0.25, 0.50 y 0.75 son respecti
vamente el primer, el segundo y tercer cuartil}. El segundo cuartil es la mediana.
</p>
</div>
</div>
<div id="outline-container-org24c2cee" class="outline-5">
<h5 id="org24c2cee">Ejemplos</h5>
</div>
<div id="outline-container-org0e718e1" class="outline-5">
<h5 id="org0e718e1">Ejemplo 1.16.</h5>
<div class="outline-text-5" id="text-org0e718e1">
<p>
En el Ejemplo 1.1 hemos visto que la función de distribución del resultado}
del lanzamie nto de un dado equilibrado e s una escalera con saltos de altura 1 / 6 en los puntos
1, 2, 3, 4, 5, 6:
F<sub>X</sub>(x) =
5
X
{i=1}
i
6
1 \{i &le; x &lt; i + 1}\} + 1\{6 &le; x\}.
Como la i magen de F}
X
es el conjunto \0, 1 / 6, 2 / 6, 3 / 6, 4 / 6, 5 / 6, 1{\} la ecuación (18) solo tiene
solución para &alpha; &isin; \}1 / 6, 2 / 6, 3 / 6, 4 / 6, 5 / 6{\}. Más aún, para cada i = 1, &hellip; , 5
F<sub>X</sub>(x) =
i
6
\iff x &isin; [i, i + 1).
En otras palabras, para cada i = 1, &hellip; , 5 los cuantiles-{i/}6 de X son el intervalo [i, i + 1). En
particular, /"la"/mediana de X es cualquier punto del intervalo [3, 4).
Para cada &alpha; &isin;

{i-1}
6
,
i
6

, i = 1, &hellip; , 6, el cuantil &alpha; de X es x
&alpha;
= i.
</p>
</div>
</div>
<div id="outline-container-org592f0d0" class="outline-5">
<h5 id="org592f0d0">Ejemplo 1.17.</h5>
<div class="outline-text-5" id="text-org592f0d0">
<p>
Sea T el tiempo de funcionamiento hasta la aparición de la primera falla para}
un sistema con función intensidad de fallas &lambda;(t) = 2{t{1{\}t &ge; 0{\} (ver Ejemplo 1.2). La función
de distribución de T es
F
T
(t) =
</p>

<p>
1 − exp
</p>

<p>
−
Z
t<sub>0</sub>
2{sds}

1\{t &gt; 0}\} =

1 − exp

−t
2

1\{t &gt; 0} \. (21) 
Como F}
T
(t) es continua los cuantiles- &alpha; , &alpha; &isin; (0, 1), se obtienen resolviendo la ecuación (18):
F
T
(t) = &alpha; \iff 1 − exp 

−t
2

= &alpha; \iff t = }
p
− log(1 − &alpha; ) .
Por lo tanto, para cada &alpha; &isin; (0, 1) el cuantil-{&alpha; de T es
t
&alpha;
=
p
− log(1 − &alpha; ) . (22)}
En particular, la mediana de T es t<sub>0.5</sub>
=
p
− log(1 − 0.5) &asymp; 0.8325.
12
\hypertarget{pfd}
</p>
</div>
</div>
<div id="outline-container-org810297b" class="outline-5">
<h5 id="org810297b">Ejemplo 1.18.</h5>
<div class="outline-text-5" id="text-org810297b">
<p>
Se considera un sistema con función intensidad de fallas &lambda;(t) = 2{t{1{\}t &ge; 0{\}.
El sistema debe prestar ser vici os durante 1 hora. Si durante ese período el sistema falla, se lo
repara y se lo vuelve a utiliza hasta que cumpla con el el plazo estipulado. Sea S el tiempo
de funcionamiento (medido en horas) del sistema después de la primera reparación.
En el Ejemplo 1.3 vimos que la función de distribución de S es
F
S
(s) = exp
</p>

<p>
−
Z
1{−s}
0
2{tdt}

1\{0 &le; s &lt; 1}\} + 1\{s &ge; 1\}
= exp

−(1 − s ) 
2

1\{0 &le; s &lt; 1}\} + 1\{s &ge; 1}\, 
y que S es una variable aleatoria mixta (ver Figura 2) con un único átomo en s = 0 cuyo
peso es e
−{1}
. En consecuencia, s = 0 es un cuantil-{&alpha; de S para todo &alpha; &isin;

0, e}
−{1}

. Restringida
al intervalo (0, 1) la función F}
S
(s) es continua y su imagen es el intervalo (e
−{1}
, 1). Por ende,}
para cada &alpha; &isin; (e
−{1}
, 1) el cuantil&alpha; de S se obtiene resolviendo la ecuación F
S
(s) = &alpha;}:
F
S
(s) = &alpha; \iff exp 

−(1 − s ) 
2

= &alpha; \iff −(1 − s ) 
2
= log( &alpha; )
\iff (1 − s ) 
2
= − log( &alpha; ) \iff |{1 − s| =
p
− log( &alpha; )
\iff 1 − s =
p
− log( &alpha; ) \iff 1 −
p
− log( &alpha; ) = s.}
Por lo tanto, para cada &alpha; &isin; (e
−{1}
, 1) el cuantil&alpha; de S es}
s
&alpha;
= 1 −}
p
− log( &alpha; ).
En particular, la mediana de S e s s
0.5
= 1 −}
p
− log(0.5) &asymp; 0.1674.
</p>
</div>
</div>
</div>
<div id="outline-container-org00c2926" class="outline-3">
<h3 id="org00c2926">Construcción de variables aleatorias</h3>
<div class="outline-text-3" id="text-org00c2926">
</div>
<div id="outline-container-orgd1fc471" class="outline-5">
<h5 id="orgd1fc471">Teorema 1.19 (Simulación). Sea F : R &rarr; [0, 1] una función con las siguientes propiedades}</h5>
<div class="outline-text-5" id="text-orgd1fc471">
<p>
(F1) es no decreciente{: si x
1
&le; x
2
, entonces F (x
1
) &le; F (x
2
);
(F2) es continua a derecha{: para todo x
0
&isin; R vale que lím
x{↓}x
0
F  ( x) = F  ( x
0
);
(F3) lim<sub>x &rarr;−&infin;</sub>
F  ( x) = 0 y lím}
{x&rarr;&infin;}
F  ( x) = 1.
Existe una variable aleatoria X tal que F (x) = \mathbb{P}(X &le; x).
Esquema de la demostración.
1
o
) Definir la inversa generalizada de F mediante
F
−{1}
(u) := mín\{x &isin; \Re : u &le; F (x)\, u &isin; (0, 1).
2
o
) Definir X mediante
X := F
−{1}
(U), donde U &sim; \mathcal{U} (0, 1).
3
o
) Observar que vale la equivalencia (inmediata) F}
−{1}
(u) &le; x ⇔ u &le; F (x) y deducir que
\mathbb{P}(X &le; x) = \mathbb{P}(F
−{1}
(U) &le; x) = \mathbb{P}(U &le; F (x)) = F (x).
</p>
</div>
</div>
<div id="outline-container-org9d59fa2" class="outline-5">
<h5 id="org9d59fa2">Observación 1.20. Si la función F del enunciado del Teorema 1.19 es continua, la inversa}</h5>
<div class="outline-text-5" id="text-org9d59fa2">
<p>
generalizada es simplemente la inversa.
13
\hypertarget{pfe}
</p>
</div>
</div>
<div id="outline-container-org2c9e469" class="outline-5">
<h5 id="org2c9e469">Nota Bene</h5>
<div class="outline-text-5" id="text-org2c9e469">
<p>
El esquema de la demostración del Teorema 1.19 muestra cómo se construye
una va riab le aleatoria X con función de distribución F}
X
(x). La construcción es clave para sim
ular variables aleatorias en una computadora: algoritmos estándar generan variables aleatorias
U con distribución uniforme sobre el intervalo (0, 1), aplicando la inversa generalizada de la}
función de distribución se obtiene la variable aleatoria F}
−{1}
X
(U) cuya función de distribución
es F}
X
(x).
Método gráfico para calcular inversas generalizadas. Sea u &isin; (0, 1), por definición,}
F
−{1}
(u) := mín\{x &isin; \Re : u &le; F (x)\, 0 &lt; u &lt; 1. Gráficamente esto significa que para calcular
F
−{1}
(u) hay que determinar el conjunto de to dos los puntos del gráfico de F (x) que están
sobre o por encima de la recta horizontal de altura u y proyectarlo sobre el eje de las abscisas.
El resultado de la proyección es una semi-recta sobre el eje de las abscisas y el valor de la
abscisa que la cierra por izquierda es el valor de F}
−{1}
(u).
</p>
</div>
</div>
<div id="outline-container-orge1f7f9e" class="outline-5">
<h5 id="orge1f7f9e">Ejemplo 1.21</h5>
<div class="outline-text-5" id="text-orge1f7f9e">
<p>
(Moneda cargada). Se quiere simular el lanzamiento de una moneda /"cargada''}
con probabilidad p &isin; (0}, 1) de salir cara. El problema se resuelve construyendo una variable}
aleatoria X a valores \0, 1{\} tal que \mathbb{P}(X = 1) = p y \mathbb{P}(X = 0) = 1 − p, (X = 1 representa el
evento /"la moneda sale cara"/y X = 0 /"la moneda sale c eca''). La función de distribución de
X debe ser F  ( x) = (1 − p)1{\}0 &le; x &lt; 1{\} + 1{\}x &ge; 1\} y su gráfico se muestra en la Figura 5.}
u
1 x
1 − p}
p
1
0
Figura 5: Gráfico de la función F (x) = (1 − p)1{\}0 &le; x &lt; 1{\} + 1\{x &ge; 1{\}.
La demostración del Teorema 1.19 indica que para construir la variable aleatoria X lo
primero que hay que hacer es determinar la expresión de la inversa generalizada de F (x).
Para ello usaremos el método gráfico.
En la Figura 5 se puede ver que para cada 0 &lt; u &le; 1 − p el conjunto \{x &isin; \Re : u &le; F (x)\}
es la semi-recta [0, &infin;}) y el punto que la cierra por izquierda es x = 0. En consecuencia
F
−{1}
(u) = 0 para todo 0 &lt; u &le; 1 − p}. Del mismo modo se puede ver que F}
−{1}
(u) = 1 para
todo 1 − p &lt; u &lt; 1. Por lo tanto, F}
−{1}
(u) = 1{\}1 − p &lt; u &lt; 1{\}.
Definiendo X := 1{\}1 − p &lt; U &lt; 1{\, donde U &sim; \mathcal{U} (0, 1) se obtiene la variable aleatoria
deseada.
</p>
</div>
</div>
<div id="outline-container-org3a36d3e" class="outline-5">
<h5 id="org3a36d3e">Ejemplo 1.22</h5>
<div class="outline-text-5" id="text-org3a36d3e">
<p>
(Moneda cargada). Simular diez lanzamientos de una moneda /"cargada"/con}
probabilidad 0.6 de salir cara en cada lanzamiento.
De acuerdo con el resultado obtenido en el Ejemplo 1.21, 
para simular el lanzamiento
de una moneda cargada con probabilidad 0.6 de salir cara se construye la variable aleatoria
X := 1{\}0.4 &lt; U &lt; 1{\, donde U &sim; U(0 , 1).
14
\hypertarget{pff}
Para simular 10 valores de X se simulan 10 valores de U}. Si en 10 simulaciones de U}
se obtuviesen los valores 0.578, 0.295, 0.885, 0.726, 0.548, 0.048, 0.474, 0.722, 0.786, 0.598,
los valores de la variable X serían 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, respectivamente, y en tal caso, los
resultados de los 10 lanzamientos de la moneda serían H, T, H, H, H, T, H, H, H, H}.
</p>
</div>
</div>
<div id="outline-container-orgeea308d" class="outline-5">
<h5 id="orgeea308d">Ejemplo 1.23</h5>
<div class="outline-text-5" id="text-orgeea308d">
<p>
(Fiabilidad). Se considera un sistema electrónico con función intensidad de}
fallas de la forma &lambda; ( t) = 2}t{1{\}t &gt; 0{\ . Se quiere estimar la función de probabilidad de la
cantidad de fallas ocurridas durante la primer unidad de tiempo de funcionamiento.
Para simplificar el problema vamos a suponer que cada vez que se produce una falla, el
sistema se repara instantáneamente renovándose sus condiciones iniciales de funcionamien
to. Según el Ejemplo 1.2, 
la función de distribución del tiempo de funcionamiento hasta la
aparición de la primer falla es
F  ( t) =}

1 − exp

−t
2

1\{t &gt; 0} \. (23) 
Debido a que la función de distribución F (t) es continua, su inversa generalizada es simple
mente su inversa y se obtiene despejando t de la ecuación 1 −}exp

−t
2

= u. En consecuencia,
F
−{1}
(u) =
p
− log(1 − u), u &isin; (0, 1). Para construir la variable T usamos un número aleatorio}
U, uniformemente distribuido sobre el intervalo (0, 1) y definimos}
T := F
−{1}
(U) =
p
− log(1 − U ) . (24)}
La ventaja de la construcción es que puede implementarse casi de inmediato en una computa
dora. Por ejemplo, una rutina en Octave para simular T es la siguiente
U=rand;
T=sqrt(-log(1-rand))
Sobre la base de esa rutina podemos simular valores de T . Por ejemplo, en diez simulaciones
de T obtuvimos los valores siguientes: 0.3577, 1.7233, 1.1623, 0.3988, 1.4417, 0.3052, 1.1532,
0.3875, 0.8493, 0.9888.
t<sub>10</sub> 2 3 4 5 6 7 8 9
Figura 6: Simulación de los tiempos de ocurrencia de las fallas de un sistema electrónico con
función intensidad de fallas de la forma &lambda;(t) = 2{t{1{\}t &ge; 0{\}. Las fallas ocurren los instantes
0.3577, 2.0811, 3.2434, 3.6422, 5.0839, 5.3892, 6.5423, 6.9298, 7.7791, 8.7679.
La rutina puede utilizarse para simular cien mil realizaciones del experimento que consiste
en observar la cantidad de fallas durante la primer unidad de tiempo de funcionamiento
del sistema electrónico bajo consideración: N[0, 1] := mín \{n &ge; 1 :
P
n
{i=1}
T
i
&gt; 1{\} − 1, donde}
T<sub>1</sub>
, T<sub>2</sub>
, &hellip; son realizaciones independientes de los tiempos de funcionamiento del sistema hasta}
la ocurrencia de una falla.
Por ejemplo, repitiendo la simulación 100000 veces obtuvimos la siguiente tabla que con
tiene la cantidad de veces que fué simulado cada valor de la variable N[0, 1]:
valor simulado 0 1 2 3 4
frecuencia 36995 51792 10438 743 32
(25)
15
obteniéndose las siguientes estimaciones
\mathbb{P}(N[0, 1] = 0) &asymp; 0.36995, \mathbb{P}(N[0, 1] = 1) &asymp; 0.51792, \mathbb{P}(N[0, 1] = 2) &asymp; 0.10438, 
\mathbb{P}(N[0, 1] = 3) &asymp; 0.00743, \mathbb{P}(N[0, 1] = 4) &asymp; 0.00032.
Para finalizar este ejemplo, presentamos una rutina en Octave que simula cien mil veces
la cantidad de fallas en la primer unidad de tiempo y que al final produce los resultados para
construir una tabla similar a la tabla (25).
for i=1:100000
n=-1;
S=0;
while S&lt;=1;
T=sqrt(-log(1-rand));
S=S+T;
n=n+1;
end
f(i)=n;
end
M=max(f);
for i=1:M+1;
N(i)=length(find(f==i-1));
end
N
</p>
</div>
</div>
<div id="outline-container-org58d5c9c" class="outline-5">
<h5 id="org58d5c9c">Ejemplo 1.24</h5>
<div class="outline-text-5" id="text-org58d5c9c">
<p>
(Saltando, saltando, sa, sa, sa, saltando,&#x2026;}

). La función
F  ( x) =}
&infin;
X
{n=1}
1
2
n
1\{x &ge; r}
n
\, (26)}
donde r
1
, r
2
, &hellip; es un reordenamiento de los números racionales del intervalo (0, 1) con denom
inadores crecientes:
1
2
,
1
3
,
2
3
,
1
4
,
3
4
,
1
5
,
2
5
,
3
5
,
4
5
, &hellip; , tiene las siguientes propiedades es creciente,}
continua a derecha, lim<sub>x &rarr;−&infin;</sub>
F  ( x) = 0 y lím}
{x&rarr;&infin;}
F  ( x) = 1; tiene saltos en todos los números}
racionales del (0, 1) y es continua en los irracionales del (0, 1).
Pero no! Mejor no hablar de ciertas cosas &#x2026;
</p>
</div>
</div>
<div id="outline-container-orgab13a26" class="outline-5">
<h5 id="orgab13a26">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-orgab13a26">
<ol class="org-ol">
<li>Sea X una variable aleatoria con función de distribución F<sub>X</sub>(x). Mostrar que para cada</li>
</ol>
<p>
&alpha; &isin; (0}, 1) vale que}
sup\{x &isin; \Re : F}
X
(x) &lt; &alpha;{\} = mín\{x &isin; \Re : F}
X
(x) &ge; &alpha;\}.
16
</p>
</div>
</div>
</div>
<div id="outline-container-org633de9a" class="outline-3">
<h3 id="org633de9a">Función de distribución empírica e histogramas</h3>
<div class="outline-text-3" id="text-org633de9a">
<p>
Distribución empírica
La función de distribución empírica F
n
(x) de n puntos sobre la recta x
1
, &hellip; , x
n
es la
función escalera con saltos de altura 1{/n en los puntos x
1
, &hellip; , x
n
. En otras palabras, nF}
n
(x)
es igual a la cantidad de puntos x
k
en (−&infin;, x] y F}
n
(x) es una función de distribución:
F
n
(x) =
1
n
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\{i = 1, &hellip; , n : x}</td>
</tr>
</tbody>
</table>
<p>
i
&le; x\}| =}
1
n
n
X
{i=1}
1\{x}
i
&le; x\. (27)}
</p>
</div>
<div id="outline-container-org7188893" class="outline-5">
<h5 id="org7188893">Nota Bene</h5>
<div class="outline-text-5" id="text-org7188893">
<p>
En la práctica, disponemos de conjuntos de observaciones (/"muestras'') corre
spondientes a un experimento considerado aleatorio y queremos extraer de ellas conclusiones
sobre los modelos que podrían cumplir. Dada una muestra x
1
, &hellip; , x
n
, la función de distribu
ción empírica F}
n
(x) coincide con la función de distribución de una variable aleatoria discreta
que concentra toda la masa en los valores x
1
, &hellip; , x
n
, dando a cada uno probabilidad 1{/n}.
</p>
</div>
</div>
<div id="outline-container-org2d7c781" class="outline-5">
<h5 id="org2d7c781">Observación 1.25. Sea F</h5>
<div class="outline-text-5" id="text-org2d7c781">
<p>
n
(x) la función de distribución empírica correspondiente a una
muestra de n valores x
1
, &hellip; , x
n
. Sean a y b dos números reales tales que a &lt; b}. Notar que
F
n
(b) − F
n
(a) =
1
n
n
X
{i=1}
1\{x}
i
&isin; (a, b]\} =}
1
n
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\{i = 1, &hellip; , n : x}</td>
</tr>
</tbody>
</table>
<p>
i
&isin; (a, b]\}|.
En consecuencia, el cociente incremental de F}
n
(x) sobre el intervalo [a, b] es la frecuencia
relativa de los valores de la muestra x
1
, &hellip; , x
n
contenidos en el intervalo (a, b] /"normalizada''
por la longitud de dicho intervalo:
F
n
(b) − F
n
(a)
b − a
=
</p>

<p>
1
b − a

1
n
n
X
{i=1}
1\{x}
i
&isin; (a, b]\}
!
. (28)
Notar que si los n valores, x
1
, &hellip; , x
n
, corresponden a n observaciones independientes de
los valores de una variable aleatoria X, la i
nterpretación intuitiva de la probabilidad indica
que el cociente incre mental (28) debería estar próximo del cociente incremental de la función
de distribución, F}
X
(x), de la variable aleatoria X sobre el intervalo [a, b]:
F
n
(b) − F
n
(a)
b − a
&asymp;
\mathbb{P}(a &lt; X &le; b)
b − a
=
F
X
(b) − F
X
(a)
b − a
. (29)
Cuando X es una variable aleatoria absolutamente continua con función densidad continua
f<sub>X</sub>(x) la aproximación (28) adopta la forma
F
n
(b) − F
n
(a)
b − a
&asymp;
1
b − a
Z
b
a
f<sub>X</sub>(x)dx = f<sub>X</sub>(x), (30)
donde x es algún punto perteneciente al intervalo (a, b).
17
Histogramas
Un histograma de una muestra x
1
, &hellip; , x
n
se obtiene eligiendo una partición en m intervalos
de extremos a
0
&lt;  &ctdot;  &lt; a
m
, con longitudes L}
j
= a
j
−a
j{−{1
; calculando las frecuencias relativas}
p
j
=
1
n
n
X
{i=1}
1\{a}
j{−{1
&lt; x
i
&lt; a
j
\}
y graficando la función igual a p
j
/L
j
en el intervalo (a
j{−{1
, a
j
] y a 0 fuera de los intervalos:
f
x
1
,&#x2026;,x
n
; a
0
,&#x2026;,a
m
(x) :=
m
X
{j=1}
p
j
L
j
1\{x &isin; (a
j{−{1
, a
j
]\. (31)
O sea, un conjunto de rectángulos con área p
j
.
Cuando la muestra x
1
, &hellip; , x
n
corresponde a n observaciones independientes de una vari
able aleatoria X absolutamente continua la función definida en (31) es una versión discreta
de la densidad de X en la que las áreas miden frecuencias relativas.
</p>
</div>
</div>
<div id="outline-container-org2e8b648" class="outline-5">
<h5 id="org2e8b648">Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-org2e8b648">
<ol class="org-ol">
<li>Lucas filma vídeos de tamaños aleatorios. En una muestra aleatoria de 5 vídeos filmados}</li>
</ol>
<p>
por Lucas se obtuvieron los siguiente tamaños (en MB):
17, 21.3, 18.7, 21, 18.7
Hallar y graficar la función de distribución empírica asociada a esta muestra. Estimar, usando
la función de distribución empírica asociada a esta muestra, la probabilidad de que un vídeo
ocupe menos de 19.5 MB.
</p>
<ol class="org-ol">
<li>Los siguientes datos corresponden a los tiempos de funcionamiento (en años) hasta que}</li>
</ol>
<p>
ocurre la primer falla de una muestra de 12 máquinas industriales:
2.0087, 1.9067, 2.0195, 1.9242, 1.8885, 1.8098, 
1.9611, 2.0404, 2.1133, 2.0844, 2.1695, 1.9695.
Usando los intervalos con extremos 1.7, 1.9, 2.1, 2.3, hallar la función histograma basada en
la muestra observada e integrarla para estimar la probabilidad de que una máquina industrial
del mismo tipo funcione sin fallas durante menos de dos años.
</p>
</div>
</div>
<div id="outline-container-org4a46cd5" class="outline-5">
<h5 id="org4a46cd5">Ejemplo 1.26.</h5>
<div class="outline-text-5" id="text-org4a46cd5">
<p>
Sea T una variable aleatoria con distribución exponencial de intensidad 1}
(ver (14)). Esto es, T es una variable aleatoria absolutamente continua con función densidad
de probabilidad
f
T
(t) = e
−t<sub>1</sub>\{t &gt; 0}\}
y función de distribución
F
T
(t) =

1 − e}
−t

1\{t &ge; 0\}.
18
De acuerdo con el esquema de la demostración del Teorema 1.19 podemos simular muestras de
T utilizando un generador de números aleatorios uniformemente distribuidos sobre el intervalo}
(0, 1). Concretamente, si U &sim; \mathcal{U} (0, 1), entonces
ˆ
T = − log(1 − U ) 
es una variable con distribución exponencial de intensidad 1.
Para obtener una muestra de 10 valores t<sub>1</sub>
, &hellip; , t<sub>10</sub>
de una variable con distribución ex
ponencial de intensidad 1 generamos 10 números aleatorios u
1
, &hellip; , u
10
y los transformamos
poniendo t
i
= − log(1 − u}
i
). Por ejemplo, si los valores u
1
, &hellip; , u
10
son, respectivamente,
0.1406, 0.3159, 0.8613, 0.4334, 0.0595, 0.8859, 0.2560, 0.2876, 0.2239, 0.5912, 
los valores de la muestra obtenida, t<sub>1</sub>
, &hellip; , t<sub>10</sub>
, son, respectivamente,
0.1515, 0.3797, 1.9753, 0.5682, 0.0613, 2.1703, 0.2957, 0.3390, 0.2535, 0.8946. (32)
La función de distribución empírica de la muestra observada, F}
10
(t), es una función escalera
con saltos de altura 1 / 10 en los siguientes puntos del eje t:
0.0613, 0.1515, 0.2535, 0.2957, 0.3390, 0.3797, 0.5682, 0.8946, 1.9753, 2.1703.
Para construir un histograma usaremos la partición que se obtiene dividiendo en dos
intervalos de igual longitud el intervalo comprendido entre los valores mínimos y máximos
observados: 0.0613, 1.1158, 2.1703. La longitud L de cada intervalo es 1.0545. La frecuencia
relativa de la muestra sobre el primer intervalo es p
1
= 8 / 10 y sobre el segundo p
2
= 2 / 10 y
la correspondiente altura de cada rectángulo es p
1
/L = 0.75865 y p
2
/L = 0.18966.
0 1 2 3 4 5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Empírica
Teórica
(a)
0 1 2 3 4 5 6 7
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Hitograma
Densidad
(b)
Figura 7: (a) Gráficos de la función de distribución empírica F}
10
(t) correspondiente a la
muestra dada en (32) y de la función de distribución de T . (b) Histograma correspondiente a
la misma muestra y gráfico de la densidad de T .
19
Para producir los gráficos de la Figura 7 usamos las siguientes rutinas en Octave.
Rutina para simular 10 valores de una exponencial de intensidad 1}
U=rand(1,10);
T=-log(1-U);
Rutina para graficar la función de distribución empírica de la muestra T}
t=sort(T);
s=empirical\<sub>cdf</sub>(t,t);
stairs([t(1),t],[0 s])
Rutina para graficar un histograma de la muestra T}
[f,c]=hist(T,2);
p=f/10;
L=c(2)-c(1);
bar(c,p/L,1,'w')
Usando rutinas similares para muestras de tamaño 100 se obtienen los siguientes gráficos.
0 1 2 3 4 5 6 7
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Empírica
Teórica
(a)
0 1 2 3 4 5 6 7
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Hitograma
Densidad
(b)
Figura 8: (a) Gráficos de la función de distribución empírica F}
100
(t) correspondiente a una
muestra de tamaño 100 de una variable T con distribución exponencial de intensidad 1 y de
la función de distribución de T . (b) Histograma correspondiente a la misma muestra y gr
áfico
de la densidad de T .
20
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf89b669" class="outline-2">
<h2 id="orgf89b669">Variables truncadas</h2>
<div class="outline-text-2" id="text-orgf89b669">
<p>
Sea X una variable aleatoria definida sobre un espacio de probabilidad \((\Omega, \mathcal{A},\mathbb{P})\). Sea
B &sub; \Re un conjunto tal que X 
−{1}
(B) = \{&omega; &isin; &Omega; : X(&omega;) &isin; B\} &isin; A y tal que \mathbb{P}(X &isin; B) &gt; 0.
Truncar la variable aleatoria X al conjunto B significa condicionarla a tomar valores en
el conjunto B.
Mediante X | X &isin; B designaremos la variable aleatoria obtenida por truncar X al conjunto
B. Por definición, la función de distribución de X | X &isin; B es}
F
X | {X&isin; B}
(x) = \mathbb{P}(X &le; x{| X &isin; B) =
\mathbb{P}(X &le; x, X &isin; B)
\mathbb{P}(X &isin; B)
. (33)
Caso absolutamente continuo. Si la variable aleatoria X es absolutamente continua con
densidad de probabilidades f<sub>X</sub>(x), la función de distribución de X | X &isin; B adopta la forma
F
X | {X&isin; B}
(x) =
R
\{X\leqx\}&cap;\{X\inB\}
f<sub>X</sub>(x)dx}
\mathbb{P}(X &isin; B)
=
R
x
−&infin;
f<sub>X</sub>(x)1\{x &isin; B\dx 
\mathbb{P}(X &isin; B)
. (34)
Por lo tanto, X | X &isin; B es una variable aleatoria absolutamente continua con densidad de
probabilidades
f
X | {X&isin; B}
(x) =
f<sub>X</sub>(x)
\mathbb{P}(X &isin; B)
1\{x &isin; B\. (35) 
</p>
</div>
<div id="outline-container-orgdb850ff" class="outline-5">
<h5 id="orgdb850ff">Nota Bene</h5>
<div class="outline-text-5" id="text-orgdb850ff">
<p>
La densidad condicional f}
X | {X&isin; B}
(x) es cero fuera del conjunto condicionante
B. Dentro del conjunto condicionante la densidad condicional tiene exactamente la misma}
forma que la densidad incondicional, salvo que está escalada por el factor de normalización
1{/\mathbb{P}(X &isin; B) que asegura que f
X{|&isin;}B
(x) integra 1.
</p>
</div>
</div>
<div id="outline-container-orgfad27dc" class="outline-5">
<h5 id="orgfad27dc">Ejemplo 2.1 (Exponencial truncada a la derecha)</h5>
<div class="outline-text-5" id="text-orgfad27dc">
<p>
Sea T una variable aleatoria con distribu
ción exponencial de intensidad &lambda; &gt; 0 y sea t<sub>0</sub>
&gt; 0. Según la fórmula (35) la variable aleatoria}
T truncada a la semi-recta (t, +{&infin;), T | T &gt; t<sub>0</sub>
, tiene la siguiente densidad de probabilidades
f
T | T &gt;t<sub>0</sub>
(t) =
&lambda; e
−{&lambda; t}
e
−{&lambda; t}
0
1\{t &gt; t<sub>0</sub>
\} = e}
−{&lambda; ( t}−t<sub>0</sub>
)
1\{t − t}
0
&gt; 0{\} = f
T
(t − t}
0
).
En otros términos, si T &sim; Exp( &lambda; ), entonces T | T &gt; t}
0
&sim; t<sub>0</sub>
+Exp( &lambda; ).
Caso discreto. El caso discreto se trata en forma análoga a la anterior. La función de}
probabilidad de X | X &isin; B adopta la forma
p
X | {X&isin; B}
(x) =
\mathbb{P}(X = x)
\mathbb{P}(X &isin; B)
1\{x &isin; B\. (36) 
</p>
</div>
</div>
<div id="outline-container-org52218a2" class="outline-5">
<h5 id="org52218a2">Ejemplo 2.2 (Dado equilibrado).</h5>
<div class="outline-text-5" id="text-org52218a2">
<p>
Sea X el resultado del tiro de un dado equilibrado y sea}
B = \2, 4, 6{\}. El evento <i>"el resultado del tiro es un número par"</i> es X &isin; B}. Aplicando la 
fórmula anterior obtenemos
p
X | {X&isin; B}
(x) =
1 / 6
1 / 2
1\{x &isin; \{2, 4, 6\}\} =
1
3
1\{x &isin; \{2, 4, 6\}\. (37) 
21
</p>
</div>
</div>
<div id="outline-container-orga9b483c" class="outline-3">
<h3 id="orga9b483c">Perdida de memoria</h3>
<div class="outline-text-3" id="text-orga9b483c">
</div>
<div id="outline-container-org828163b" class="outline-5">
<h5 id="org828163b">Ejemplo 2.3.</h5>
<div class="outline-text-5" id="text-org828163b">
<p>
Lucas camina hacia la parada del colectivo. El tie mpo, T , entre llegadas}
de colectivos tiene distribución ex ponencial de intensidad &lambda;}. Supongamos que Lucas llega t
minutos después de la llegada de un colectivo. Sea X el tiempo que Lucas tendrá que esperar
hasta que llegue el próximo colectivo. Cuál es la distribución del tiempo de espera X?
Designamos mediante A = \{T &gt; t\} el evento /"Lucas llegó t minutos después de la llegada}
de un colectivo''. Tenemos que}
\mathbb{P}(X &gt; x | A) = \mathbb{P}(T &gt; t + x | T &gt; t) =}
\mathbb{P}(T &gt; t + x, T &gt; t)
\mathbb{P}(T &gt; t)
=
\mathbb{P}(T &gt; t + x)
\mathbb{P}(T &gt; t)
=
e
−{&lambda; ( t{+}x ) 
e
−{&lambda; t}
= e
−{&lambda; x}
.
</p>
</div>
</div>
<div id="outline-container-orga965d0c" class="outline-5">
<h5 id="orga965d0c">Definición 2.4.</h5>
<div class="outline-text-5" id="text-orga965d0c">
<p>
Se dice que una variable aleatoria T no tiene memoria, o pierde memoria, si 
\mathbb{P}(T &gt; s + t | T &gt; t) = \mathbb{P}(T &gt; s) para todo s, t &ge; 0. (38)
La condición de pérdida de memoria es equivalente a la siguiente
\mathbb{P}(T &gt; s + t) = \mathbb{P}(T &gt; s)\mathbb{P}(T &gt; t). (39)
En efecto, basta observar que \mathbb{P}(T &gt; s + t, T &gt; t) = \mathbb{P}(T &gt; s + t) y usar la definición de
probabilidad condicional.
</p>
</div>
</div>
<div id="outline-container-orgd921793" class="outline-5">
<h5 id="orgd921793">Nota Bene</h5>
<div class="outline-text-5" id="text-orgd921793">
<p>
Si se piensa que T es el tiempo para completar cierta operación, la ecuación}
(38) establece que si a tiempo t la operación no ha sido completada, la probabilidad de que
la operación no se complete a tiempo s + t es la misma que la probabilidad inicial de que la
operación no haya sido completada a tiempo s.
</p>
</div>
</div>
<div id="outline-container-org9ba2d56" class="outline-5">
<h5 id="org9ba2d56">Lema 2.5. La variable exponencial no tiene memoria.</h5>
</div>
<div id="outline-container-org2569b8a" class="outline-5">
<h5 id="org2569b8a">Demostración Si T &sim; Exp( &lambda; ), entonces}</h5>
<div class="outline-text-5" id="text-org2569b8a">
<p>
\mathbb{P}(T &gt; t) = e}
−{&lambda; t}
para todo t &ge; 0. (40)
Usando (40) se prueba inmediatamente que la e cuación (39) se satisface cuando T tiene
distribución exponencial (pues e
−{&lambda; ( s{+}t ) 
= e
−{&lambda; s}
e
−{&lambda; t}
).
</p>
</div>
</div>
<div id="outline-container-org97c64ae" class="outline-5">
<h5 id="org97c64ae">Nota Bene</h5>
<div class="outline-text-5" id="text-org97c64ae">
<p>
Si modelamos el tiempo para completar cierta operación por una variable}
aleatoria T con distribución exponencial, la propiedad de pérdida de memoria implica que
mientras la operación no haya sido completada, el tiempo restante para completarla tiene la
misma función de distribución, no importa cuando haya empezado la operación.
</p>
</div>
</div>
<div id="outline-container-org15d0c70" class="outline-5">
<h5 id="org15d0c70">Ejemplo 2.6.</h5>
<div class="outline-text-5" id="text-org15d0c70">
<p>
Supongamos que el tiempo de espera para recibir un mensaje tenga distribu
ción exponencial de intensidad 1 / 10 minutos. Cuál es la probabilidad de que tengamos que
esperar más de 15 minutos para recibirlo? Cuál es la probabilidad de que tengamos que es
perar más de 15 minutos para recibir el mensaje dado que hace más de 10 minutos que lo
estamos esperando?
22
Si T representa el tiempo de espera, T &sim; Exp(1 / 10). La primer probabilidad es
\mathbb{P}(T &gt; 15) = e}
−
1
10
15
= e
−
3
2
&asymp; 0.220}
La segunda pregunta interroga por la probabilidad de que habiendo esperado 10 minutos
tengamos que esperar al menos 5 minutos más. Usando la propiedad de falta de memoria de
la exponencial, dicha probabilidad es
\mathbb{P}(T &gt; 5) = e}
−
1
10
5
= e
−
1
2
&asymp; 0.604.
</p>
</div>
</div>
</div>
<div id="outline-container-org6fe71b2" class="outline-3">
<h3 id="org6fe71b2">Caracterización cualitativa de la distribución exponencial</h3>
<div class="outline-text-3" id="text-org6fe71b2">
<p>
La propiedad de pérdida de memoria caracteriza a la distribución exponencial.
</p>
</div>
<div id="outline-container-org9671ba1" class="outline-5">
<h5 id="org9671ba1">Teorema 2.7. Sea T una variable aleatoria continua a valores en R</h5>
<div class="outline-text-5" id="text-org9671ba1">
<ul class="org-ul">
<li></li>
</ul>
<p>
. Si T pierde memoria,
entonces T &sim; Exp( &lambda; ), donde &lambda; = − log \mathbb{P}(T &gt; 1).
</p>
</div>
</div>
<div id="outline-container-orgaa787dc" class="outline-5">
<h5 id="orgaa787dc">Demostración (a la Cauchy). Sea G(t) := \mathbb{P}(T &gt; t). De la ecuación (39) se deduce que}</h5>
<div class="outline-text-5" id="text-orgaa787dc">
<p>
G ( s + t) = G ( s ) G ( t ) . (41)
La única función continua a derecha que satisface la ecuación funcional (41) es
G ( t) = G(1)
t
. (42)
Para ello basta ver que G}

m
n

= G(1)
m
n
. Si vale (41), entonces G}

2
n

= G}

1
n
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
1
n

=
G

1
n

G

1
n

= G}

1
n

2
y repitiendo el argumento se puede ver que
G

m
n

= G}
</p>

<p>
1
n

m
. (43)
En particular, si m = n se obtiene G (1) = G}

1
n

n
. Equivalentemente,
G
</p>

<p>
1
n

= G(1)
1
n
(44)
De las identidades (43) y (44) se deduce que
G

m
n

= G(1)
m
n
. (45)
Ahora bien, debido a que G(1) = \mathbb{P}(T &gt; 1) &isin; (0, 1), existe &lambda; &gt; 0 tal que G(1) = e
− &lambda; 
(&lambda; = − l og G(1)). Reemplazando en (42) se obtiene G(t) =

e
− &lambda; 

t
= e
−{&lambda; t}
.
</p>
</div>
</div>
</div>
<div id="outline-container-orgc76e70d" class="outline-3">
<h3 id="orgc76e70d">Dividir y conquistar</h3>
<div class="outline-text-3" id="text-orgc76e70d">
</div>
<div id="outline-container-org6ad5f07" class="outline-5">
<h5 id="org6ad5f07">Teorema 2.8. Sea X una variable aleatoria absolutamente continua con densidad de proba</h5>
<div class="outline-text-5" id="text-org6ad5f07">
<p>
bilidades f<sub>X</sub>(x). Sea (B
i
)
i &ge; 1
una familia de subconjuntos disjuntos dos a dos de la recta real
tales que \{X &isin; B}
i
\} &isin; A y \mathbb{P}(X &isin; B
i
) &gt; 0 para todo i &ge; 1. Si &Omega; = &cup;}
i &ge; 1
\{X &isin; B
i
\, entonces}
f<sub>X</sub>(x) =
X
i &ge; 1
f
X | {X&isin; B}
i
(x)\mathbb{P}(X &isin; B}
i
). (46)
</p>
</div>
</div>

<div id="outline-container-orgf4e2ca7" class="outline-5">
<h5 id="orgf4e2ca7">Demostración</h5>
<div class="outline-text-5" id="text-orgf4e2ca7">
<p>
Inmediata de la fórmula (35) y de observar que}
P
i &ge; 1
1\{X &isin; B}
i
\} = 1.
</p>
</div>
</div>
<div id="outline-container-org7d33423" class="outline-5">
<h5 id="org7d33423">Ejemplo 2.9 (Dividir y conquistar). Todas las mañanas Lucas l lega a la estación del subte}</h5>
<div class="outline-text-5" id="text-org7d33423">
<p>
entre las 7:10 y las 7:30 (con distribución uniforme en el intervalo). El subte llega a la estación
cada quince minutos comenzando a las 6:00. ¿Cuál es la densidad de probabilidades del tiempo
que tiene que esperar Lucas hasta subirse al subte?
Sea X el tiempo de llegada de Lucas a la estación del subte, X &sim; \mathcal{U} [7:10, 7:30]. Sea Y
el tiempo de espera. Consideramos los eventos A = \7:10 &le; X &le; 7:15{\} = ''Lucas sube en el}
subte de las 7:15''; B = \7:15 &lt; X &le; 7:30{\} = ''Lucas sube en el subte de las 7:30''.
Condicionado al evento A, el tiempo de llegada de Lucas a la estación del subte es uniforme
entre las 7:10 y las 7:15. En en ese caso, el tiempo de esp era Y es uniforme entre 0 y 5 minutos.
Análogamente, condicionado al evento B, Y es uniforme entre 0 y 15 minutos. La densidad
de probabilidades de Y se obtiene dividiendo y conquistando
f<sub>Y</sub>(y) =
</p>

<p>
5
20

1
5
1\{0 &le; y &le; 5\} +
</p>

<p>
15
20

1
15
1\{0 &le; y &le; 15\}
=
1
10
1\{0 &le; y &le; 5\} +
1
20
1\{5 &le; y &le; 15\}.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org5b32511" class="outline-2">
<h2 id="org5b32511">Bibliografía consultada</h2>
<div class="outline-text-2" id="text-org5b32511">
<p>
Para redactar estas notas se consultaron los siguientes libros:
</p>
<ol class="org-ol">
<li>Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to Probability. M.I.T. Lecture Notes.</li>
</ol>
<p>
(2000)
</p>
<ol class="org-ol">
<li>Chung, K. L.: A Course in Probability Theory. Academic Press, San Diego. (2001)</li>
<li>Durrett R.:Probability.Theory and Examples. Duxbury Press, Belmont. (1996)</li>
<li>Feller, W.: An introduction to Probability Theory and Its Applications. Vol. 1. John</li>
</ol>
<p>
Wiley &amp; Sons, New York. (1968)
</p>
<ol class="org-ol">
<li>Feller, W.: An introduction to Probability Theory and Its Applications. Vol. 2. John</li>
</ol>
<p>
Wiley &amp; Sons, New York. (1971)
</p>
<ol class="org-ol">
<li>Grimmett, G. R., Stirzaker, D. R.: Probability and Random Processes. Oxford Univer</li>
</ol>
<p>
sity Press, New York. (2001)
</p>
<ol class="org-ol">
<li>Johnson, N. L., Kotz, S., Balakrishnan, N.: Continuous Univariate Distributions. Vol.</li>
<li>John Wiley &amp; Sons, New York. (1995)</li>
<li>Kolmogorov, A. N.: Foundations of the Theory of Probability. Chelsea Publishing Co.,</li>
</ol>
<p>
New York. (1956)
</p>
<ol class="org-ol">
<li>Maronna R.: Probabilidad y Estadística Elementales para Estudiantes de Ciencias. Ed</li>
</ol>
<p>
itorial Exacta, La Plata. (1995).
</p>
<ol class="org-ol">
<li>Pugachev, V. S.: Introducción a la Teoría de las Probabilidades. Mir, Moscú. (1973)</li>
<li>Ross, S.: Introduction to Probability Models. Academic Press, San Diego. (2007)</li>
</ol>
<p>
24
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
Last update: 2019-03-18 00:16
</div>
</body>
</html>
