<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-09-16 Wed 12:18 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Variables aleatorias</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="/res/org.css"/>
<link rel="stylesheet" type="text/css" href="../res/org.css"/>

<script type="text/javascript" src="https://orgmode.org/org-info.js">
/**
 *
 * @source: https://orgmode.org/org-info.js
 *
 * @licstart  The following is the entire license notice for the
 *  JavaScript code in https://orgmode.org/org-info.js.
 *
 * Copyright (C) 2012-2020 Free Software Foundation, Inc.
 *
 *
 * The JavaScript code in this tag is free software: you can
 * redistribute it and/or modify it under the terms of the GNU
 * General Public License (GNU GPL) as published by the Free Software
 * Foundation, either version 3 of the License, or (at your option)
 * any later version.  The code is distributed WITHOUT ANY WARRANTY;
 * without even the implied warranty of MERCHANTABILITY or FITNESS
 * FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.
 *
 * As additional permission under GNU GPL version 3 section 7, you
 * may distribute non-source (e.g., minimized or compacted) forms of
 * that code without the copy of the GNU GPL normally required by
 * section 4, provided you include this license notice and a URL
 * through which recipients can access the Corresponding Source.
 *
 * @licend  The above is the entire license notice
 * for the JavaScript code in https://orgmode.org/org-info.js.
 *
 */
</script>

<script type="text/javascript">

/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/

<!--/*--><![CDATA[/*><!--*/
org_html_manager.set("TOC_DEPTH", "6");
org_html_manager.set("LINK_HOME", "");
org_html_manager.set("LINK_UP", "");
org_html_manager.set("LOCAL_TOC", "1");
org_html_manager.set("VIEW_BUTTONS", "0");
org_html_manager.set("MOUSE_HINT", "underline");
org_html_manager.set("FIXED_TOC", "0");
org_html_manager.set("TOC", "0");
org_html_manager.set("VIEW", "info");
org_html_manager.setup();  // activate after the parameters are set
/*]]>*///-->
</script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgd9f1f08">1. Variables aleatorias</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#org22dd77d">1.0.0.1. Cálculo de probabilidades</a></li>
</ul>
</li>
<li><a href="#org496e478">1.0.1. Ejemplos</a>
<ul>
<li><a href="#org322cadb">1.0.1.1. Ejemplo 1.1 (Dado equilibrado)</a></li>
<li><a href="#org977bc78">1.0.1.2. Ejemplo 1.2 (Fiabilidad)</a></li>
<li><a href="#org59bdd05">1.0.1.3. Nota Bene</a></li>
<li><a href="#org333b97e">1.0.1.4. Ejemplo 1.3 (Fiabilidad)</a></li>
<li><a href="#orge731165">1.0.1.5. Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org96355e5">1.1. Propiedades de la función de distribución</a>
<ul>
<li>
<ul>
<li><a href="#org7cf34ce">1.1.0.1. Lema 1.4</a></li>
<li><a href="#org3ce40a3">1.1.0.2. Demostración</a></li>
<li><a href="#orgb5ff0ad">1.1.0.3. Observación 1.5</a></li>
<li><a href="#orga8f0e72">1.1.0.4. Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge50052f">1.2. Clasificación de variables aleatorias</a>
<ul>
<li>
<ul>
<li><a href="#org7287b9e">1.2.0.1. Nota Bene</a></li>
<li><a href="#orgf5aef76">1.2.0.2. Atomos</a></li>
<li><a href="#org0cba11a">1.2.0.3. Definición 1.6 (Variables discretas)</a></li>
<li><a href="#orgba37307">1.2.0.4. Escalones</a></li>
<li><a href="#orgb710c8c">1.2.0.5. Definición 1.7 (Variables continuas)</a></li>
<li><a href="#org5b0faeb">1.2.0.6. Definición 1.8 (Variables mixtas)</a></li>
<li><a href="#org72e50c4">1.2.0.7. Definición 1.9 (Variables absolutamente continuas)</a></li>
<li><a href="#orga46d42f">1.2.0.8. Nota Bene</a></li>
<li><a href="#orgd1183c3">1.2.0.9. Interpretación intuitiva de la densidad de probabilidad</a></li>
</ul>
</li>
<li><a href="#org648d64d">1.2.1. Ejemplos</a>
<ul>
<li><a href="#org52a44a6">1.2.1.1. Ejemplo 1.10</a></li>
<li><a href="#org2a831ab">1.2.1.2. Ejemplo 1.11 (Números al azar)</a></li>
<li><a href="#org56c6f74">1.2.1.3. Nota Bene</a></li>
<li><a href="#orge821946">1.2.1.4. Comentario</a></li>
<li><a href="#org78050bc">1.2.1.5. Ejemplo 1.12.</a></li>
<li><a href="#orgc26996a">1.2.1.6. Nota Bene: algunos casos particulares del Ejemplo 1.12</a>
<ul>
<li><a href="#org3b46e23">1.2.1.6.1. Exponencial de intensidad &lambda;</a></li>
<li><a href="#org4d8713e">1.2.1.6.2. Weibull de parámetros c y &alpha;</a></li>
</ul>
</li>
<li><a href="#orgf4008cf">1.2.1.7. Ejemplo 1.13</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb6ce066">1.3. Cuantiles</a>
<ul>
<li>
<ul>
<li><a href="#org358fcab">1.3.0.1. Definición 1.14</a></li>
<li><a href="#org17b5288">1.3.0.2. Observación 1.15</a></li>
<li><a href="#orge912239">1.3.0.3. Interpretación <i>geométrica</i> del cuantil- &alpha;</a></li>
<li><a href="#org4b821d2">1.3.0.4. Nota Bene</a></li>
<li><a href="#org80d496e">1.3.0.5. Nota Bene</a></li>
<li><a href="#org7f717a3">1.3.0.6. Nota Bene</a></li>
<li><a href="#org7ce5352">1.3.0.7. Cuartiles y mediana</a></li>
</ul>
</li>
<li><a href="#orgc712d28">1.3.1. Ejemplos</a>
<ul>
<li><a href="#org579fa48">1.3.1.1. Ejemplo 1.16.</a></li>
<li><a href="#orga0c5c32">1.3.1.2. Ejemplo 1.17.</a></li>
<li><a href="#org7a45b52">1.3.1.3. Ejemplo 1.18</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org37283e1">1.4. Construcción de variables aleatorias</a>
<ul>
<li>
<ul>
<li><a href="#org1e6bbdc">1.4.0.1. Teorema 1.19 (Simulación)</a></li>
<li><a href="#orgce9bf16">1.4.0.2. Esquema de la demostración</a></li>
<li><a href="#org12ba30b">1.4.0.3. Observación 1.20</a></li>
<li><a href="#org59b9cfb">1.4.0.4. Nota Bene</a></li>
<li><a href="#org7d38803">1.4.0.5. Método gráfico para calcular inversas generalizadas</a></li>
<li><a href="#org82d5eae">1.4.0.6. Ejemplo 1.21 (Moneda cargada)</a></li>
<li><a href="#org22223fd">1.4.0.7. Ejemplo 1.22 (Moneda cargada)</a></li>
<li><a href="#orgf092b2e">1.4.0.8. Ejemplo 1.23 (Fiabilidad)</a></li>
<li><a href="#org15a76da">1.4.0.9. Ejemplo 1.24</a></li>
<li><a href="#org2eb4d34">1.4.0.10. Ejercicios adicionales</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org6974db1">1.5. Función de distribución empírica e histogramas</a>
<ul>
<li>
<ul>
<li><a href="#org1e673b1">1.5.0.1. Nota Bene</a></li>
<li><a href="#org079c960">1.5.0.2. Observación 1.25. Sea F<sub>n</sub></a></li>
<li><a href="#org37ca286">1.5.0.3. Ejercicios adicionales</a></li>
<li><a href="#org2118109">1.5.0.4. Ejemplo 1.26.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb6e4e93">2. Variables truncadas</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#orge2d04e5">2.0.0.1. Nota Bene</a></li>
<li><a href="#orga1bd5d0">2.0.0.2. Ejemplo 2.1 (Exponencial truncada a la derecha)</a></li>
<li><a href="#orga746559">2.0.0.3. Ejemplo 2.2 (Dado equilibrado).</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0dcb8f9">2.1. Perdida de memoria</a>
<ul>
<li>
<ul>
<li><a href="#orgd1d247d">2.1.0.1. Ejemplo 2.3.</a></li>
<li><a href="#orga53466f">2.1.0.2. Definición 2.4.</a></li>
<li><a href="#orgd862eae">2.1.0.3. Nota Bene</a></li>
<li><a href="#org9fae8b3">2.1.0.4. Lema 2.5. La variable exponencial no tiene memoria.</a></li>
<li><a href="#orgdd54374">2.1.0.5. Demostración Si T &sim; Exp(&lambda;), entonces}</a></li>
<li><a href="#org884eccf">2.1.0.6. Nota Bene</a></li>
<li><a href="#org4dc052a">2.1.0.7. Ejemplo 2.6.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org5c48157">2.2. Caracterización cualitativa de la distribución exponencial</a>
<ul>
<li>
<ul>
<li><a href="#orgd34fd28">2.2.0.1. Teorema 2.7. Sea T una variable aleatoria continua a valores en R</a></li>
<li><a href="#org9362b7f">2.2.0.2. Demostración (a la Cauchy). Sea G(t) := \mathbb{P}(T &gt; t). De la ecuación (39) se deduce que}</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org7bbabf6">2.3. Dividir y conquistar</a>
<ul>
<li>
<ul>
<li><a href="#org9214a89">2.3.0.1. Teorema 2.8. Sea X una variable aleatoria absolutamente continua con densidad de proba</a></li>
<li><a href="#org505f96c">2.3.0.2. Demostración</a></li>
<li><a href="#orgee573bb">2.3.0.3. Ejemplo 2.9 (Dividir y conquistar). Todas las mañanas Lucas l lega a la estación del subte}</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org5f56173">3. Bibliografía consultada</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgd9f1f08" class="outline-2">
<h2 id="orgd9f1f08"><span class="section-number-2">1</span> Variables aleatorias</h2>
<div class="outline-text-2" id="text-1">
<p>
Sea \((\Omega, \mathcal{A},\mathbb{P})\) un espacio de probabilidad. Una variable
aleatoria sobre \(\Omega\) es una función \(X : \Omega \rightarrow \Re\) tal que
para todo \(x \in \Re\)
</p>

<p>
\[\{X \leq x\} := \{\omega \in \Omega : X(\omega) \leq x\} \in \mathcal{A}\]
</p>

<p>
i.e., para to do \(x \in \Re\) el evento \(\{X \leq x\}\) tiene asignada
probabilidad. La función de distribución \(F_X: R \rightarrow [0, 1]\) de la
variable aleatoria \(X\) se define por
</p>

<p>
\[F_X(x) := \mathbb{P}(X \leq x)\]
</p>
</div>

<div id="outline-container-org22dd77d" class="outline-5">
<h5 id="org22dd77d"><span class="section-number-5">1.0.0.1</span> Cálculo de probabilidades</h5>
<div class="outline-text-5" id="text-1-0-0-1">
<p>
La función de distribución resume (y contiene) toda la in formación relevante
sobre de la variable aleatoria. Para ser más precisos, para cada pareja de
números reales \(a < b\) vale que<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>

<p>
\[\mathbb{P}(a < X \leq b) = F_X (b) − F_X(a)\] . (1)
</p>
</div>
</div>

<div id="outline-container-org496e478" class="outline-4">
<h4 id="org496e478"><span class="section-number-4">1.0.1</span> Ejemplos</h4>
<div class="outline-text-4" id="text-1-0-1">
</div>
<div id="outline-container-org322cadb" class="outline-5">
<h5 id="org322cadb"><span class="section-number-5">1.0.1.1</span> Ejemplo 1.1 (Dado equilibrado)</h5>
<div class="outline-text-5" id="text-1-0-1-1">
<p>
Sea \(X\) el resultado del lanzamiento de un dado equilibrado. Los posibles
valores de \(X\) son \(1, 2, 3, 4, 5, 6\). Para cada \(k \in \{1, 2, 3, 4, 5, 6 \}\)
la probabilidad de que \(X\) tome el valor \(k\) es \(1 / 6\).
</p>

<p>
Sea \(x \in \Re\). Si \(x < 1\) es evidente que \(\mathbb{P}(X \leq x) = 0\). Si \(k
\leq x < k + 1\) para algún \(k \in \{1, 2, 3, 4, 5\}\) la probabilidad del evento
\(\{X \leq x\}\) es la probabilidad de observar un valor menor o igual que k y en
consecuencia, \(\mathbb{P}(X \leq x) = k/6\). Finalmente, si \(x \geq 6\) es
evidente que \(\mathbb{P}(X \leq x) = 1\).
</p>

<p>
Figura 1: Gráfico de la función de distribución del resultado de lanzar un dado equilibrado.
</p>

<p>
Por lo tanto, la función de distribución de \(X\) se puede expresar del siguiente
modo
</p>

<p>
\[F_X(x) = \sum_{k=1}^6\frac{1}{6} \mathbf{1}\{k \leq x\}\]
</p>
</div>
</div>

<div id="outline-container-org977bc78" class="outline-5">
<h5 id="org977bc78"><span class="section-number-5">1.0.1.2</span> Ejemplo 1.2 (Fiabilidad)</h5>
<div class="outline-text-5" id="text-1-0-1-2">
<p>
Un problema fundamental de la ingeniería es el problema de la fiabilidad.
Informalmente, la fiabilidad de un sistema se define como su capacidad para
cumplir ciertas funciones prefijadas. Esta propiedad se conserva durante un
período de tiempo hasta que ocurre una fa lla que altera la capacidad de trabajo
del sistema. Por ejemplo: rupturas y cortocircuitos; fracturas, deformaciones y
atascamientos de piezas mecánicas; el fundido o la combustión de las componentes
de un circuito.
</p>

<p>
Debido a que las fallas pueden ocurrir como hechos casuales, podemos considerar
que el tiempo de funcionamiento, \(T\), hasta la aparición de la primer falla es
una variable aleatoria a valores no negativos.
</p>

<p>
La fiabilidad de un sistema se caracteriza por su función intensidad de fallas
\(\lambda(t)\). Esta función temporal tiene la siguiente propiedad: cuando se la
multiplica por \(dt\) se obtiene la probabilidad condicional de que el sistema
sufra una falla durante el intervalo de tiempo \((t, t + dt]\) sabiendo que hasta
el momento \(t\) funcionaba normalmente. Si se conoce la función \(\lambda(t)\) se
puede hallar la ley de distribución de probabilidades de \(T\).
</p>

<p>
Para calcular la función de distribución de \(T\) estudiaremos dos eventos: \(A :=
\{T > t\}\) (el sistema funciona hasta el momento \(t\)) y \(B := \{t < T \leq t +
dt\}\) (el sistema sufre una falla en el intervalo de tiempo \((t, t + dt]\)). Como
\(B \subset A\), tenemos que \(\mathbb{P}(B) = \mathbb{P}(B \cap A)\) y de la regla
del producto se deduce que
</p>

<p>
\[\mathbb{P}(B) = \mathbb{P}(B | A)\mathbb{P}(A)\] (2)
</p>

<p>
Si la función de distribución de \(T\) admite derivada continua, salvo términos de
segundo orden que se pueden despreciar, la probabilidad del evento \(B\) se puede
expresar en la forma
</p>

<p>
\[\mathbb{P}(B) = \mathbb{P}(t < T \leq t + dt) = F_T(t + dt) − F_T(t) =
F'_T(t)dt\]. (3)
</p>

<p>
La probabilidad del evento \(A\) se puede expresar en la forma
</p>

<p>
\[\mathbb{P}(A) = \mathbb{P}(T > t) = 1 − \mathbb{P}(T \leq t) = 1 − F_T (t)\](4)
</p>

<p>
Finalmente, la probabilidad condicional \(\mathbb{P}(B | A)\) se expresa mediante
la función intensidad de fallas \(\lambda(t)\):
</p>

<p>
\[\mathbb{P}(B | A) = \lambda(t)dt\] (5)
</p>

<p>
Sustituyendo las expresiones (3)-(5) en la fórmula (2) obtenemos, después de
dividir ambos miembros por dt, una ecuación diferencial de primer orden para
\(F_T(t)\)
</p>

<p>
\[F'_T(t) = \lambda(t)(1 − F_T(t))\] (6)
</p>

<p>
Debido a que la duración del servicio del sistema no puede ser negativa, el evento \(\{T \leq 0\}\) es
imposible. En consecuencia, \(F_T(0) = 0\). Integrando la ecuación diferencial (6) con la condición
inicial \(F(0) = 0\), obtenemos<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup>
</p>

<p>
\[F_T(t) = 1 − exp\left(-\int_0^t \lambda(s) ds \right)\] (7)
</p>
</div>
</div>

<div id="outline-container-org59bdd05" class="outline-5">
<h5 id="org59bdd05"><span class="section-number-5">1.0.1.3</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-0-1-3">
<p>
El desarrollo anterior presupone que la función intensidad de fallas
\(\lambda(t)\) verifica las siguientes condiciones: (1) \(\lambda(t) \geq 0\) para
todo \(t > 0\) y (2) \(\int_0^\infty \lambda (t) dt = +\infty\).
</p>
</div>
</div>

<div id="outline-container-org333b97e" class="outline-5">
<h5 id="org333b97e"><span class="section-number-5">1.0.1.4</span> Ejemplo 1.3 (Fiabilidad)</h5>
<div class="outline-text-5" id="text-1-0-1-4">
<p>
Se estipula que la duración de servicio de un sistema automático debe ser \(t_0\).
Si durante ese período el sistema falla, se lo repara y se lo utiliza hasta que
sirva el plazo estipulado. Sea \(S\) el tiempo de funcionamiento del sistema
después de la primera reparación. Quere mos hallar la función de distribución de
\(S\).
</p>

<p>
En primer lugar observamos que la relación entre la variable aleatoria \(S\) y el
instante \(T\) en que ocurre la primera falla del sistema es la siguiente
</p>

<p>
S = máx(t<sub>0</sub> − T, 0) =
</p>

<p>
t<sub>0</sub> − T si T &le; t<sub>0</sub>,
0 si T &gt; t<sub>0</sub>.
</p>

<p>
Sea \(F_S(s)\) la función de distribución de la variable \(S\). Es claro que para \(s
< 0\), \(F_S (s) = 0\) y que para \(s \geq t_0\) , \(F_S (s) = 1\). Lo que falta hacer
es analizar el compor tamiento de \(F_S\) sobre el intervalo \(0 \leq s < t_0\) .
Sea \(s \in [0, t_0)\)
</p>

<p>
F<sub>S</sub>(s) &amp;= \mathbb{P}(S &le; s) = \mathbb{P}(máx(t<sub>0</sub> − T, 0) &le; s) =
\mathbb{P}(t<sub>0</sub> − T &le; s, 0 &le; s)<br />
&amp;= \mathbb{P}(t<sub>0</sub>− T &le; s) = \mathbb{P}(t<sub>0</sub>− s &le; T) = exp \left(
-&int;<sub>0</sub><sup>t<sub>0</sub> - s</sup> &lambda; (t) dt \right)
</p>

<p>
donde \(\lambda(t)\) es la función intensidad de fallas del sistema.
</p>

<p>
Figura 2: Gráfico de la función de distribución de la variable aleatoria S}.
</p>

<p>
Por lo tanto,
</p>

<p>
\[F_S(s) = exp \left( -\int_0^{t_0 - s} \lambda (t) dt \right) \textbf{1}\{0
\leq s < t_0\} + \textbf{1}\{s \geq t_0\}\]
</p>
</div>
</div>

<div id="outline-container-orge731165" class="outline-5">
<h5 id="orge731165"><span class="section-number-5">1.0.1.5</span> Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-1-0-1-5">
<ol class="org-ol">
<li>Sea \(X\) una variable aleatoria con función de distribución \(F_X(x)\). Mostrar
que para cada pareja de números reales \(a < b\) vale que:</li>
</ol>

<p>
\mathbb{P}(a &le; X &le; b) = F<sub>X</sub>(b) − F<sub>X</sub>(a) + \mathbb{P}(X = a) (8)
</p>

<p>
\mathbb{P}(a &le; X &lt; b) = F<sub>X</sub>(b) − \mathbb{P}(X = b) − F<sub>X</sub>(a) + \mathbb{P}(X = a) (9)
</p>

<p>
\mathbb{P}(a &lt; X &lt; b) = F<sub>X</sub>(b) − \mathbb{P}(X = b) − F<sub>X</sub>(a) (10)
</p>

<p>
Notar que las fórmulas (8)-(10), junto con (1), muestran como calcular la
probabilidad de que la variable aleatoria \(X\) tome valores en un intervalo de
extremos \(a\) y \(b\) y contienen una advertencia sobre la acumulación de masa
positiva en alguno de los dos extremos.
</p>
</div>
</div>
</div>

<div id="outline-container-org96355e5" class="outline-3">
<h3 id="org96355e5"><span class="section-number-3">1.1</span> Propiedades de la función de distribución</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org7cf34ce" class="outline-5">
<h5 id="org7cf34ce"><span class="section-number-5">1.1.0.1</span> Lema 1.4</h5>
<div class="outline-text-5" id="text-1-1-0-1">
<p>
Sea \(X : \Omega \rightarrow \Re\) una variable aleatoria. La función de
distribución de \(X\), \(F_X(x) = \mathbb{P}(X \leq x)\), tiene las siguientes
propiedades:
</p>

<ul class="org-ul">
<li>(F1) es no decreciente: si \(x_1 \leq x_2\), entonces \(F_X(x_1) \leq F_X(x_2)\);</li>
<li>(F2) es continua a derecha: para todo \(x_0 \in \Re\) vale que \(lím_{x ↓ x_0}
  F_X(x) = F_X(x_0)\);</li>
<li>(F3) \(\displaystyle\lim_{x \rightarrow−\infty}F_X(x) = 0\) y
\(\displaystyle\lim_{x \rightarrow\infty} F_X(x) = 1\).</li>
</ul>
</div>
</div>

<div id="outline-container-org3ce40a3" class="outline-5">
<h5 id="org3ce40a3"><span class="section-number-5">1.1.0.2</span> Demostración</h5>
<div class="outline-text-5" id="text-1-1-0-2">
<p>
La propiedad (F1) se deduce de la fórmula (1).
</p>

<p>
La propiedad (F2) es consecuencia del axioma de continuidad de la medida de probabilidad
P. Se considera una sucesión decreciente de números positivos que converge a 0, &epsilon;
1
&gt; &epsilon;
2
&gt;
dots &gt; 0, arbitraria, pero fija y se definen eventos A}
n
= \{x}
0
&lt; X &le; x<sub>0</sub>
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n
\. Se observa que}
A<sub>1</sub>
&sup; A<sub>2</sub>
&sup;  &ctdot;  y
T<sub>n</sub>{&isin;{N
A<sub>n</sub>
= &empty;:
</p>

<p>
0 = \displaystylelim<sub>n  &rarr; &infin;</sub>
\mathbb{P}(A<sub>n</sub>) = \displaystylelim<sub>n  &rarr; &infin;</sub>
\mathbb{P}(x}
0
&lt; X &le; x<sub>0</sub>
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n) = \displaystylelim<sub>n  &rarr; &infin;</sub>
F(x<sub>0</sub>
</p>
<ul class="org-ul">
<li>&epsilon;}</li>
</ul>
<p>
n) − F (x<sub>0</sub>).
</p>

<p>
Por lo tanto,
</p>

<p>
\[F(x_0) = \displaystyle\lim_{n  \rightarrow \infty}F(x_0+ \epsilon_n)\]
</p>

<p>
Las propiedades (F3) se demuestran de manera similar.
</p>
</div>
</div>

<div id="outline-container-orgb5ff0ad" class="outline-5">
<h5 id="orgb5ff0ad"><span class="section-number-5">1.1.0.3</span> Observación 1.5</h5>
<div class="outline-text-5" id="text-1-1-0-3">
<p>
Si se define
</p>

<p>
\[F_X(x_0^-) := \displaystyle\lim_{x ↑ x_0} F_X(x)\]
</p>

<p>
entonces \(F_X(x_0^-) = \mathbb{P}(X < x_0)\). Por lo tanto, \(\mathbb{P}(X = x_0)
= F_X (x_0) − F_X (x_0^-)\). En particular, si \(F_X(x)\) es continua en \(x_0\),
entonces \(\mathbb{P}(X = x_0) = 0\). Si \(\mathbb{P}(X = x_0) > 0\), entonces \(F_X
(x)\) es discontinua en \(x_0\) y su discontinuidad es un salto de altura
\(\mathbb{P}(X = x_0) > 0\).
</p>
</div>
</div>

<div id="outline-container-orga8f0e72" class="outline-5">
<h5 id="orga8f0e72"><span class="section-number-5">1.1.0.4</span> Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-1-1-0-4">
<ol class="org-ol">
<li><p>
Sea \((\Omega, \mathcal{A},\mathbb{P})\) un espacio de probabilidad y \(X :
   \Omega \rightarrow \Re\) una variable aleatoria con función de distribución
\(F_X(x)\).
</p>
<ol class="org-ol">
<li>Mostrar que \(\lim_{x \rightarrow−\infty} F_X(x) = 0\) y
\(\displaystyle\lim_{x \rightarrow\infty} F_X(x) = 1\).</li>
</ol>
<p>
(Sugerencia. Considerar sucesiones de eventos B<sub>n</sub> = \{X &le; −n\} y \(C_n =
   \{X \leq n\}\), \(n \in N\), y utilizar el axioma de continuidad de la medida de
probabilidad \(\mathbb{P}\).)
</p>
<ol class="org-ol">
<li>Mostrar que \(\lim_{x ↑ x_0}F_X(x) = \mathbb{P}(X < x_0)\).</li>
</ol>
<p>
(Sugerencia. Observar que si \(x ↑ x_0\), entonces \(\{X \leq x\} ↑ \{X < x_0\}\)
y utilizar el axioma de continuidad de la medida de probabilidad
\(\mathbb{P}\).)
</p></li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orge50052f" class="outline-3">
<h3 id="orge50052f"><span class="section-number-3">1.2</span> Clasificación de variables aleatorias</h3>
<div class="outline-text-3" id="text-1-2">
<p>
En todo lo que sigue, \(X\) designa una variable ale atoria definida sobre un
espacio de probabilidad \((\Omega, \mathcal{A},\mathbb{P})\) y \(F_X (x) :=
\mathbb{P}(X \leq x)\) su función de distribución.
</p>
</div>

<div id="outline-container-org7287b9e" class="outline-5">
<h5 id="org7287b9e"><span class="section-number-5">1.2.0.1</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-2-0-1">
<p>
Al observar el gráfico de una función de distribución lo primero que llama la
atención son sus saltos y sus escalones.
</p>
</div>
</div>

<div id="outline-container-orgf5aef76" class="outline-5">
<h5 id="orgf5aef76"><span class="section-number-5">1.2.0.2</span> Atomos</h5>
<div class="outline-text-5" id="text-1-2-0-2">
<p>
Diremos que \(a \in \Re\) es un átomo de \(F_X(x)\) si su peso es positivo:
\(\mathbb{P}(X = a) = F_X(a) − F_X(a−) > 0\).
</p>

<p>
El conjunto de todos los átomos de \(F_X(x): A = \{a \in \Re : F_X(a) − F_X(a−) >
0\}\), coincide con el conjunto de todos los puntos de discontinuidad de
\(F_X(x)\). El peso de cada átomo coincide con la longitud del salto dado por la
función de distribución en dicho átomo. En consecuencia, existen a lo sumo un
átomo de probabilidad \(> \frac{1}{2}\), a lo sumo dos átomos de probabilidad \(>
\frac{1}{3}\), etcétera. Por lo tanto, es posible reordenar los átomos en una
sucesión \(a_1, a_2, \dots\) tal que \(\mathbb{P}(X = a_1) \geq \mathbb{P}(X = a_2)
\geq \cdots\). En otras palabras, existen a lo sumo numerables átomos.
</p>

<p>
La propiedad de &sigma;-aditividad de la medida de probabilidad \(\mathbb{P}\)
implica que el peso total del conjunto \(A\) no puede exceder la unidad:
</p>

<p>
\[\sum_{a \in A}\mathbb{P}(X = a) \leq 1\]
</p>
</div>
</div>

<div id="outline-container-org0cba11a" class="outline-5">
<h5 id="org0cba11a"><span class="section-number-5">1.2.0.3</span> Definición 1.6 (Variables discretas)</h5>
<div class="outline-text-5" id="text-1-2-0-3">
<p>
Diremos que X es una variable aleatoria discreta si
</p>

<p>
\[\sum_{a \in A}\mathbb{P}(X = a) = 1\]
</p>

<p>
En tal caso, la función \(p_X: A \rightarrow \Re\) definida por \(p_X (x) =
\mathbb{P}(X = x)\) se denomina la función de probabilidad de \(X\).
</p>
</div>
</div>

<div id="outline-container-orgba37307" class="outline-5">
<h5 id="orgba37307"><span class="section-number-5">1.2.0.4</span> Escalones</h5>
<div class="outline-text-5" id="text-1-2-0-4">
<p>
Sea \(X\) una variable aleatoria discreta. Si \(a_1
< a_2\)
son dos átomos consecutivos,
entonces \(F_X
(x) = F_X
(a_1)\) para todo \(x \in (a_1, a_2)\). En otras palabras, la función de distribución
de una variable aleatoria discreta debe ser constante entre saltos consecutivos.
</p>

<p>
Si no lo fuera, deberían existir dos números \(x_1 < x_2\) contenidos en el
intervalo \((a_1, a_2)\) tales que \(F_X (x_1) < F_X (x_2)\). En tal caso,
</p>

\begin{align}
\mathbb{P}(X \in A \cup (x_1, x_2]) &= \mathbb{P}(X \in A}) + \mathbb{P}(x_1
< X \leq x_2) = \sum_{a\in A}\mathbb{P}(X = a) + F_X(x_2) − F_X(x_1)\\
&= 1 + F_X(x_2) − F_X(x_1) > 1
\end{align}
<p>
lo que constituye un absurdo.
</p>
</div>
</div>

<div id="outline-container-orgb710c8c" class="outline-5">
<h5 id="orgb710c8c"><span class="section-number-5">1.2.0.5</span> Definición 1.7 (Variables continuas)</h5>
<div class="outline-text-5" id="text-1-2-0-5">
<p>
Diremos que \(X\) es una variable aleatoria continua si su función de distribución
es continua.
</p>
</div>
</div>

<div id="outline-container-org5b0faeb" class="outline-5">
<h5 id="org5b0faeb"><span class="section-number-5">1.2.0.6</span> Definición 1.8 (Variables mixtas)</h5>
<div class="outline-text-5" id="text-1-2-0-6">
<p>
Diremos que \(X\) es una variable aleatoria mixta si no es continua ni discreta.
</p>
</div>
</div>

<div id="outline-container-org72e50c4" class="outline-5">
<h5 id="org72e50c4"><span class="section-number-5">1.2.0.7</span> Definición 1.9 (Variables absolutamente continuas)</h5>
<div class="outline-text-5" id="text-1-2-0-7">
<p>
Diremos que \(X\) es absolutamente continua si exi ste una función (medible) \(f_X:
\Re \rightarrow \Re^+\), llamada densidad de \(X\), tal que cualesquiera sean
\(−\infty \leq a < b < \infty\) vale que
</p>

<p>
\[\mathbb{P}(a < X \leq b) = \int_a^b f_X(x) dx\] (11)
</p>

<p>
En particular, para cada \(x \in \Re\), vale que
</p>

<p>
\[F_X(x) = \mathbb{P}(X \leq x) = \int_{−\infty}^x f_X(t) dt\] (12)
</p>
</div>
</div>

<div id="outline-container-orga46d42f" class="outline-5">
<h5 id="orga46d42f"><span class="section-number-5">1.2.0.8</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-2-0-8">
<p>
Notar que de (12) se deduce que
</p>

<p>
\[\int_{−\infty}^{\infty} f_X(x)dx = 1\]
</p>

<p>
Aplicando en (12) el teorema Fundamental del Cálculo Integral, se obtiene que si
\(X\) es absolutamente continua, \(F_X(x)\) es una función continua para todo \(x\), y
su derivada es \(f_X(x)\) en todos los \(x\) donde \(f_X\) es continua.
</p>

<p>
Como la expresión <i>absolutamente continua</i> es demasiado larga, se suele hablar
simple mente de <i>distribuciones continuas</i>. Sin embargo, hay que tener en cuenta
que el hecho de que \(F_X\) sea una función continua, no implica que la
distribución de X sea absolutamente con tinua: hay funciones monótonas y
continuas, que sin embargo no son la primitiva de ninguna función. (Para más
detalles consultar el ejemplo sobre distribuciones tipo Cantor que está en
Feller Vol II, p.35-36).
</p>
</div>
</div>

<div id="outline-container-orgd1183c3" class="outline-5">
<h5 id="orgd1183c3"><span class="section-number-5">1.2.0.9</span> Interpretación intuitiva de la densidad de probabilidad</h5>
<div class="outline-text-5" id="text-1-2-0-9">
<p>
Sea \(X\) una variable aleatoria absolutamente continua con función densidad
\(f_X(x)\) continua. Para cada \(\epsilon > 0\) pequeño y para \(x \in \Re\) vale que
</p>

<p>
\[\mathbb{P}(x − \epsilon/2 < X \leq x + \epsilon/2) =
\int_{x−\epsilon/2}^{x+\epsilon/2} f_X (t) dt \approx f_X (x)\epsilon\]
</p>

<p>
Dicho en palabras, la probabilidad de que el valor de \(X\) se encuentre en un
intervalo de longitud \(\epsilon\) centrado en \(x\) es aproximadamente
\(f_X(x)\epsilon\).
</p>
</div>
</div>

<div id="outline-container-org648d64d" class="outline-4">
<h4 id="org648d64d"><span class="section-number-4">1.2.1</span> Ejemplos</h4>
<div class="outline-text-4" id="text-1-2-1">
</div>
<div id="outline-container-org52a44a6" class="outline-5">
<h5 id="org52a44a6"><span class="section-number-5">1.2.1.1</span> Ejemplo 1.10</h5>
<div class="outline-text-5" id="text-1-2-1-1">
<p>
El resultado, \(X\), del lanzamiento de un dado equilibrado (ver Ejemplo 1.1) es
una variable aleatoria discreta. Esto resulta evidente de observar que el
gráfico de la función de distribución de \(X\) (ver Figura 1) que tiene la forma
de una escalera con saltos de altura \(1 / 6\) en los puntos \(1, 2, 3, 4, 5, 6\).
Dicho en otras palabras, toda la masa de la variable aleatoria \(X\) está
concentrada en el conjunto de los átomos de \(F_X\), \(A = \{1, 2, 3, 4, 5, 6\}\).
</p>
</div>
</div>

<div id="outline-container-org2a831ab" class="outline-5">
<h5 id="org2a831ab"><span class="section-number-5">1.2.1.2</span> Ejemplo 1.11 (Números al azar)</h5>
<div class="outline-text-5" id="text-1-2-1-2">
<p>
El resultado de <i>sortear</i> un número al azar sobre el intervalo (0, 1) es una
variable aleatoria absolutamente continua. La probabilidad del evento \(U \leq u\)
es igual a la longitud del intervalo \((−\infty, u] \cap (0, 1)\).
</p>

<p>
Notar que cuando \(u \leq 0\) el intervalo \((−\infty, u] \cap (0, 1)\) se reduce al
conjunto vacío que por definición tiene longitud 0. Por otra parte, para
cualquier \(u \in (0, 1)\) se tiene que \((−\infty, u] \cap (0, 1) = (0, u)\) y en
consecuencia \(\mathbb{P}(U \leq u) = u\); mientras que si \(u \geq 1, (−\infty, u]
\cap (0, 1) = (0, 1)\) de donde sigue que \(\mathbb{P}(U \leq u) = 1\). Por lo
tanto, la función de distribución de \(U\) es
</p>

<p>
\[F_U(u) = u \textbf{1}\{0 \leq u < 1\} + \textbf{1}\{u \geq 1\}\]
</p>


<p>
Figura 3: Gráfico de la función de distribución del resultado de <i>sortear</i> un
número al azar. Derivando, respecto de \(u\), la función de distribución \(F_U (u)\)
se obtiene una función densidad para U:
</p>

<p>
\[f_U(u) = \textbf{1}\{0 < u < 1\}\]
</p>
</div>
</div>

<div id="outline-container-org56c6f74" class="outline-5">
<h5 id="org56c6f74"><span class="section-number-5">1.2.1.3</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-2-1-3">
<p>
Sortear un número al azar sobre el intervalo \((0, 1)\) es un caso particular de
una familia de variables aleatorias denominadas uniformes. Una variable
aleatoria \(X\), definida sobre un espacio de probabilidad \((\Omega, \mathcal{A},
\mathbb{P})\), se denomina uniformemente distribuida sobre el intervalo \((a, b)\),
donde \(a < b\), si \(X\) es absolutamente continua y admite una función densidad de
la forma
</p>

<p>
\[f_X(x) = \frac{1}{b-a} \textbf{1}\{x \in (a, b)\}\]
</p>

<p>
En tal caso escribiremos \(X \sim \mathcal{U} (a, b)\).
</p>
</div>
</div>

<div id="outline-container-orge821946" class="outline-5">
<h5 id="orge821946"><span class="section-number-5">1.2.1.4</span> Comentario</h5>
<div class="outline-text-5" id="text-1-2-1-4">
<p>
En la Sección 1.4 mostraremos que todas las variables aleatorias se pueden
construir utilizando variables aleatorias uniformemente distribuidas sobre el
intervalo \((0, 1)\).
</p>
</div>
</div>

<div id="outline-container-org78050bc" class="outline-5">
<h5 id="org78050bc"><span class="section-number-5">1.2.1.5</span> Ejemplo 1.12.</h5>
<div class="outline-text-5" id="text-1-2-1-5">
<p>
El tiempo, \(T\), de funcionamiento hasta la aparición de la primera falla para un
sistema con función intensidad de fallas continua \(\lambda(t)\) (ver Ejemplo 1.2)
es una variable aleatoria absolutamente continua que admite una densidad de la
forma
</p>

<p>
\[f_T(t) = \lambda(t) exp \left( -\int_0^t \lambda(s) ds \right)\textbf{1} \{t >
0\}\] (13)
</p>
</div>
</div>

<div id="outline-container-orgc26996a" class="outline-5">
<h5 id="orgc26996a"><span class="section-number-5">1.2.1.6</span> Nota Bene: algunos casos particulares del Ejemplo 1.12</h5>
<div class="outline-text-5" id="text-1-2-1-6">
<p>
El comportamiento de la densidad (13) depende de la forma particular de la
función intensidad de fallas \(\lambda(t)\). En lo que sigue mostraremos algunos
casos particulares.
</p>
</div>

<div id="outline-container-org3b46e23" class="outline-6">
<h6 id="org3b46e23"><span class="section-number-6">1.2.1.6.1</span> Exponencial de intensidad &lambda;</h6>
<div class="outline-text-6" id="text-1-2-1-6-1">
<p>
Se obtiene poniendo \(\lambda(t) = \lambda \textbf{1}\{t \geq 0\}\), donde \(\lambda\) es una
constante positiva, arbitraria pero fija.
</p>

<p>
\[f_T(t) = \lambda exp (−\lambda t) \textbf{1}\{t > 0\}\] (14)
</p>
</div>
</div>

<div id="outline-container-org4d8713e" class="outline-6">
<h6 id="org4d8713e"><span class="section-number-6">1.2.1.6.2</span> Weibull de parámetros c y &alpha;</h6>
<div class="outline-text-6" id="text-1-2-1-6-2">
<p>
Se obtiene poniendo \(\lambda(t) = \frac{c}{\alpha} \frac{t}{\alpha}^{c−1}
\textbf{1}\{t \geq 0\}\), donde \(c > 0\) y \(\alpha > 0\). En este caso, la densidad
(13) adopta la forma
</p>

<p>
\[f_T (t) = \frac{c}{\alpha} \frac{t}{\alpha}^{c−1} exp \left( - \left(
\frac{t}{\alpha} \right)^{c} \right)\] (15)
</p>

<p>
Figura 4: Gráficos de las densidades Weibull de parámetro de escala &alpha; = 1 y
parámetro de forma: c = 1, 2, 4: en línea sólida c = 1; en línea quebrada c = 2
y en línea punteada c = 4.
</p>

<p>
Notar que la exponencial de intensidad \(\lambda\) es un caso especial de la
Weibull puesto que (14) se obtiene de (15) poniendo \(c = 1\) y \(\alpha =
\lambda^{−1}\).
</p>
</div>
</div>
</div>

<div id="outline-container-orgf4008cf" class="outline-5">
<h5 id="orgf4008cf"><span class="section-number-5">1.2.1.7</span> Ejemplo 1.13</h5>
<div class="outline-text-5" id="text-1-2-1-7">
<p>
La variable aleatoria, \(S\), considerada en el Ejemplo 1.3 es una variable
aleatoria mixta (ver Figura 2) porque no es discreta ni continua. Tiene un único
átomo en s = 0 y su peso es \(exp \left(- \int_0^{t_0} \lambda(x)dx\right)\).
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgb6ce066" class="outline-3">
<h3 id="orgb6ce066"><span class="section-number-3">1.3</span> Cuantiles</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org358fcab" class="outline-5">
<h5 id="org358fcab"><span class="section-number-5">1.3.0.1</span> Definición 1.14</h5>
<div class="outline-text-5" id="text-1-3-0-1">
<p>
Sea \(\alpha \in (0, 1)\). Un cuantil-&alpha; de \(X\) es cualquier número
\(x_{\alpha} \in \Re\) tal que
</p>

<p>
\[\mathbb{P}(X < x_{\alpha}) \leq \alpha \text{ y } \alpha \leq \mathbb{P}(X
\leq x_{\alpha})\] (16)
</p>
</div>
</div>

<div id="outline-container-org17b5288" class="outline-5">
<h5 id="org17b5288"><span class="section-number-5">1.3.0.2</span> Observación 1.15</h5>
<div class="outline-text-5" id="text-1-3-0-2">
<p>
Notar que las desigualdades que caracterizan a los cuantiles-&alpha; se pueden
reescribir de la siguiente manera
</p>

<p>
\[F_X(x_{\alpha}) − \mathbb{P}(X = x_{\alpha}) \leq \alpha \text{ y }\alpha \leq
F_X (x_{\alpha})\] (17)
</p>

<p>
Por lo tanto, si \(F_X(x)\) es continua, \(x_{\alpha}\) es un cuantil \(\alpha\) si y
sólo si
</p>

<p>
\[F_X(x_{\alpha}) = \alpha\] (18)
</p>
</div>
</div>

<div id="outline-container-orge912239" class="outline-5">
<h5 id="orge912239"><span class="section-number-5">1.3.0.3</span> Interpretación <i>geométrica</i> del cuantil- &alpha;</h5>
<div class="outline-text-5" id="text-1-3-0-3">
<p>
Si \(X\) es una variable aleatoria absolutamente continua con función de densidad
\(f_X(x)\) el cuantil-&alpha; de \(X\) es la única solución de la ecuación
</p>

<p>
\[\int_{−\infty}^{x_{\alpha}}f_X(x)dx = \alpha\]
</p>

<p>
Esto significa que el cuantil-&alpha; de \(X\) es el único punto sobre el eje de
las abscisas a cuya izquierda el área bajo la función de densidad \(f_X(x)\) es
igual a \(\alpha\).
</p>
</div>
</div>

<div id="outline-container-org4b821d2" class="outline-5">
<h5 id="org4b821d2"><span class="section-number-5">1.3.0.4</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-3-0-4">
<p>
Sea \(x \in \Re\). Las desigualdades (17) significan que \(x\) es un cuantil
\(\alpha\) si y sólo si \(\alpha \in [ F(x) − \mathbb{P}(X = x) , F(x)]\)
</p>
</div>
</div>

<div id="outline-container-org80d496e" class="outline-5">
<h5 id="org80d496e"><span class="section-number-5">1.3.0.5</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-3-0-5">
<p>
El cuantil-&alpha; siempre existe. Sea $, la existencia del cuantil &alpha; se
deduce analizando el conjunto \(R_X^{\alpha} = \{x \in \Re : \alpha \leq
F_X(x)\}\).
</p>
<ol class="org-ol">
<li>\(R_X^{\alpha}\) es no vacío porque \(\displaystyle\lim_{x
   \rightarrow\infty}F_X(x) = 1\).</li>
<li>\(R_X^{\alpha}\) es acotado inferiormente porque \(\displaystyle\lim_{x
   \rightarrow−\infty} F_X(x) = 0\).</li>
<li>Si \(x_0 \in R_X^{\alpha}\), entonces \([x_0, +\infty) \subset R_X^{\alpha}\)
porque \(F_X (x)\) es no decreciente.</li>
<li>\(inf R_X^{\alpha} \in R_X^{\alpha}\) porque existe una sucesión \{x<sub>n</sub>: n &isin;
N\} &sub; R<sub>X</sub><sup>&alpha;</sup>$ tal que \(x_n ↓ ínf R_X^{\alpha}\) y \(F_X(x)\) es una
función continua a derecha: \[\alpha \leq \lim_{n \rightarrow \infty}
   F_X(x_n) = F_X \left( \lim_{n \rightarrow \infty} x_n \right) = F_X (inf
   R_X^{\alpha})\]</li>
</ol>

<p>
De las propiedades anteriores se deduce que
</p>

<p>
\[R_X^{\alpha} = [inf R_X^{\alpha}, +\infty) = [mín R_X^{\alpha}, +\infty)\]
</p>

<p>
Hay dos casos posibles:
</p>
<ul class="org-ul">
<li>(a) \(F_X (mín R_X^{\alpha}) = \alpha\) o</li>
<li>(b) $F<sub>X</sub> (mín R<sub>X</sub><sup>&alpha;</sup>) &gt; &alpha;.</li>
</ul>

<p>
(a) Si \(F_X(mín R_X^{\alpha}) = \alpha\), entonces \(\mathbb{P}(X < mín
R_X^{\alpha}) = \alpha − \mathbb{P}(X = mín R_X^{\alpha}) \leq \alpha\).
</p>

<p>
(b) Si \(F_X(mín R_X^{\alpha}) > \alpha\), entonces
</p>

<p>
$$\mathbb{P}(X &lt; x) &lt; &alpha; &forall; x &lt; mín R<sub>X</sub><sup>&alpha;</sup>$(19)
</p>

<p>
porque sino existe un \(x < mín R_x^{\alpha}\) tal que \(\alpha \leq \mathbb{P}(X <
x) \leq F_X(x)\) y por lo tanto, \(x \in R_X^{\alpha}\) lo que constituye un
absurdo.
</p>

<p>
De (19) se deduce que \(\mathbb{P}(X < mín R_X^{\alpha}) = \displaystyle\lim_{x ↑
mín R_X^{\alpha}} F_X(x) \leq \alpha\).
</p>

<p>
En cualquiera de los dos casos
</p>

<p>
\[x_{\alpha} = mín \{x \in \Re : F_X(x) \geq \alpha\}\] (20)
</p>

<p>
es un cuantil-&alpha;.
</p>
</div>
</div>

<div id="outline-container-org7f717a3" class="outline-5">
<h5 id="org7f717a3"><span class="section-number-5">1.3.0.6</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-3-0-6">
<p>
Si \(F_X\) es discontinua, (18) no tiene siempre solución; y por eso es mejor
tomar (16) como definición. Si \(F_X\) es estrictamente creciente, los cuantiles
son únicos. Pero si no, los valores que satisfacen (18) forman un intervalo.
</p>
</div>
</div>

<div id="outline-container-org7ce5352" class="outline-5">
<h5 id="org7ce5352"><span class="section-number-5">1.3.0.7</span> Cuartiles y mediana</h5>
<div class="outline-text-5" id="text-1-3-0-7">
<p>
Los cuantiles correspondientes a \(\alpha = 0.25, 0.50\) y \(0.75\) son
respectivamente el primer, el segundo y tercer cuartil. El segundo cuartil es la
mediana.
</p>
</div>
</div>

<div id="outline-container-orgc712d28" class="outline-4">
<h4 id="orgc712d28"><span class="section-number-4">1.3.1</span> Ejemplos</h4>
<div class="outline-text-4" id="text-1-3-1">
</div>
<div id="outline-container-org579fa48" class="outline-5">
<h5 id="org579fa48"><span class="section-number-5">1.3.1.1</span> Ejemplo 1.16.</h5>
<div class="outline-text-5" id="text-1-3-1-1">
<p>
En el Ejemplo 1.1 hemos visto que la función de distribución del resultado}
del lanzamie nto de un dado equilibrado e s una escalera con saltos de altura 1 / 6 en los puntos
1, 2, 3, 4, 5, 6:
</p>

<p>
F<sub>X</sub>(x) =
5
X
{i=1}
i
6
1 \{i &le; x &lt; i + 1}\} + 1\{6 &le; x\}.
</p>

<p>
Como la i magen de F<sub>X</sub>
es el conjunto \0, 1 / 6, 2 / 6, 3 / 6, 4 / 6, 5 / 6, 1{\} la ecuación (18) solo tiene
solución para &alpha; &isin; \}1 / 6, 2 / 6, 3 / 6, 4 / 6, 5 / 6{\}. Más aún, para cada i = 1, &hellip; , 5
</p>

<p>
F<sub>X</sub>(x) =
i
6
\iff x &isin; [i, i + 1).
</p>

<p>
En otras palabras, para cada i = 1, &hellip; , 5 los cuantiles-{i/}6 de X son el intervalo [i, i + 1). En
particular, <i>la</i> mediana de X es cualquier punto del intervalo [3, 4).
</p>

<p>
Para cada &alpha; &isin;

{i-1}
6,
i
6
, i = 1, &hellip; , 6, el cuantil &alpha; de X es x
&alpha;
= i.
</p>
</div>
</div>

<div id="outline-container-orga0c5c32" class="outline-5">
<h5 id="orga0c5c32"><span class="section-number-5">1.3.1.2</span> Ejemplo 1.17.</h5>
<div class="outline-text-5" id="text-1-3-1-2">
<p>
Sea T el tiempo de funcionamiento hasta la aparición de la primera falla para}
un sistema con función intensidad de fallas &lambda;(t) = 2{t{1{\}t &ge; 0{\} (ver Ejemplo 1.2). La función
de distribución de T es
</p>

<p>
F<sub>T</sub>
(t) =
</p>

<p>
1 − exp
</p>

<p>
−
Z
t<sub>0</sub>
2{sds}

1\{t &gt; 0}\} =

1 − exp

−t
2

1\{t &gt; 0} \. (21)
</p>

<p>
Como F<sub>T</sub>
(t) es continua los cuantiles- &alpha; , &alpha; &isin; (0, 1), se obtienen resolviendo la ecuación (18):
</p>

<p>
F<sub>T</sub>
(t) = &alpha; \iff 1 − exp

−t
2

= &alpha; \iff t = }
p
− log(1 − &alpha;) .
</p>

<p>
Por lo tanto, para cada &alpha; &isin; (0, 1) el cuantil-{&alpha; de T es
t
&alpha;
=
p
− log(1 − &alpha;) . (22)}
</p>

<p>
En particular, la mediana de T es t<sub>0.5</sub>
=
p
− log(1 − 0.5) &asymp; 0.8325.
</p>
</div>
</div>

<div id="outline-container-org7a45b52" class="outline-5">
<h5 id="org7a45b52"><span class="section-number-5">1.3.1.3</span> Ejemplo 1.18</h5>
<div class="outline-text-5" id="text-1-3-1-3">
<p>
Se considera un sistema con función intensidad de fallas &lambda;(t) = 2{t{1{\}t &ge; 0{\}.
</p>

<p>
El sistema debe prestar ser vici os durante 1 hora. Si durante ese período el sistema falla, se lo
repara y se lo vuelve a utiliza hasta que cumpla con el el plazo estipulado. Sea S el tiempo
de funcionamiento (medido en horas) del sistema después de la primera reparación.
</p>

<p>
En el Ejemplo 1.3 vimos que la función de distribución de S es
</p>

<p>
F<sub>S</sub>
(s) = exp
</p>

<p>
−
Z
1{−s}
0
2{tdt}

1\{0 &le; s &lt; 1}\} + 1\{s &ge; 1\}
= exp

−(1 − s)
2

1\{0 &le; s &lt; 1}\} + 1\{s &ge; 1}\,
</p>

<p>
y que S es una variable aleatoria mixta (ver Figura 2) con un único átomo en s = 0 cuyo
peso es e
−{1}
. En consecuencia, s = 0 es un cuantil-{&alpha; de S para todo &alpha; &isin;

0, e}
−{1}

</p>

<p>
. Restringida
al intervalo (0, 1) la función F<sub>S</sub>
(s) es continua y su imagen es el intervalo (e
−{1}, 1). Por ende,}
para cada &alpha; &isin; (e
−{1}, 1) el cuantil&alpha; de S se obtiene resolviendo la ecuación F<sub>S</sub>
(s) = &alpha;}:
F<sub>S</sub>
(s) = &alpha; \iff exp

−(1 − s)
2

= &alpha; \iff −(1 − s)
2
= log(&alpha;)
\iff (1 − s)
2
= − log(&alpha;) \iff |{1 − s| =
p
− log(&alpha;)
\iff 1 − s =
p
− log(&alpha;) \iff 1 −
p
− log(&alpha;) = s.}
</p>

<p>
Por lo tanto, para cada &alpha; &isin; (e
−{1}, 1) el cuantil&alpha; de S es}
s
&alpha;
= 1 −}
p
− log(&alpha;).
</p>

<p>
En particular, la mediana de S e s s
0.5
= 1 −}
p
− log(0.5) &asymp; 0.1674.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org37283e1" class="outline-3">
<h3 id="org37283e1"><span class="section-number-3">1.4</span> Construcción de variables aleatorias</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org1e6bbdc" class="outline-5">
<h5 id="org1e6bbdc"><span class="section-number-5">1.4.0.1</span> Teorema 1.19 (Simulación)</h5>
<div class="outline-text-5" id="text-1-4-0-1">
<p>
Sea F : R &rarr; [0, 1] una función con las siguientes propiedades
(F1) es no decreciente{: si x<sub>1</sub>
&le; x<sub>2</sub>, entonces F (x<sub>1</sub>) &le; F (x<sub>2</sub>);
(F2) es continua a derecha{: para todo x<sub>0</sub>
&isin; R vale que lim
x{↓}x<sub>0</sub>
F(x) = F(x<sub>0</sub>);
</p>

<p>
(F3) \displaystylelim<sub>x &rarr;−&infin;</sub>
F(x) = 0 y lim}
{x&rarr;&infin;}
F(x) = 1.
</p>

<p>
Existe una variable aleatoria X tal que F (x) = \mathbb{P}(X &le; x).
</p>
</div>
</div>

<div id="outline-container-orgce9bf16" class="outline-5">
<h5 id="orgce9bf16"><span class="section-number-5">1.4.0.2</span> Esquema de la demostración</h5>
<div class="outline-text-5" id="text-1-4-0-2">
<p>
1
o) Definir la inversa generalizada de F mediante
F
−{1}
(u) := mín\{x &isin; \Re : u &le; F (x)\, u &isin; (0, 1).
2
o) Definir X mediante
X := F
−{1}
(U), donde U &sim; \mathcal{U} (0, 1).
3
o) Observar que vale la equivalencia (inmediata) F_−{1}
(u) &le; x ⇔ u &le; F (x) y deducir que
\mathbb{P}(X &le; x) = \mathbb{P}(F
−{1}
(U) &le; x) = \mathbb{P}(U &le; F (x)) = F (x).
</p>
</div>
</div>

<div id="outline-container-org12ba30b" class="outline-5">
<h5 id="org12ba30b"><span class="section-number-5">1.4.0.3</span> Observación 1.20</h5>
<div class="outline-text-5" id="text-1-4-0-3">
<p>
Si la función \(F\) del enunciado del Teorema 1.19 es continua, la inversa
generalizada es simplemente la inversa.
</p>
</div>
</div>

<div id="outline-container-org59b9cfb" class="outline-5">
<h5 id="org59b9cfb"><span class="section-number-5">1.4.0.4</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-4-0-4">
<p>
El esquema de la demostración del Teorema 1.19 muestra cómo se construye
una va riab le aleatoria X con función de distribución F<sub>X</sub>
(x). La construcción es clave para simular variables aleatorias en una computadora: algoritmos estándar generan variables aleatorias
U con distribución uniforme sobre el intervalo (0, 1), aplicando la inversa generalizada de la
función de distribución se obtiene la variable aleatoria F_−{1}
X
(U) cuya función de distribución
es F<sub>X</sub>(x).
</p>
</div>
</div>

<div id="outline-container-org7d38803" class="outline-5">
<h5 id="org7d38803"><span class="section-number-5">1.4.0.5</span> Método gráfico para calcular inversas generalizadas</h5>
<div class="outline-text-5" id="text-1-4-0-5">
<p>
ea u &isin; (0, 1), por definición,
F
−{1}
(u) := mín\{x &isin; \Re : u &le; F (x)\, 0 &lt; u &lt; 1. Gráficamente esto significa que para calcular
F
−{1}
</p>

<p>
(u) hay que determinar el conjunto de to dos los puntos del gráfico de F (x) que están
sobre o por encima de la recta horizontal de altura u y proyectarlo sobre el eje de las abscisas.
</p>

<p>
El resultado de la proyección es una semi-recta sobre el eje de las abscisas y el valor de la
abscisa que la cierra por izquierda es el valor de F_−{1}
(u).
</p>
</div>
</div>

<div id="outline-container-org82d5eae" class="outline-5">
<h5 id="org82d5eae"><span class="section-number-5">1.4.0.6</span> Ejemplo 1.21 (Moneda cargada)</h5>
<div class="outline-text-5" id="text-1-4-0-6">
<p>
Se quiere simular el lanzamiento de una moneda <i>cargada</i>
con probabilidad p &isin; (0}, 1) de salir cara. El problema se resuelve construyendo una variable
aleatoria X a valores \0, 1{\} tal que \mathbb{P}(X = 1) = p y \mathbb{P}(X = 0) = 1 − p, (X = 1 representa el
evento <i>la moneda sale cara"/y X = 0 /"la moneda sale ceca</i>). La función de distribución de
X debe ser F(x) = (1 − p)1{\}0 &le; x &lt; 1{\} + 1{\}x &ge; 1\} y su gráfico se muestra en la Figura 5.
</p>

<p>
Figura 5: Gráfico de la función F (x) = (1 − p)1{\}0 &le; x &lt; 1{\} + 1\{x &ge; 1{\}.
La demostración del Teorema 1.19 indica que para construir la variable aleatoria X lo
primero que hay que hacer es determinar la expresión de la inversa generalizada de F (x).
</p>

<p>
Para ello usaremos el método gráfico.
</p>

<p>
En la Figura 5 se puede ver que para cada 0 &lt; u &le; 1 − p el conjunto \{x &isin; \Re : u &le; F (x)\}
es la semi-recta [0, &infin;}) y el punto que la cierra por izquierda es x = 0. En consecuencia
</p>

<p>
F
−{1}
(u) = 0 para todo 0 &lt; u &le; 1 − p}. Del mismo modo se puede ver que F_−{1}
(u) = 1 para
todo 1 − p &lt; u &lt; 1. Por lo tanto, F_−{1}
(u) = 1{\}1 − p &lt; u &lt; 1{\}.
</p>

<p>
Definiendo X := 1{\}1 − p &lt; U &lt; 1{\, donde U &sim; \mathcal{U} (0, 1) se obtiene la variable aleatoria
deseada.
</p>
</div>
</div>
<div id="outline-container-org22223fd" class="outline-5">
<h5 id="org22223fd"><span class="section-number-5">1.4.0.7</span> Ejemplo 1.22 (Moneda cargada)</h5>
<div class="outline-text-5" id="text-1-4-0-7">
<p>
Simular diez lanzamientos de una moneda <i>cargada</i> con
probabilidad 0.6 de salir cara en cada lanzamiento.
</p>

<p>
De acuerdo con el resultado obtenido en el Ejemplo 1.21,
para simular el lanzamiento
de una moneda cargada con probabilidad 0.6 de salir cara se construye la variable aleatoria
X := 1{\}0.4 &lt; U &lt; 1{\, donde U &sim; U(0 , 1).
</p>

<p>
Para simular 10 valores de X se simulan 10 valores de U}. Si en 10 simulaciones de U}
se obtuviesen los valores 0.578, 0.295, 0.885, 0.726, 0.548, 0.048, 0.474, 0.722, 0.786, 0.598,
los valores de la variable X serían 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, respectivamente, y en tal caso, los
resultados de los 10 lanzamientos de la moneda serían H, T, H, H, H, T, H, H, H, H}.
</p>
</div>
</div>
<div id="outline-container-orgf092b2e" class="outline-5">
<h5 id="orgf092b2e"><span class="section-number-5">1.4.0.8</span> Ejemplo 1.23 (Fiabilidad)</h5>
<div class="outline-text-5" id="text-1-4-0-8">
<p>
Se considera un sistema electrónico con función intensidad de
fallas de la forma &lambda; (t) = 2}t{1{\}t &gt; 0{\ . Se quiere estimar la función de probabilidad de la
cantidad de fallas ocurridas durante la primer unidad de tiempo de funcionamiento.
</p>

<p>
Para simplificar el problema vamos a suponer que cada vez que se produce una falla, el
sistema se repara instantáneamente renovándose sus condiciones iniciales de funcionamien
to. Según el Ejemplo 1.2,
la función de distribución del tiempo de funcionamiento hasta la
aparición de la primer falla es
</p>

<p>
F(t) =}

1 − exp

−t
2

1\{t &gt; 0} \. (23)
</p>

<p>
Debido a que la función de distribución F (t) es continua, su inversa generalizada es simple
mente su inversa y se obtiene despejando t de la ecuación 1 −}exp

−t
2

= u. En consecuencia,
F
−{1}
(u) =
p
− log(1 − u), u &isin; (0, 1). Para construir la variable T usamos un número aleatorio}
U, uniformemente distribuido sobre el intervalo (0, 1) y definimos}
T := F
−{1}
(U) =
p
− log(1 − U) . (24)}
</p>

<p>
La ventaja de la construcción es que puede implementarse casi de inmediato en una computa
dora. Por ejemplo, una rutina en Octave para simular T es la siguiente
</p>

<p>
U=rand;
T=sqrt(-log(1-rand))
</p>

<p>
Sobre la base de esa rutina podemos simular valores de T . Por ejemplo, en diez simulaciones
de T obtuvimos los valores siguientes: 0.3577, 1.7233, 1.1623, 0.3988, 1.4417, 0.3052, 1.1532,
0.3875, 0.8493, 0.9888.
t<sub>10</sub> 2 3 4 5 6 7 8 9
</p>

<p>
Figura 6: Simulación de los tiempos de ocurrencia de las fallas de un sistema electrónico con
función intensidad de fallas de la forma &lambda;(t) = 2{t{1{\}t &ge; 0{\}. Las fallas ocurren los instantes
0.3577, 2.0811, 3.2434, 3.6422, 5.0839, 5.3892, 6.5423, 6.9298, 7.7791, 8.7679.
</p>

<p>
La rutina puede utilizarse para simular cien mil realizaciones del experimento que consiste
en observar la cantidad de fallas durante la primer unidad de tiempo de funcionamiento
del sistema electrónico bajo consideración: N[0, 1] := mín \{n &ge; 1 :
</p>

<p>
P
n
{i=1}
T
i
&gt; 1{\} − 1, donde}
T<sub>1</sub>, T<sub>2</sub>, &hellip; son realizaciones independientes de los tiempos de funcionamiento del sistema hasta}
la ocurrencia de una falla.
</p>

<p>
Por ejemplo, repitiendo la simulación 100000 veces obtuvimos la siguiente tabla que con
tiene la cantidad de veces que fué simulado cada valor de la variable N[0, 1]:
valor simulado 0 1 2 3 4
frecuencia 36995 51792 10438 743 32
(25)
15
obteniéndose las siguientes estimaciones
</p>

<p>
\mathbb{P}(N[0, 1] = 0) &asymp; 0.36995, \mathbb{P}(N[0, 1] = 1) &asymp; 0.51792, \mathbb{P}(N[0, 1] = 2) &asymp; 0.10438,
\mathbb{P}(N[0, 1] = 3) &asymp; 0.00743, \mathbb{P}(N[0, 1] = 4) &asymp; 0.00032.
</p>

<p>
Para finalizar este ejemplo, presentamos una rutina en Octave que simula cien mil veces
la cantidad de fallas en la primer unidad de tiempo y que al final produce los resultados para
construir una tabla similar a la tabla (25).
</p>

<p>
for i=1:100000
n=-1;
S=0;
while S&lt;=1;
T=sqrt(-log(1-rand));
S=S+T;
n=n+1;
end
f(i)=n;
end
M=max(f);
for i=1:M+1;
N(i)=length(find(f==i-1));
end
N
</p>
</div>
</div>

<div id="outline-container-org15a76da" class="outline-5">
<h5 id="org15a76da"><span class="section-number-5">1.4.0.9</span> Ejemplo 1.24</h5>
<div class="outline-text-5" id="text-1-4-0-9">
<p>
La función
</p>

<p>
F(x) =}
&infin;
X
{n=1}
1
2
n
1\{x &ge; r}
n
\, (26)}
</p>

<p>
donde r
1, r
2, &hellip; es un reordenamiento de los números racionales del intervalo (0, 1) con denom
inadores crecientes:
</p>

<p>
1
2,
1
3,
2
3,
1
4,
3
4,
1
5,
2
5,
3
5,
4
5, &hellip; , tiene las siguientes propiedades es creciente,}
continua a derecha, \displaystylelim<sub>x &rarr;−&infin;</sub>
</p>

<p>
F(x) = 0 y lim}
{x&rarr;&infin;}
F(x) = 1; tiene saltos en todos los números
racionales del (0, 1) y es continua en los irracionales del (0, 1).
</p>
</div>
</div>

<div id="outline-container-org2eb4d34" class="outline-5">
<h5 id="org2eb4d34"><span class="section-number-5">1.4.0.10</span> Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-1-4-0-10">
<ol class="org-ol">
<li>Sea X una variable aleatoria con función de distribución F<sub>X</sub>(x). Mostrar que para cada</li>
</ol>
<p>
&alpha; &isin; (0}, 1) vale que
sup\{x &isin; \Re : F<sub>X</sub>
(x) &lt; &alpha;{\} = mín\{x &isin; \Re : F<sub>X</sub>
(x) &ge; &alpha;\}.
</p>
</div>
</div>
</div>

<div id="outline-container-org6974db1" class="outline-3">
<h3 id="org6974db1"><span class="section-number-3">1.5</span> Función de distribución empírica e histogramas</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Distribución empírica
La función de distribución empírica F<sub>n</sub>
(x) de n puntos sobre la recta x<sub>1</sub>, &hellip; , x<sub>n</sub>
es la
función escalera con saltos de altura 1{/n en los puntos x<sub>1</sub>, &hellip; , x<sub>n</sub>
. En otras palabras, nF<sub>n</sub>
(x)
es igual a la cantidad de puntos x
k
en (−&infin;, x] y F<sub>n</sub>
(x) es una función de distribución:
F<sub>n</sub>
(x) =
1
n
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\{i = 1, &hellip; , n : x}</td>
</tr>
</tbody>
</table>
<p>
i
&le; x\}| =}
1
n
n
X
{i=1}
1\{x}
i
&le; x\. (27)}
</p>
</div>
<div id="outline-container-org1e673b1" class="outline-5">
<h5 id="org1e673b1"><span class="section-number-5">1.5.0.1</span> Nota Bene</h5>
<div class="outline-text-5" id="text-1-5-0-1">
<p>
En la práctica, disponemos de conjuntos de observaciones (<i>muestras</i>  ) corre
spondientes a un experimento considerado aleatorio y queremos extraer de ellas conclusiones
sobre los modelos que podrían cumplir. Dada una muestra x<sub>1</sub>, &hellip; , x<sub>n</sub>, la función de distribu
ción empírica F<sub>n</sub>
(x) coincide con la función de distribución de una variable aleatoria discreta
que concentra toda la masa en los valores x<sub>1</sub>, &hellip; , x<sub>n</sub>, dando a cada uno probabilidad 1{/n}.
</p>
</div>
</div>
<div id="outline-container-org079c960" class="outline-5">
<h5 id="org079c960"><span class="section-number-5">1.5.0.2</span> Observación 1.25. Sea F<sub>n</sub></h5>
<div class="outline-text-5" id="text-1-5-0-2">
<p>
(x) la función de distribución empírica correspondiente a una
muestra de n valores x<sub>1</sub>, &hellip; , x<sub>n</sub>
. Sean a y b dos números reales tales que a &lt; b}. Notar que
F<sub>n</sub>
(b) − F<sub>n</sub>
(a) =
1
n
n
X
{i=1}
1\{x}
i
&isin; (a, b]\} =}
1
n
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\{i = 1, &hellip; , n : x}</td>
</tr>
</tbody>
</table>
<p>
i
&isin; (a, b]\}|.
En consecuencia, el cociente incremental de F<sub>n</sub>
(x) sobre el intervalo [a, b] es la frecuencia
relativa de los valores de la muestra x<sub>1</sub>, &hellip; , x<sub>n</sub>
contenidos en el intervalo (a, b] <i>normalizada</i>
por la longitud de dicho intervalo:
F<sub>n</sub>
(b) − F<sub>n</sub>
(a)
b − a
=
</p>

<p>
1
b − a

1
n
n
X
{i=1}
1\{x}
i
&isin; (a, b]\}
!
. (28)
Notar que si los n valores, x<sub>1</sub>, &hellip; , x<sub>n</sub>, corresponden a n observaciones independientes de
los valores de una variable aleatoria X, la i
nterpretación intuitiva de la probabilidad indica
que el cociente incre mental (28) debería estar próximo del cociente incremental de la función
de distribución, F<sub>X</sub>
(x), de la variable aleatoria X sobre el intervalo [a, b]:
F<sub>n</sub>
(b) − F<sub>n</sub>
(a)
b − a
&asymp;
\mathbb{P}(a &lt; X &le; b)
b − a
=
F<sub>X</sub>
(b) − F<sub>X</sub>
(a)
b − a
. (29)
Cuando X es una variable aleatoria absolutamente continua con función densidad continua
f<sub>X</sub>(x) la aproximación (28) adopta la forma
F<sub>n</sub>
(b) − F<sub>n</sub>
(a)
b − a
&asymp;<sub>1</sub>
b − a
Z
b
a
f<sub>X</sub>(x)dx = f<sub>X</sub>(x), (30)
donde x es algún punto perteneciente al intervalo (a, b).
17
Histogramas
Un histograma de una muestra x<sub>1</sub>, &hellip; , x<sub>n</sub>
se obtiene eligiendo una partición en m intervalos
de extremos a
0
&lt;  &ctdot;  &lt; a
m, con longitudes L}
j
= a
j
−a
j{−{1
; calculando las frecuencias relativas}
p
j
=
1
n
n
X
{i=1}
1\{a}
j{−{1
&lt; x
i
&lt; a
j
\}
y graficando la función igual a p
j
/L
j
en el intervalo (a
j{−{1, a
j
] y a 0 fuera de los intervalos:
f
x<sub>1,&#x2026;,x</sub><sub>n</sub>
; a
0,&#x2026;,a
m
(x) :=
m
X
{j=1}
p
j
L
j
1\{x &isin; (a
j{−{1, a
j
]\. (31)
O sea, un conjunto de rectángulos con área p
j
.
Cuando la muestra x<sub>1</sub>, &hellip; , x<sub>n</sub>
corresponde a n observaciones independientes de una vari
able aleatoria X absolutamente continua la función definida en (31) es una versión discreta
de la densidad de X en la que las áreas miden frecuencias relativas.
</p>
</div>
</div>
<div id="outline-container-org37ca286" class="outline-5">
<h5 id="org37ca286"><span class="section-number-5">1.5.0.3</span> Ejercicios adicionales</h5>
<div class="outline-text-5" id="text-1-5-0-3">
<ol class="org-ol">
<li>Lucas filma vídeos de tamaños aleatorios. En una muestra aleatoria de 5 vídeos filmados}</li>
</ol>
<p>
por Lucas se obtuvieron los siguiente tamaños (en MB):
17, 21.3, 18.7, 21, 18.7
Hallar y graficar la función de distribución empírica asociada a esta muestra. Estimar, usando
la función de distribución empírica asociada a esta muestra, la probabilidad de que un vídeo
ocupe menos de 19.5 MB.
</p>
<ol class="org-ol">
<li>Los siguientes datos corresponden a los tiempos de funcionamiento (en años) hasta que}</li>
</ol>
<p>
ocurre la primer falla de una muestra de 12 máquinas industriales:
2.0087, 1.9067, 2.0195, 1.9242, 1.8885, 1.8098,
1.9611, 2.0404, 2.1133, 2.0844, 2.1695, 1.9695.
Usando los intervalos con extremos 1.7, 1.9, 2.1, 2.3, hallar la función histograma basada en
la muestra observada e integrarla para estimar la probabilidad de que una máquina industrial
del mismo tipo funcione sin fallas durante menos de dos años.
</p>
</div>
</div>
<div id="outline-container-org2118109" class="outline-5">
<h5 id="org2118109"><span class="section-number-5">1.5.0.4</span> Ejemplo 1.26.</h5>
<div class="outline-text-5" id="text-1-5-0-4">
<p>
Sea T una variable aleatoria con distribución exponencial de intensidad 1}
(ver (14)). Esto es, T es una variable aleatoria absolutamente continua con función densidad
de probabilidad
f<sub>T</sub>
(t) = e
−t<sub>1</sub>\{t &gt; 0}\}
y función de distribución
F<sub>T</sub>(t) =

1 − e}
−t

1\{t &ge; 0\}.
</p>


<p>
De acuerdo con el esquema de la demostración del Teorema 1.19 podemos simular muestras de
T utilizando un generador de números aleatorios uniformemente distribuidos sobre el intervalo}
(0, 1). Concretamente, si U &sim; \mathcal{U} (0, 1), entonces
ˆ
T = − log(1 − U)
es una variable con distribución exponencial de intensidad 1.
Para obtener una muestra de 10 valores t<sub>1</sub>, &hellip; , t<sub>10</sub>
de una variable con distribución ex
ponencial de intensidad 1 generamos 10 números aleatorios u
1, &hellip; , u
10
y los transformamos
poniendo t
i
= − log(1 − u}
i). Por ejemplo, si los valores u
1, &hellip; , u
10
son, respectivamente,
0.1406, 0.3159, 0.8613, 0.4334, 0.0595, 0.8859, 0.2560, 0.2876, 0.2239, 0.5912,
los valores de la muestra obtenida, t<sub>1</sub>, &hellip; , t<sub>10</sub>, son, respectivamente,
0.1515, 0.3797, 1.9753, 0.5682, 0.0613, 2.1703, 0.2957, 0.3390, 0.2535, 0.8946. (32)
</p>

<p>
La función de distribución empírica de la muestra observada, F<sub>10</sub>
(t), es una función escalera
con saltos de altura 1 / 10 en los siguientes puntos del eje t:
0.0613, 0.1515, 0.2535, 0.2957, 0.3390, 0.3797, 0.5682, 0.8946, 1.9753, 2.1703.
</p>

<p>
Para construir un histograma usaremos la partición que se obtiene dividiendo en dos
intervalos de igual longitud el intervalo comprendido entre los valores mínimos y máximos
observados: 0.0613, 1.1158, 2.1703. La longitud L de cada intervalo es 1.0545. La frecuencia
relativa de la muestra sobre el primer intervalo es p
1
= 8 / 10 y sobre el segundo p
2
= 2 / 10 y
la correspondiente altura de cada rectángulo es p
1
/L = 0.75865 y p
2
/L = 0.18966.
</p>

<p>
Empírica
Teórica
(a)
</p>

<p>
Hitograma
Densidad
(b)
</p>

<p>
Figura 7: (a) Gráficos de la función de distribución empírica F<sub>10</sub>
(t) correspondiente a la
muestra dada en (32) y de la función de distribución de T . (b) Histograma correspondiente a
la misma muestra y gráfico de la densidad de T .
</p>

<p>
Para producir los gráficos de la Figura 7 usamos las siguientes rutinas en Octave.
</p>

<p>
Rutina para simular 10 valores de una exponencial de intensidad 1
U=rand(1,10);
T=-log(1-U);
</p>

<p>
Rutina para graficar la función de distribución empírica de la muestra T
t=sort(T);
s=empirical\<sub>cdf</sub>(t,t);
stairs([t(1),t],[0 s])
</p>

<p>
Rutina para graficar un histograma de la muestra T}
[f,c]=hist(T,2);
p=f/10;
L=c(2)-c(1);
bar(c,p/L,1,'w')
</p>

<p>
Usando rutinas similares para muestras de tamaño 100 se obtienen los siguientes gráficos.
</p>

<p>
Empírica
Teórica
(a)
</p>

<p>
Histograma
Densidad
(b)
</p>

<p>
Figura 8: (a) Gráficos de la función de distribución empírica F<sub>100</sub>
(t) correspondiente a una
muestra de tamaño 100 de una variable T con distribución exponencial de intensidad 1 y de
la función de distribución de T . (b) Histograma correspondiente a la misma muestra y gráfico
de la densidad de T .
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgb6e4e93" class="outline-2">
<h2 id="orgb6e4e93"><span class="section-number-2">2</span> Variables truncadas</h2>
<div class="outline-text-2" id="text-2">
<p>
Sea X una variable aleatoria definida sobre un espacio de probabilidad \((\Omega, \mathcal{A},\mathbb{P})\). Sea
B &sub; \Re un conjunto tal que X
−{1}
(B) = \{&omega; &isin; &Omega; : X(&omega;) &isin; B\} &isin; A y tal que \mathbb{P}(X &isin; B) &gt; 0.
</p>

<p>
Truncar la variable aleatoria X al conjunto B significa condicionarla a tomar valores en
el conjunto B.
</p>

<p>
Mediante X | X &isin; B designaremos la variable aleatoria obtenida por truncar X al conjunto
B. Por definición, la función de distribución de X | X &isin; B es
</p>

<p>
F<sub>X</sub> | {X&isin; B}
(x) = \mathbb{P}(X &le; x{| X &isin; B) =
\mathbb{P}(X &le; x, X &isin; B)
\mathbb{P}(X &isin; B)
. (33)
</p>

<p>
Caso absolutamente continuo. Si la variable aleatoria X es absolutamente continua con
densidad de probabilidades f<sub>X</sub>(x), la función de distribución de X | X &isin; B adopta la forma
F<sub>X</sub> | {X&isin; B}
(x) =
R
\{X\leqx\}&cap;\{X\inB\}
f<sub>X</sub>(x)dx}
\mathbb{P}(X &isin; B)
=
R
x
−&infin;
f<sub>X</sub>(x)1\{x &isin; B\dx
\mathbb{P}(X &isin; B)
. (34)
Por lo tanto, X | X &isin; B es una variable aleatoria absolutamente continua con densidad de
probabilidades
</p>

<p>
f<sub>X</sub> | {X&isin; B}
(x) =
f<sub>X</sub>(x)
\mathbb{P}(X &isin; B)
1\{x &isin; B\. (35)
</p>
</div>

<div id="outline-container-orge2d04e5" class="outline-5">
<h5 id="orge2d04e5"><span class="section-number-5">2.0.0.1</span> Nota Bene</h5>
<div class="outline-text-5" id="text-2-0-0-1">
<p>
La densidad condicional f<sub>X</sub> | {X&isin; B}
(x) es cero fuera del conjunto condicionante
B. Dentro del conjunto condicionante la densidad condicional tiene exactamente la misma}
forma que la densidad incondicional, salvo que está escalada por el factor de normalización
1{/\mathbb{P}(X &isin; B) que asegura que f<sub>X</sub>{|&isin;}B
(x) integra 1.
</p>
</div>
</div>
<div id="outline-container-orga1bd5d0" class="outline-5">
<h5 id="orga1bd5d0"><span class="section-number-5">2.0.0.2</span> Ejemplo 2.1 (Exponencial truncada a la derecha)</h5>
<div class="outline-text-5" id="text-2-0-0-2">
<p>
Sea T una variable aleatoria con distribu
ción exponencial de intensidad &lambda; &gt; 0 y sea t<sub>0</sub>
&gt; 0. Según la fórmula (35) la variable aleatoria}
T truncada a la semi-recta (t, +{&infin;), T | T &gt; t<sub>0</sub>, tiene la siguiente densidad de probabilidades
</p>

<p>
f<sub>T</sub> | T &gt;t<sub>0</sub>
(t) =
&lambda; e
−{&lambda; t}
e
−{&lambda; t<sub>0</sub>
1\{t &gt; t<sub>0</sub>
\} = e}
−{&lambda; (t}−t<sub>0</sub>)
1\{t − t<sub>0</sub>
&gt; 0{\} = f<sub>T</sub>
(t − t<sub>0</sub>).
</p>

<p>
En otros términos, si T &sim; Exp(&lambda;), entonces T | T &gt; t<sub>0</sub> &sim; t<sub>0</sub>
+Exp(&lambda;).
Caso discreto. El caso discreto se trata en forma análoga a la anterior. La función de}
probabilidad de X | X &isin; B adopta la forma
</p>

<p>
p<sub>X</sub> | {X&isin; B}
(x) =
\mathbb{P}(X = x)
\mathbb{P}(X &isin; B)
1\{x &isin; B\. (36)
</p>
</div>
</div>

<div id="outline-container-orga746559" class="outline-5">
<h5 id="orga746559"><span class="section-number-5">2.0.0.3</span> Ejemplo 2.2 (Dado equilibrado).</h5>
<div class="outline-text-5" id="text-2-0-0-3">
<p>
Sea X el resultado del tiro de un dado equilibrado y sea}
B = \2, 4, 6{\}. El evento <i>el resultado del tiro es un número par</i>  es X &isin; B}. Aplicando la
fórmula anterior obtenemos
p<sub>X</sub> | {X&isin; B}
(x) =
1 / 6
1 / 2
1\{x &isin; \{2, 4, 6\}\} =
1
3
1\{x &isin; \{2, 4, 6\}\. (37)
21
</p>
</div>
</div>
<div id="outline-container-org0dcb8f9" class="outline-3">
<h3 id="org0dcb8f9"><span class="section-number-3">2.1</span> Perdida de memoria</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-orgd1d247d" class="outline-5">
<h5 id="orgd1d247d"><span class="section-number-5">2.1.0.1</span> Ejemplo 2.3.</h5>
<div class="outline-text-5" id="text-2-1-0-1">
<p>
Lucas camina hacia la parada del colectivo. El tie mpo, T , entre llegadas}
de colectivos tiene distribución ex ponencial de intensidad &lambda;}. Supongamos que Lucas llega t
minutos después de la llegada de un colectivo. Sea X el tiempo que Lucas tendrá que esperar
hasta que llegue el próximo colectivo. Cuál es la distribución del tiempo de espera X?
Designamos mediante A = \{T &gt; t\} el evento /"Lucas llegó t minutos después de la llegada}
de un colectivo''. Tenemos que}
\mathbb{P}(X &gt; x | A) = \mathbb{P}(T &gt; t + x | T &gt; t) =}
\mathbb{P}(T &gt; t + x, T &gt; t)
\mathbb{P}(T &gt; t)
=
\mathbb{P}(T &gt; t + x)
\mathbb{P}(T &gt; t)
=
e
−{&lambda; (t{+}x)
e
−{&lambda; t}
= e
−{&lambda; x}
.
</p>
</div>
</div>
<div id="outline-container-orga53466f" class="outline-5">
<h5 id="orga53466f"><span class="section-number-5">2.1.0.2</span> Definición 2.4.</h5>
<div class="outline-text-5" id="text-2-1-0-2">
<p>
Se dice que una variable aleatoria T no tiene memoria, o pierde memoria, si
\mathbb{P}(T &gt; s + t | T &gt; t) = \mathbb{P}(T &gt; s) para todo s, t &ge; 0. (38)
La condición de pérdida de memoria es equivalente a la siguiente
\mathbb{P}(T &gt; s + t) = \mathbb{P}(T &gt; s)\mathbb{P}(T &gt; t). (39)
En efecto, basta observar que \mathbb{P}(T &gt; s + t, T &gt; t) = \mathbb{P}(T &gt; s + t) y usar la definición de
probabilidad condicional.
</p>
</div>
</div>
<div id="outline-container-orgd862eae" class="outline-5">
<h5 id="orgd862eae"><span class="section-number-5">2.1.0.3</span> Nota Bene</h5>
<div class="outline-text-5" id="text-2-1-0-3">
<p>
Si se piensa que T es el tiempo para completar cierta operación, la ecuación}
(38) establece que si a tiempo t la operación no ha sido completada, la probabilidad de que
la operación no se complete a tiempo s + t es la misma que la probabilidad inicial de que la
operación no haya sido completada a tiempo s.
</p>
</div>
</div>
<div id="outline-container-org9fae8b3" class="outline-5">
<h5 id="org9fae8b3"><span class="section-number-5">2.1.0.4</span> Lema 2.5. La variable exponencial no tiene memoria.</h5>
</div>
<div id="outline-container-orgdd54374" class="outline-5">
<h5 id="orgdd54374"><span class="section-number-5">2.1.0.5</span> Demostración Si T &sim; Exp(&lambda;), entonces}</h5>
<div class="outline-text-5" id="text-2-1-0-5">
<p>
\mathbb{P}(T &gt; t) = e}
−{&lambda; t}
para todo t &ge; 0. (40)
Usando (40) se prueba inmediatamente que la e cuación (39) se satisface cuando T tiene
distribución exponencial (pues e
−{&lambda; (s{+}t)
= e
−{&lambda; s}
e
−{&lambda; t}).
</p>
</div>
</div>
<div id="outline-container-org884eccf" class="outline-5">
<h5 id="org884eccf"><span class="section-number-5">2.1.0.6</span> Nota Bene</h5>
<div class="outline-text-5" id="text-2-1-0-6">
<p>
Si modelamos el tiempo para completar cierta operación por una variable}
aleatoria T con distribución exponencial, la propiedad de pérdida de memoria implica que
mientras la operación no haya sido completada, el tiempo restante para completarla tiene la
misma función de distribución, no importa cuando haya empezado la operación.
</p>
</div>
</div>
<div id="outline-container-org4dc052a" class="outline-5">
<h5 id="org4dc052a"><span class="section-number-5">2.1.0.7</span> Ejemplo 2.6.</h5>
<div class="outline-text-5" id="text-2-1-0-7">
<p>
Supongamos que el tiempo de espera para recibir un mensaje tenga distribu
ción exponencial de intensidad 1 / 10 minutos. Cuál es la probabilidad de que tengamos que
esperar más de 15 minutos para recibirlo? Cuál es la probabilidad de que tengamos que es
perar más de 15 minutos para recibir el mensaje dado que hace más de 10 minutos que lo
estamos esperando?
22
Si T representa el tiempo de espera, T &sim; Exp(1 / 10). La primer probabilidad es
\mathbb{P}(T &gt; 15) = e}
−
1
10
15
= e
−
3
2
&asymp; 0.220}
La segunda pregunta interroga por la probabilidad de que habiendo esperado 10 minutos
tengamos que esperar al menos 5 minutos más. Usando la propiedad de falta de memoria de
la exponencial, dicha probabilidad es
\mathbb{P}(T &gt; 5) = e}
−
1
10
5
= e
−
1
2
&asymp; 0.604.
</p>
</div>
</div>
</div>
<div id="outline-container-org5c48157" class="outline-3">
<h3 id="org5c48157"><span class="section-number-3">2.2</span> Caracterización cualitativa de la distribución exponencial</h3>
<div class="outline-text-3" id="text-2-2">
<p>
La propiedad de pérdida de memoria caracteriza a la distribución exponencial.
</p>
</div>
<div id="outline-container-orgd34fd28" class="outline-5">
<h5 id="orgd34fd28"><span class="section-number-5">2.2.0.1</span> Teorema 2.7. Sea T una variable aleatoria continua a valores en R</h5>
<div class="outline-text-5" id="text-2-2-0-1">
<ul class="org-ul">
<li></li>
</ul>
<p>
. Si T pierde memoria,
entonces T &sim; Exp(&lambda;), donde &lambda; = − log \mathbb{P}(T &gt; 1).
</p>
</div>
</div>
<div id="outline-container-org9362b7f" class="outline-5">
<h5 id="org9362b7f"><span class="section-number-5">2.2.0.2</span> Demostración (a la Cauchy). Sea G(t) := \mathbb{P}(T &gt; t). De la ecuación (39) se deduce que}</h5>
<div class="outline-text-5" id="text-2-2-0-2">
<p>
G (s + t) = G (s) G (t) . (41)
La única función continua a derecha que satisface la ecuación funcional (41) es
G (t) = G(1)
t
. (42)
Para ello basta ver que G}

m
n

= G(1)
m
n
. Si vale (41), entonces G}

2
n

= G}

1
n
</p>
<ul class="org-ul">
<li></li>
</ul>
<p>
1
n

=
G

1
n

G

1
n

= G}

1
n

2
y repitiendo el argumento se puede ver que
G

m
n

= G}
</p>

<p>
1
n

m
. (43)
En particular, si m = n se obtiene G (1) = G}

1
n

n
. Equivalentemente,
G
</p>

<p>
1
n

= G(1)
1
n
(44)
De las identidades (43) y (44) se deduce que
G

m
n

= G(1)
m
n
. (45)
Ahora bien, debido a que G(1) = \mathbb{P}(T &gt; 1) &isin; (0, 1), existe &lambda; &gt; 0 tal que G(1) = e
− &lambda;
(&lambda; = − l og G(1)). Reemplazando en (42) se obtiene G(t) =

e
− &lambda;

t
= e
−{&lambda; t}
.
</p>
</div>
</div>
</div>
<div id="outline-container-org7bbabf6" class="outline-3">
<h3 id="org7bbabf6"><span class="section-number-3">2.3</span> Dividir y conquistar</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-org9214a89" class="outline-5">
<h5 id="org9214a89"><span class="section-number-5">2.3.0.1</span> Teorema 2.8. Sea X una variable aleatoria absolutamente continua con densidad de proba</h5>
<div class="outline-text-5" id="text-2-3-0-1">
<p>
bilidades f<sub>X</sub>(x). Sea (B
i)
i &ge; 1
una familia de subconjuntos disjuntos dos a dos de la recta real
tales que \{X &isin; B}
i
\} &isin; A y \mathbb{P}(X &isin; B
i) &gt; 0 para todo i &ge; 1. Si &Omega; = &cup;}
i &ge; 1
\{X &isin; B
i
\, entonces}
f<sub>X</sub>(x) =
X
i &ge; 1
f<sub>X</sub> | {X&isin; B}
i
(x)\mathbb{P}(X &isin; B}
i). (46)
</p>
</div>
</div>

<div id="outline-container-org505f96c" class="outline-5">
<h5 id="org505f96c"><span class="section-number-5">2.3.0.2</span> Demostración</h5>
<div class="outline-text-5" id="text-2-3-0-2">
<p>
Inmediata de la fórmula (35) y de observar que}
P
i &ge; 1
1\{X &isin; B}
i
\} = 1.
</p>
</div>
</div>
<div id="outline-container-orgee573bb" class="outline-5">
<h5 id="orgee573bb"><span class="section-number-5">2.3.0.3</span> Ejemplo 2.9 (Dividir y conquistar). Todas las mañanas Lucas l lega a la estación del subte}</h5>
<div class="outline-text-5" id="text-2-3-0-3">
<p>
entre las 7:10 y las 7:30 (con distribución uniforme en el intervalo). El subte llega a la estación
cada quince minutos comenzando a las 6:00. ¿Cuál es la densidad de probabilidades del tiempo
que tiene que esperar Lucas hasta subirse al subte?
Sea X el tiempo de llegada de Lucas a la estación del subte, X &sim; \mathcal{U} [7:10, 7:30]. Sea Y
el tiempo de espera. Consideramos los eventos A = \7:10 &le; X &le; 7:15{\} = ''Lucas sube en el}
subte de las 7:15''; B = \7:15 &lt; X &le; 7:30{\} = ''Lucas sube en el subte de las 7:30''.
Condicionado al evento A, el tiempo de llegada de Lucas a la estación del subte es uniforme
entre las 7:10 y las 7:15. En en ese caso, el tiempo de esp era Y es uniforme entre 0 y 5 minutos.
Análogamente, condicionado al evento B, Y es uniforme entre 0 y 15 minutos. La densidad
de probabilidades de Y se obtiene dividiendo y conquistando
f<sub>Y</sub>(y) =
</p>

<p>
5
20

1
5
1\{0 &le; y &le; 5\} +
</p>

<p>
15
20

1
15
1\{0 &le; y &le; 15\}
=
1
10
1\{0 &le; y &le; 5\} +
1
20
1\{5 &le; y &le; 15\}.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org5f56173" class="outline-2">
<h2 id="org5f56173"><span class="section-number-2">3</span> Bibliografía consultada</h2>
<div class="outline-text-2" id="text-3">
<p>
Para redactar estas notas se consultaron los siguientes libros:
</p>
<ol class="org-ol">
<li>Bertsekas, D. P., Tsitsiklis, J. N.: Introduction to Probability. M.I.T. Lecture Notes.</li>
</ol>
<p>
(2000)
</p>
<ol class="org-ol">
<li>Chung, K. L.: A Course in Probability Theory. Academic Press, San Diego. (2001)</li>
<li>Durrett R.:Probability.Theory and Examples. Duxbury Press, Belmont. (1996)</li>
<li>Feller, W.: An introduction to Probability Theory and Its Applications. Vol. 1. John</li>
</ol>
<p>
Wiley &amp; Sons, New York. (1968)
</p>
<ol class="org-ol">
<li>Feller, W.: An introduction to Probability Theory and Its Applications. Vol. 2. John</li>
</ol>
<p>
Wiley &amp; Sons, New York. (1971)
</p>
<ol class="org-ol">
<li>Grimmett, G. R., Stirzaker, D. R.: Probability and Random Processes. Oxford Univer</li>
</ol>
<p>
sity Press, New York. (2001)
</p>
<ol class="org-ol">
<li>Johnson, N. L., Kotz, S., Balakrishnan, N.: Continuous Univariate Distributions. Vol.</li>
<li>John Wiley &amp; Sons, New York. (1995)</li>
<li>Kolmogorov, A. N.: Foundations of the Theory of Probability. Chelsea Publishing Co.,</li>
</ol>
<p>
New York. (1956)
</p>
<ol class="org-ol">
<li>Maronna R.: Probabilidad y Estadística Elementales para Estudiantes de Ciencias. Ed</li>
</ol>
<p>
itorial Exacta, La Plata. (1995).
</p>
<ol class="org-ol">
<li>Pugachev, V. S.: Introducción a la Teoría de las Probabilidades. Mir, Moscú. (1973)</li>
<li>Ross, S.: Introduction to Probability Models. Academic Press, San Diego. (2007)</li>
</ol>
<p>
24
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Basta observar que \(\{X \leq a\} \subset \{X \leq b\}\) y usar las
propiedades de la probabilidad. De la igualdad \(\{a < X \leq b\} = \{X \leq b\}
\setminus \{X \leq a\}\) se deduce que \(\mathbb{P}(a < X \leq b) = \mathbb{P}(X
\leq b) − \mathbb{P}(X \leq a) = F_X (b) − F_X (a)\).
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara">\begin{align}
F'_T (t) = \lambda(t)(1 − F_T(t)) &\iff \frac{F'_T(t)}{ 1 − F_T (t)} =
\lambda(t) \iff \frac{d} {dt} log(1 − F_T(t)) = − \lambda (t)\\
&\iff log(1 − F_T(t)) = −\int_0^t \lambda(s) ds + C \iff F_T(t) = 1 − exp\left(
−\int_0^t \lambda(s) ds + C \right)
\end{align}
<p class="footpara">
Usando que \(F_T (0) = 0\) se deduce que \(C = 0\).
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
Last update: 2020-09-16 12:18
</div>
</body>
</html>
